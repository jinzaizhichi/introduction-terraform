{"./":{"url":"./","title":"Introduction","keywords":"","body":"前言 很多年以前参加过一次AWS AWSome Day，那是一种AWS在全球各大城市巡回举办的免费的技术研讨会，时长一天，为初次接触AWS大的开发人员、IT技术人员以及企业技术领域的决策者提供入门级的AWS产品介绍。在那次AWSome Day中，我第一次接触到了现在公有云里那些耳熟能详的概念，比如Region、Availability Zone、Auto Scaling Group、RDS这些经典产品。 最让我觉得惊奇的是，培训师现场演示了一种名为CloudFormation的产品，用培训师的话说就是“撒豆成兵”，通过编写一些JSON就可以批量反复创建一批云端资源，例如AWS官方提供的一个CloudFormation例子： { \"Description\" : \"Create an EC2 instance running the Amazon Linux 32 bit AMI.\", \"Parameters\" : { \"KeyPair\" : { \"Description\" : \"The EC2 Key Pair to allow SSH access to the instance\", \"Type\" : \"String\" } }, \"Resources\" : { \"Ec2Instance\" : { \"Type\" : \"AWS::EC2::Instance\", \"Properties\" : { \"KeyName\" : { \"Ref\" : \"KeyPair\" }, \"ImageId\" : \"ami-3b355a52\" } } }, \"Outputs\" : { \"InstanceId\" : { \"Description\" : \"The InstanceId of the newly created EC2 instance\", \"Value\" : { \"Ref\" : \"Ec2Instance\" } } }, \"AWSTemplateFormatVersion\" : \"2010-09-09\" } 这样一段简单的JSON，就可以让我们用指定的镜像id创建一台云端虚拟机，不需要在界面上点点点。要知道在当时，我正在一家初创公司工作，同时身兼架构师、后台开发程序员、DBA以及运维数职，要维护测试、预发布以及生产三套环境，时不时还因为要去修复因环境之间配置不一致而引发的种种错误而焦头烂额，那时的我就很期待CloudFormation能够给予我这种能够批量创建并管理\"招之能来，来之能战，战之能胜，胜之能去\"的环境的能力。但很可惜，CloudFormation是AWS独家拥有的能力，而那时的AWS价格对我们来说太贵了，中国区的产品也非常少，所以这个梦想也就不了了之了，但是CloudFormation的那种高度标准化与自动化给我带来的冲击一直挥之不去。 我当时并不知道在西雅图的华盛顿大学，有一个美日混血大帅哥Mitchell Hashimoto和他的老板Armon Dagar也深深沉迷于CloudFormation所带来的那种优雅与高效，同时他们也在头疼CloudFormation本身的一系列问题，最主要的就是它是AWS独占的。强人和我这种庸人最大的区别就是，强人有了想法直接就去做，Mitchell和Armon在讨论中渐渐有了一个想法——打造一个多云(Multi-Cloud)的开源的基础设施即代码(IaC)工具，并且要超越CloudFormation。他们组建了一家名为HashiCorp的公司来实现这个目标。 在今年3月，HashiCorp宣布成功获得1.75亿美元的E轮融资，投后公司估值51亿美元。HashiCorp的产品线主要有Nomad、Consul、Valut以及Terraform，另外还有Vagrant以及Packer两个开源工具，2020年还推出了Boundary以及Waypoint两个新产品。 HashiCorp的产品线主要是由Nomad、Consul、Vault、Terraform组成的HashiStack，Terraform扮演了承载整个HashiStack的关键角色，负责在不同的云平台之上创建出一致的基础设施来，当然我们完全可以只使用Terraform而不是使用完整的HashiStack。 HashiCorp这家公司有一个显著特点，就是他们极其有耐心，并且极其重视“基础设施”的建设。例如，他们在思考Terraform配置文件该用JSON还是YAML时，对两者都不满意，所以他们宁可慢下来，花时间去设计了HCL(HashiCorp Configuration Language)，使得他们对于声明式代码的可读性有了完全的掌控力。再比如在他们设计Terraform以及Vault、Packer时，他们使用的go语言因为是把引用代码下载下来后静态链接编译成单一可执行文件，所以不像jar或者dll那样有运行时动态加载插件的能力。因此他们又花时间开发了go-plugin这个项目，把插件编译成一个独立进程，与主进程通过rpc进行互操作。该项目上的投资很好地支撑了Terraform、Vault、Packer项目的插件机制，进而演化出如今百花齐放的HashiCorp开源生态。 我这些年陆陆续续向很多人推荐过Terraform，并且很高兴地看到行业内越来越多的团队开始认可并采纳，但是前不久我仍然十分惊讶地意识到，由于Terraform官方并没有提供任何的中文文档，导致了许多中国互联网从业者没有足够的动力去啃完所有英文文档并付诸实践。这当然是一件非常正常的事情，对国人来说阅读英文文档毕竟比读中文的文档费力一些。先贤说：山不来就我，我便去就山。既然我期望Terraform能在中国得到更大的推广，那么我就为此做一些工作，为Terraform写一个入门级的中文教程，降低学习和推广的难度。 这个教程受到HashiCorp Infrastructure Automation Certification的启发，这是一个HashiCorp出品的Terraform认证，是一个相当基础的认证考试，内容涵盖了Terraform所有的常规操作技能。通过这门认证并不能让你成为一个高效的Terraform开发人员，但可以确保你装备齐全，拥有了足够全面的知识来进行Terraform实战和探索。 这个教程基本按照Terraform认证考试所列的考纲来编写，第三章到第五章内容主要是翻译官方文档，目标读者是((对“基础设施即代码”以及Terraform有兴趣 || 厌倦了在浏览器中依靠大量低级重复点点点操作云) && (懒得阅读英文文档)) 的人。如果你是为了确认Terraform某项功能，或是你的英语阅读能力足够好，请直接按照考纲去阅读官方文档，毕竟官方文档最为权威，更新也比较及时。假如你只是想偷个懒，想通过快速浏览中文文档来对Terraform有一个大概的了解，那么这个教程就是为你准备的。另外如果有朋友担心学习曲线问题的话，请不用担心，Terraform在设计时就为降低学习曲线做了大量工作，可以这样说，只要你能够看懂JSON，那么就能轻松掌握Terraform。 另外本教程在编写过程中参考了Terraform著名教材——Yevgeniy Brikman编纂的《Terraform Up & Runnning》： 这本书是目前Terraform最好的教材，喜闻电子工业出版社已于2020年12月出版，建议读者在掌握了Terraform基础知识以后阅读该教材，掌握更多的Terraform生态高阶技能。 对于这本书我再安利一下，目前中国人参加ACM(acm.org，计算机协会)年费有折扣，折下来160+一年，可以在learning.acm.org上进入O'REILLY在线学习中心畅读大量O'REILLY的电子书，非常划算，基本读两三本就回本了。这本书也可以通过这种方式在线阅读。 教程编写时Terraform对主力版本是0.13.5；Terraform提供了Macos、Linux以及Windows的发行版，所以读者完全可以自己跟着教程进行一些练习和实验。 另外，Terraform的生态环境到了今天，已经发展为三个分支，分别是： 开源版 Terraform Cloud云服务版 Terraform企业版 三个版本之间有些微的差别，包括对同一名词(例如Workspace)的定义都会有所不同。本教程针对开源版编写，暂不涉及云服务版以及企业版。 特别鸣谢李宇飞同学为本书进行了非常细致的校对工作。 让我们开始我们的Terraform入门之旅吧。 "},"1.Terraform初步体验.html":{"url":"1.Terraform初步体验.html","title":"Terraform初步体验","keywords":"","body":"Terraform初步体验 安装 首先我们先安装Terraform。对于Ubuntu用户： curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository -y \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" sudo apt-get update && sudo apt-get install -y terraform 对于CentOS用户： sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo sudo yum -y install terraform 对于Mac用户： brew tap hashicorp/tap brew install hashicorp/tap/terraform 对于Windows用户，官方推荐的包管理器是choco，可以去https://chocolatey.org/ 下载安装好chocolatey后，以管理员身份启动powershell，然后： choco install terraform 如果只想纯手动安装，那么可以前往Terraform官网下载对应操作系统的可执行文件(Terraform是用go编写的，只有一个可执行文件)，解压缩到指定的位置后，配置一下环境变量的PATH，使其包含Terraform所在的目录即可。 验证 terraform version Terraform v0.13.5 terraform -help Usage: terraform [-version] [-help] [args] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you're just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. ##... 一个简单的例子 让我们以UCloud为例写一个简单的例子，运行这个例子会产生些许费用，如果读者不想付费，那么只需要阅读流程即可。另外介绍Terraform入门的文章很多，大多以AWS为例，阿里云与腾讯云也有相关入门介绍文章，不想注册UCloud账号的读者也可以自行查阅其他公有云相关的入门文章，本系列教程的重点将是后续的部分，所以无论用什么公有云，读者只需要对Terraform有一个最简单的体验就可以。 首先，你需要前往ucloud.cn注册一个UCloud账号，然后登录控制台，获取PublicKey和PrivateKey，再访问https://accountv2.ucloud.cn/auth_manage/project，获取默认项目id。 然后我们创建一个干净的空文件夹，在里面创建一个main.tf文件(tf就是Terraform，Terraform代码大部分是.tf文件，语法是HCL，当然目前也支持JSON格式的Terraform代码，但我们暂时只以tf为例)： terraform { required_version = \"~>0.13.5\" required_providers { ucloud = { source = \"ucloud/ucloud\" version = \"~>1.22.0\" } } } provider \"ucloud\" { public_key = \"JInqRnkSY8eAmxKFRxW9kVANYThg1pcvjD2Aw5f5p\" private_key = \"IlJn6GlmanYI1iDVEtrPyt5R9noAGz41B8q5TML7abqD8e4YjVdylwaKWdY61J5TcA\" project_id = \"org-tgqbvi\" region = \"cn-bj2\" } data \"ucloud_security_groups\" \"default\" { type = \"recommend_web\" } data \"ucloud_images\" \"default\" { availability_zone = \"cn-bj2-04\" name_regex = \"^CentOS 6.5 64\" image_type = \"base\" } resource \"ucloud_instance\" \"web\" { availability_zone = \"cn-bj2-04\" image_id = data.ucloud_images.default.images[0].id instance_type = \"n-basic-2\" root_password = \"supersecret1234\" name = \"tf-example-instance\" tag = \"tf-example\" boot_disk_type = \"cloud_ssd\" security_group = data.ucloud_security_groups.default.security_groups[0].id delete_disks_with_instance = true user_data = 这里要注意修改代码中的这一段： provider \"ucloud\" { public_key = \"JInqRnkSY8eAmxKFRxW9kVANYThg1pcvjD2Aw5f5p\" private_key = \"IlJn6GlmanYI1iDVEtrPyt5R9noAGz41B8q5TML7abqD8e4YjVdylwaKWdY61J5TcA\" project_id = \"org-tgqbvi\" region = \"cn-bj2\" } 这里的public_key、private_key以及project_id要替换成读者自己刚才获取到的访问密钥以及项目id。代码里的key和project id已经被我删除了。必须特别指出的是，这种将机密信息硬编码在代码中的做法是非常错误的，仅在此处方便演示适用，切勿将含有自己机密信息的代码提交到源代码管理系统里，练习后注意重制自己的密钥。 这段代码比较简单，头部的terraform这一段声明了这段代码所需要的Terraform版本以及UCloud插件版本，后面的provider段则是给出了调用UCloud API所需要的key和项目id等信息。 真正定义云端基础设施的代码就是后面的部分，分为三部分，data、resource和output。 data代表利用UCloud插件定义的data模型对UCloud进行查询，例如我们在代码中利用data查询cn-bj2-04机房UCloud官方提供的CentOS 6.5 x64主机镜像的id，以及官方提供的默认Web服务器适用的安全组(可以理解成防火墙)的id，这样我们就不需要人工在界面上去查询相关id，再硬编码到代码中。 resource代表我们需要在云端创建的资源，在例子里我们创建了三个资源，分别是主机、弹性公网ip，以及主机和公网ip的绑定。 我们在定义主机时给定了主机的尺寸、系统盘类型等关键信息，并且通过user_data定义了第一次开机时所要执行的初始化脚本，在脚本中我们在这台CentOS服务器上安装了nginx服务并启动之。 最后，我们声明了一个output，名字是eip，它的值就是我们创建的弹性公网ip的值。 运行这段代码很简单，让我们在代码所在的路径下进入命令行，执行： $ terraform init 这时Terraform会进行初始化操作，通过官方插件仓库下载对应操作系统的UCloud插件。如果一切都正常，读者应该会看到： Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. 然后我们可以预览一下代码即将产生的变更： $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.ucloud_images.default: Refreshing state... data.ucloud_security_groups.default: Refreshing state... ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # ucloud_eip.web-eip will be created + resource \"ucloud_eip\" \"web-eip\" { + bandwidth = (known after apply) + charge_mode = \"bandwidth\" + charge_type = \"dynamic\" + create_time = (known after apply) + expire_time = (known after apply) + id = (known after apply) + internet_type = \"bgp\" + ip_set = (known after apply) + name = \"web-eip\" + public_ip = (known after apply) + remark = (known after apply) + resource = (known after apply) + status = (known after apply) + tag = \"Default\" } # ucloud_eip_association.web-eip-association will be created + resource \"ucloud_eip_association\" \"web-eip-association\" { + eip_id = (known after apply) + id = (known after apply) + resource_id = (known after apply) + resource_type = (known after apply) } # ucloud_instance.web will be created + resource \"ucloud_instance\" \"web\" { + auto_renew = (known after apply) + availability_zone = \"cn-bj2-04\" + boot_disk_size = (known after apply) + boot_disk_type = \"cloud_ssd\" + charge_type = (known after apply) + cpu = (known after apply) + cpu_platform = (known after apply) + create_time = (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) + delete_disks_with_instance = true + disk_set = (known after apply) + expire_time = (known after apply) + id = (known after apply) + image_id = \"uimage-awndwi\" + instance_type = \"n-basic-2\" + ip_set = (known after apply) + isolation_group = (known after apply) + memory = (known after apply) + name = \"tf-example-instance\" + private_ip = (known after apply) + remark = (known after apply) + root_password = (sensitive value) + security_group = \"firewall-jofwjzmw\" + status = (known after apply) + subnet_id = (known after apply) + tag = \"tf-example\" + user_data = 这段输出告诉我们，代码即将创建3个新资源，修改0个资源，删除0个资源。资源的属性少部分是我们在代码中直接给出的，或是通过data查询的，所以在plan命令的结果中可以看到它们的值；更多的属性只有在资源真正被创建以后我们才能看到，所以会显示“(known after apply)”。 然后我们运行一下： $ terraform apply data.ucloud_images.default: Refreshing state... data.ucloud_security_groups.default: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # ucloud_eip.web-eip will be created + resource \"ucloud_eip\" \"web-eip\" { + bandwidth = (known after apply) + charge_mode = \"bandwidth\" + charge_type = \"dynamic\" + create_time = (known after apply) + expire_time = (known after apply) + id = (known after apply) + internet_type = \"bgp\" + ip_set = (known after apply) + name = \"web-eip\" + public_ip = (known after apply) + remark = (known after apply) + resource = (known after apply) + status = (known after apply) + tag = \"Default\" } # ucloud_eip_association.web-eip-association will be created + resource \"ucloud_eip_association\" \"web-eip-association\" { + eip_id = (known after apply) + id = (known after apply) + resource_id = (known after apply) + resource_type = (known after apply) } # ucloud_instance.web will be created + resource \"ucloud_instance\" \"web\" { + auto_renew = (known after apply) + availability_zone = \"cn-bj2-04\" + boot_disk_size = (known after apply) + boot_disk_type = \"cloud_ssd\" + charge_type = (known after apply) + cpu = (known after apply) + cpu_platform = (known after apply) + create_time = (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) + delete_disks_with_instance = true + disk_set = (known after apply) + expire_time = (known after apply) + id = (known after apply) + image_id = \"uimage-awndwi\" + instance_type = \"n-basic-2\" + ip_set = (known after apply) + isolation_group = (known after apply) + memory = (known after apply) + name = \"tf-example-instance\" + private_ip = (known after apply) + remark = (known after apply) + root_password = (sensitive value) + security_group = \"firewall-jofwjzmw\" + status = (known after apply) + subnet_id = (known after apply) + tag = \"tf-example\" + user_data = 当我们运行terraform apply时，Terraform会首先重新计算一下变更计划，并且像刚才执行plan命令那样把变更计划打印给我们，要求我们人工确认。让我们输入yes，然后回车： ucloud_eip.web-eip: Creating... ucloud_instance.web: Creating... ucloud_eip.web-eip: Creation complete after 3s [id=eip-pyjwpcgd] ucloud_instance.web: Still creating... [10s elapsed] ucloud_instance.web: Still creating... [20s elapsed] ucloud_instance.web: Still creating... [30s elapsed] ucloud_instance.web: Creation complete after 39s [id=uhost-e4heibq3] ucloud_eip_association.web-eip-association: Creating... ucloud_eip_association.web-eip-association: Creation complete after 5s [id=eip-pyjwpcgd:uhost-e4heibq3] Apply complete! Resources: 3 added, 0 changed, 0 destroyed. Outputs: eip = 106.75.32.183 可以看到，Terraform成功地创建了我们定义的资源，并且把我们定义的输出给打印了出来。如果我们在浏览器里访问我们输出的弹性ip地址，我们就可以看到一个nginx页面： 清理 完成这个体验后，不要忘记清理我们的云端资源。我们可以通过调用destroy命令来轻松完成清理： $ terraform destroy data.ucloud_images.default: Refreshing state... [id=1609882940] data.ucloud_security_groups.default: Refreshing state... [id=2820377529] ucloud_eip.web-eip: Refreshing state... [id=eip-pyjwpcgd] ucloud_instance.web: Refreshing state... [id=uhost-e4heibq3] ucloud_eip_association.web-eip-association: Refreshing state... [id=eip-pyjwpcgd:uhost-e4heibq3] An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # ucloud_eip.web-eip will be destroyed - resource \"ucloud_eip\" \"web-eip\" { - bandwidth = 1 -> null - charge_mode = \"bandwidth\" -> null - charge_type = \"dynamic\" -> null - create_time = \"2020-11-15T16:31:42+08:00\" -> null - expire_time = \"2020-11-15T17:31:42+08:00\" -> null - id = \"eip-pyjwpcgd\" -> null - internet_type = \"bgp\" -> null - ip_set = [ - { - internet_type = \"BGP\" - ip = \"106.75.32.183\" }, ] -> null - name = \"web-eip\" -> null - public_ip = \"106.75.32.183\" -> null - resource = { - \"id\" = \"uhost-e4heibq3\" - \"type\" = \"instance\" } -> null - status = \"used\" -> null - tag = \"Default\" -> null } # ucloud_eip_association.web-eip-association will be destroyed - resource \"ucloud_eip_association\" \"web-eip-association\" { - eip_id = \"eip-pyjwpcgd\" -> null - id = \"eip-pyjwpcgd:uhost-e4heibq3\" -> null - resource_id = \"uhost-e4heibq3\" -> null - resource_type = \"instance\" -> null } # ucloud_instance.web will be destroyed - resource \"ucloud_instance\" \"web\" { - auto_renew = true -> null - availability_zone = \"cn-bj2-04\" -> null - boot_disk_size = 20 -> null - boot_disk_type = \"cloud_ssd\" -> null - charge_type = \"month\" -> null - cpu = 2 -> null - cpu_platform = \"Intel/Broadwell\" -> null - create_time = \"2020-11-15T16:31:46+08:00\" -> null - delete_disks_with_instance = true -> null - disk_set = [ - { - id = \"bsi-wnj4eh2x\" - is_boot = true - size = 20 - type = \"cloud_ssd\" }, ] -> null - expire_time = \"2020-12-15T16:31:48+08:00\" -> null - id = \"uhost-e4heibq3\" -> null - image_id = \"uimage-awndwi\" -> null - instance_type = \"n-basic-2\" -> null - ip_set = [ - { - internet_type = \"Private\" - ip = \"10.9.20.202\" }, - { - internet_type = \"BGP\" - ip = \"106.75.32.183\" }, ] -> null - memory = 4 -> null - name = \"tf-example-instance\" -> null - private_ip = \"10.9.20.202\" -> null - root_password = (sensitive value) - security_group = \"firewall-jofwjzmw\" -> null - status = \"Running\" -> null - subnet_id = \"subnet-0azpshdq\" -> null - tag = \"tf-example\" -> null - user_data = null - vpc_id = \"uvnet-olpsy01g\" -> null } Plan: 0 to add, 0 to change, 3 to destroy. Changes to Outputs: - eip = \"106.75.32.183\" -> null Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only 'yes' will be accepted to confirm. Enter a value: yes 可以看到，Terraform列出了它即将清理的资源信息，并且要求我们人工确认同意继续执行清理操作。我们输入yes，然后回车： ucloud_eip_association.web-eip-association: Destroying... [id=eip-pyjwpcgd:uhost-e4heibq3] ucloud_eip_association.web-eip-association: Destruction complete after 2s ucloud_eip.web-eip: Destroying... [id=eip-pyjwpcgd] ucloud_instance.web: Destroying... [id=uhost-e4heibq3] ucloud_eip.web-eip: Destruction complete after 0s ucloud_instance.web: Destruction complete after 6s Destroy complete! Resources: 3 destroyed. 很快的，刚才创建的资源就全部被删除了。 Terraform与以往诸如Ansible等配置管理工具比较大的不同在于，它是根据代码计算出的目标状态与当前状态的差异来计算变更计划的，有兴趣的读者可以在执行terraform apply以后，直接再执行一次terraform apply，看看会发生什么，就能明白他们之间的差异。 实际上这段代码在apply以后，直接再次apply，得到的计划会是什么也不做，因为当前云端的资源状态已经完全符合代码所描述的期望状态了，所以Terraform什么也不会做。好了，这就是我们对Terraform的一个初步体验。 "},"2.1.Terraform基础概念——Provider.html":{"url":"2.1.Terraform基础概念——Provider.html","title":"Provider","keywords":"","body":"Terraform基础概念——Provider Terraform被设计成一个多云基础设施编排工具，不像CloudFormation那样绑定AWS平台，Terraform可以同时编排各种云平台或是其他基础设施的资源。Terraform实现多云编排的方法就是Provider插件机制。 Terraform使用的是HashiCorp自研的go-plugin库(https://github.com/hashicorp/go-plugin)，本质上各个Provider插件都是独立的进程，与Terraform进程之间通过rpc进行调用。Terraform引擎首先读取并分析用户编写的Terraform代码，形成一个由data与resource组成的图(Graph)，再通过rpc调用这些data与resource所对应的Provider插件；Provider插件的编写者根据Terraform所制定的插件框架来定义各种data和resource，并实现相应的CRUD方法；在实现这些CRUD方法时，可以调用目标平台提供的SDK，或是直接通过调用Http(s) API来操作目标平台。 下载Provider 我们在第一章的小例子中，写完代码后在apply之前，首先我们执行了一次terraform init。terraform init会分析代码中所使用到的Provider，并尝试下载Provider插件到本地。如果我们观察执行完第一章例子的文件夹，我们会发现有一个.terraform文件夹，我们所使用的UCloud Provider插件就被下载安装在里面。 .terraform └── plugins ├── registry.terraform.io │ └── ucloud │ └── ucloud │ └── 1.22.0 │ └── darwin_amd64 -> /Users/byers/.terraform.d/plugin-cache/registry.terraform.io/ucloud/ucloud/1.22.0/darwin_amd64 └── selections.json 有的时候下载某些Provider会非常缓慢，或是在开发环境中存在许多的Terraform项目，每个项目都保有自己独立的插件文件夹非常浪费磁盘，这时我们可以使用插件缓存。 有两种方式可以启用插件缓存： 第一种方法是配置TF_PLUGIN_CACHE_DIR这个环境变量： export TF_PLUGIN_CACHE_DIR=\"$HOME/.terraform.d/plugin-cache\" 第二种方法是使用CLI配置文件。Windows下是在相关用户的%APPDATA%目录下创建名为\"terraform.rc\"的文件，Macos和Linux用户则是在用户的home下创建名为\".terraformrc\"的文件。在文件中配置如下： plugin_cache_dir = \"$HOME/.terraform.d/plugin-cache\" 当启用插件缓存之后，每当执行terraform init命令时，Terraform引擎会首先检查期望使用的插件在缓存文件夹中是否已经存在，如果存在，那么就会将缓存的插件拷贝到当前工作目录下的.terraform文件夹内。如果插件不存在，那么Terraform仍然会像之前那样下载插件，并首先保存在插件文件夹中，随后再从插件文件夹拷贝到当前工作目录下的.terraform文件夹内。为了尽量避免同一份插件被保存多次，只要操作系统提供支持，Terraform就会使用符号连接而不是实际从插件缓存目录拷贝到工作目录。 需要特别注意的是，Windows 系统下plugin_cache_dir的路径也必须使用/作为分隔符，应使用C:/somefolder/plugin_cahce而不是C:\\somefolder\\plugin_cache Terrafom引擎永远不会主动删除缓存文件夹中的插件，缓存文件夹的尺寸可能会随着时间而增长到非常大，这时需要手工清理。 搜索Provider 想要了解有哪些被官方接纳的Provider，有两种方法： 第一种方法是访问Terraform 官方 Provider 文档，该页面中列出了主流的Provider： 第二种方法就是前往registry.terraform.io进行搜索： 目前推荐在registry搜索Provider，因为大量由社区开发的Provider都被注册在了那里。 一般来说，相关Provider如何声明，以及相关data、resource的使用说明，都可以在registry上查阅到相关文档。 registry.terraform.io不但可以查询Provider，也可以用来发布Provider；并且它也可以用来查询和发布模块(Module)，不过模块将是我们后续篇章讨论的话题。 Provider的声明 一组Terraform代码要被执行，相关的Provider必须在代码中被声明。不少的Provider在声明时需要传入一些关键信息才能被使用，例如我们在第一章的例子中，必须给出访问密钥以及期望执行的UCloud区域（Region）信息。 terraform { required_providers { ucloud = { source = \"ucloud/ucloud\" version = \">=1.24.1\" } } } provider \"ucloud\" { public_key = \"your_public_key\" private_key = \"your_private_key\" project_id = \"your_project_id\" region = \"cn-bj2\" } 在这段Provider声明中，首先在terraform节的required_providers里声明了本段代码必须要名为ucloud的Provider才可以执行，source = \"ucloud/ucloud\"这一行声明了ucloud这个插件的源地址(Source Address)。一个源地址是全球唯一的，它指示了Terraform如何下载该插件。一个源地址由三部分组成： [/]/ HostName是选填的，默认是官方的 registry.terraform.io，读者也可以构建自己私有的Terraform仓库。Namespace是在Terraform仓库内得到组织名，这代表了发布和维护插件的组织或是个人。Type是代表插件的一个短名，在特定的HostName/Namespace下Type必须唯一。 required_providers中的插件声明还声明了该源码所需要的插件的版本约束，在例子里就是version = \">=1.24.1\"。Terraform插件的版本号采用MAJOR.MINOR.PATCH的语义化格式，版本约束通常使用操作符和版本号表达约束条件，条件之间可以用逗号拼接，表达AND关联，例如\">= 1.2.0, =(或者不加=，直接使用版本号)：只允许特定版本号，不允许与其他条件合并使用 !=：不允许特定版本号 >,>=, ~>：锁定MAJOR与MINOR，允许PATCH号大于等于特定版本号，例如，~>0.9等价于>=0.9, 0.8.4等价于>=0.8.4, Terraform会检查当前工作环境或是插件缓存中是否存在满足版本约束的插件，如果不存在，那么Terraform会尝试下载。如果Terraform无法获得任何满足版本约束条件的插件，那么它会拒绝继续执行任何后续操作。 可以用添加后缀的方式来声明预览版，例如：1.2.0-beta。预览版只能通过\"=\"操作符(或是空缺操作符)后接明确的版本号的方式来指定，不可以与>=、~>等搭配使用。 推荐使用\">=\"操作符约束最低版本。如果你是在编写旨在由他人复用的模块代码时，请避免使用\"~>\"操作符，即使你知道模块代码与新版本插件会有不兼容。 内建Provider 绝大多数Provider是以插件形式单独分发的，但是目前有一个Provider是内建于Terraform主进程中的，那就是terraform_remote_state data source。该Provider由于是内建的，所以使用时不需要在terraform中声明required_providers。这个内建Provider的源地址是terraform.io/builtin/terraform。 多Provider实例 provider节声明了ucloud这个Provider所需要的各项配置。在上文的代码示例中，provider \"ucloud\"和required_providers中ucloud = {...}块里的ucloud，都是Provider的Local Name，一个Local Name是在一个模块中对一个Provider的唯一的标识。 我们也可以声明多个同类型的Provider，并给予不同的Local Name： terraform { required_version = \">=0.13.5\" required_providers { ucloudbj = { source = \"ucloud/ucloud\" version = \">=1.24.1\" } ucloudsh = { source = \"ucloud/ucloud\" version = \">=1.24.1\" } } } provider \"ucloudbj\" { public_key = \"your_public_key\" private_key = \"your_private_key\" project_id = \"your_project_id\" region = \"cn-bj2\" } provider \"ucloudsh\" { public_key = \"your_public_key\" private_key = \"your_private_key\" project_id = \"your_project_id\" region = \"cn-sh2\" } data \"ucloud_security_groups\" \"default\" { provider = ucloudbj type = \"recommend_web\" } data \"ucloud_images\" \"default\" { provider = ucloudsh availability_zone = \"cn-sh2-01\" name_regex = \"^CentOS 6.5 64\" image_type = \"base\" } 例如上面的例子，我们声明了两个UCloud Provider，分别定位在北京区域和上海区域。我们在接下来的data声明中显式指定了provider的Local Name，这使得我们可以在一组配置文件中同时操作不同区域、不同账号的资源。 我们也可以使用alias别名来区隔同类Provider的不同实例： terraform { required_version = \">=0.13.5\" required_providers { ucloud = { source = \"ucloud/ucloud\" version = \">=1.24.1\" } } } provider \"ucloud\" { public_key = \"your_public_key\" private_key = \"your_private_key\" project_id = \"your_project_id\" region = \"cn-bj2\" } provider \"ucloud\" { alias = \"ucloudsh\" public_key = \"your_public_key\" private_key = \"your_private_key\" project_id = \"your_project_id\" region = \"cn-sh2\" } data \"ucloud_security_groups\" \"default\" { type = \"recommend_web\" } data \"ucloud_images\" \"default\" { provider = ucloud.ucloudsh availability_zone = \"cn-sh2-01\" name_regex = \"^CentOS 6.5 64\" image_type = \"base\" } 和多Local Name相比，使用别名允许我们区分 provider 的不同实例。terraform节的required_providers中只声明了一次ucloud，并且在data中指定provider时传入的是ucloud.ucloudsh。多实例Provider请使用别名。 每一个不带alias属性的provider声明都是一个默认provider声明。没有显式指定provider的data以及resource都使用默认资源名第一个单词所对应的provider，例如，ucloud_images这个data对应的默认provider就是ucloud，aws_instance这个resource对应的默认provider就是aws。 假如代码中所有显式声明的provider都有别名，那么Terraform运行时会构造一个所有配置均为空值的默认provider。假如provider有必填字段，并且又有资源使用了默认provider，那么Terraform会抛出一个错误，抱怨默认provider缺失了必填字段。 "},"2.2.Terraform基础概念——状态管理.html":{"url":"2.2.Terraform基础概念——状态管理.html","title":"状态管理","keywords":"","body":"Terraform基础概念——状态管理 我们在第一章的末尾提过，当我们成功地执行了一次terraform apply，创建了期望的基础设施以后，我们如果再次执行terraform apply，生成的新的执行计划将不会包含任何变更，Terraform会记住当前基础设施的状态，并将之与代码所描述的期望状态进行比对。第二次apply时，因为当前状态已经与代码描述的状态一致了，所以会生成一个空的执行计划。 初探状态文件 在这里，Terraform引入了一个独特的概念——状态管理，这是Ansible等配置管理工具或是自研工具调用SDK操作基础设施的方案所没有的。简单来说，Terraform将每次执行基础设施变更操作时的状态信息保存在一个状态文件中，默认情况下会保存在当前工作目录下的terraform.tfstate文件里。例如我们在代码中声明一个data和一个resource： data \"ucloud_images\" \"default\" { availability_zone = \"cn-sh2-01\" name_regex = \"^CentOS 6.5 64\" image_type = \"base\" } resource \"ucloud_vpc\" \"vpc\" { cidr_blocks = [\"10.0.0.0/16\"] name = \"my-vpc\" } 使用terraform apply后，我们可以看到terraform.tfstate的内容： { \"version\": 4, \"terraform_version\": \"0.13.5\", \"serial\": 54, \"lineage\": \"a0d89a84-ae5b-8e14-d61b-2d9885e3359a\", \"outputs\": {}, \"resources\": [ { \"mode\": \"data\", \"type\": \"ucloud_images\", \"name\": \"default\", \"provider\": \"provider[\\\"registry.terraform.io/ucloud/ucloud\\\"]\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"availability_zone\": \"cn-sh2-01\", \"id\": \"1693951353\", \"ids\": [ \"uimage-xiucsl\" ], \"image_id\": null, \"image_type\": \"base\", \"images\": [ { \"availability_zone\": \"cn-sh2-01\", \"create_time\": \"2020-01-09T11:30:34+08:00\", \"description\": \"\", \"features\": [ \"NetEnhanced\", \"CloudInit\" ], \"id\": \"uimage-xiucsl\", \"name\": \"CentOS 6.5 64位\", \"os_name\": \"CentOS 6.5 64位\", \"os_type\": \"linux\", \"size\": 20, \"status\": \"Available\", \"type\": \"base\" } ], \"most_recent\": false, \"name_regex\": \"^CentOS 6.5 64\", \"os_type\": null, \"output_file\": null, \"total_count\": 1 } } ] }, { \"mode\": \"managed\", \"type\": \"ucloud_vpc\", \"name\": \"vpc\", \"provider\": \"provider[\\\"registry.terraform.io/ucloud/ucloud\\\"]\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"cidr_blocks\": [ \"10.0.0.0/16\" ], \"create_time\": \"2020-11-16T17:00:40+08:00\", \"id\": \"uvnet-lu2vcdds\", \"name\": \"my-vpc\", \"network_info\": [ { \"cidr_block\": \"10.0.0.0/16\" } ], \"remark\": null, \"tag\": \"Default\", \"update_time\": \"2020-11-16T17:00:40+08:00\" }, \"private\": \"bnVsbA==\" } ] } ] } 我们可以看到，查询到的data以及创建的resource信息都被以json格式保存在tfstate文件里。 我们前面已经说过，由于tfstate文件的存在，我们在terraform apply之后立即再次apply是不会执行任何变更的，那么如果我们删除了这个tfstate文件，然后再执行apply会发生什么呢？Terraform读取不到tfstate文件，会认为这是我们第一次创建这组资源，所以它会再一次创建代码中描述的所有资源。更加麻烦的是，由于我们前一次创建的资源所对应的状态信息被我们删除了，所以我们再也无法通过执行terraform destroy来销毁和回收这些资源，实际上产生了资源泄漏。所以妥善保存这个状态文件是非常重要的。 另外，如果我们对Terraform的代码进行了一些修改，导致生成的执行计划将会改变状态，那么在实际执行变更之前，Terraform会复制一份当前的tfstate文件到同路径下的terraform.tfstate.backup中，以防止由于各种意外导致的tfstate损毁。 在Terraform发展的极早期，HashiCorp曾经尝试过无状态文件的方案，也就是在执行Terraform变更计划时，给所有涉及到的资源都打上特定的tag，在下次执行变更时，先通过tag读取相关资源来重建状态信息。但因为并不是所有资源都支持打tag，也不是所有公有云都支持多tag，所以Terraform最终决定用状态文件方案。 还有一点，HashiCorp官方从未公开过tfstate的格式，也就是说，HashiCorp保留随时修改tfstate格式的权力。所以不要试图手动或是用自研代码去修改tfstate，Terraform命令行工具提供了相关的指令(我们后续会介绍到)，请确保只通过命令行的指令操作状态文件。 极其重要的安全警示——tfstate是明文的 关于Terraform状态，还有极其重要的事，所有考虑在生产环境使用Terraform的人都必须格外小心并再三警惕：Terraform的状态文件是明文的，这就意味着代码中所使用的一切机密信息都将以明文的形式保存在状态文件里。例如我们回到创建UCloud主机的例子： data \"ucloud_security_groups\" \"default\" { type = \"recommend_web\" } data \"ucloud_images\" \"default\" { availability_zone = \"cn-sh2-02\" name_regex = \"^CentOS 6.5 64\" image_type = \"base\" } resource \"ucloud_instance\" \"normal\" { availability_zone = \"cn-sh2-02\" image_id = data.ucloud_images.default.images[0].id instance_type = \"n-basic-2\" root_password = \"supersecret1234\" name = \"tf-example-normal-instance\" tag = \"tf-example\" boot_disk_type = \"cloud_ssd\" security_group = data.ucloud_security_groups.default.security_groups[0].id delete_disks_with_instance = true } 我们在代码中明文传入了root_password的值是supersecret1234，执行了terraform apply后我们观察tfstate文件中相关段落： { \"mode\": \"managed\", \"type\": \"ucloud_instance\", \"name\": \"normal\", \"provider\": \"provider[\\\"registry.terraform.io/ucloud/ucloud\\\"]\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"allow_stopping_for_update\": null, \"auto_renew\": false, \"availability_zone\": \"cn-sh2-02\", \"boot_disk_size\": 20, \"boot_disk_type\": \"cloud_ssd\", \"charge_type\": null, \"cpu\": 2, \"cpu_platform\": \"Intel/Broadwell\", \"create_time\": \"2020-11-16T18:06:32+08:00\", \"data_disk_size\": null, \"data_disk_type\": null, \"data_disks\": [], \"delete_disks_with_instance\": true, \"disk_set\": [ { \"id\": \"bsi-krv0ilrc\", \"is_boot\": true, \"size\": 20, \"type\": \"cloud_ssd\" } ], \"duration\": null, \"expire_time\": \"1970-01-01T08:00:00+08:00\", \"id\": \"uhost-u2byoz4i\", \"image_id\": \"uimage-ku3uri\", \"instance_type\": \"n-basic-2\", \"ip_set\": [ { \"internet_type\": \"Private\", \"ip\": \"10.25.94.58\" } ], \"isolation_group\": \"\", \"memory\": 4, \"min_cpu_platform\": null, \"name\": \"tf-example-normal-instance\", \"private_ip\": \"10.25.94.58\", \"remark\": \"\", \"root_password\": \"supersecret1234\", \"security_group\": \"firewall-a0lqq3r3\", \"status\": \"Running\", \"subnet_id\": \"subnet-0czucaf2\", \"tag\": \"tf-example\", \"timeouts\": null, \"user_data\": null, \"vpc_id\": \"uvnet-0noi3kun\" }, \"private\": \"eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjYwMDAwMDAwMDAwMCwidXBkYXRlIjoxMjAwMDAwMDAwMDAwfX0=\", \"dependencies\": [ \"data.ucloud_images.default\", \"data.ucloud_security_groups.default\" ] } ] } 可以看到root_password的值supersecret1234是以明文形式被写在tfstate文件里的。这是Terraform从设计之初就确定的，并且在可见的未来不会有改善。不论你是在代码中明文硬编码，还是使用参数(variable，我们之后的章节会介绍)，亦或是妙想天开地使用函数在运行时从外界读取，都无法改变这个结果。 解决之道有两种，一种是使用Vault或是AWS Secret Manager这样的动态机密管理工具生成临时有效的动态机密(比如有效期只有5分钟，即使被他人读取到，机密也早已失效)；另一种就是我们下面将要介绍的——Terraform Backend。 生产环境的tfstate管理方案——Backend 到目前为止我们的tfstate文件是保存在当前工作目录下的本地文件，假设我们的计算机损坏了，导致文件丢失，那么tfstate文件所对应的资源都将无法管理，而产生资源泄漏。 另外如果我们是一个团队在使用Terraform管理一组资源，团队成员之间要如何共享这个状态文件？能不能把tfstate文件签入源代码管理工具进行保存？ 把tfstate文件签入管代码管理工具是非常错误的，这就好比把数据库签入了源代码管理工具，如果两个人同时签出了同一份tfstate，并且对代码做了不同的修改，又同时apply了，这时想要把tfstate签入源码管理系统可能会遭遇到无法解决的冲突。 为了解决状态文件的存储和共享问题，Terraform引入了远程状态存储机制，也就是Backend。Backend是一种抽象的远程存储接口，如同Provider一样，Backend也支持多种不同的远程存储服务： Terraform Remote Backend分为两种： 标准：支持远程状态存储与状态锁 增强：在标准的基础上支持远程操作(在远程服务器上执行plan、apply等操作) 目前增强型Backend只有Terraform Cloud云服务一种。 状态锁是指，当针对一个tfstate进行变更操作时，可以针对该状态文件添加一把全局锁，确保同一时间只能有一个变更被执行。不同的Backend对状态锁的支持不尽相同，实现状态锁的机制也不尽相同，例如consul backend就通过一个.lock节点来充当锁，一个.lockinfo节点来描述锁对应的会话信息，tfstate文件被保存在backend定义的路径节点内；s3 backend则需要用户传入一个Dynamodb表来存放锁信息，而tfstate文件被存储在s3存储桶里。名为etcd的backend对应的是etcd v2，它不支持状态锁；etcdv3则提供了对状态锁的支持，等等等等。读者可以根据实际情况，挑选自己合适的Backend。接下来我将以consul为范例为读者演示Backend机制。 Consul简介以及安装 Consul是HashiCorp推出的一个开源工具，主要用来解决服务发现、配置中心以及Service Mesh等问题；Consul本身也提供了类似ZooKeeper、Etcd这样的分布式键值存储服务，具有基于Gossip协议的最终一致性，所以可以被用来充当Terraform Backend存储。 安装Consul十分简单，如果你是Ubuntu用户： curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" sudo apt-get update && sudo apt-get install -y consul 对于CentOS用户： sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo sudo yum -y install consul 对于Macos用户： brew tap hashicorp/tap brew install hashicorp/tap/consul 对于Windows用户，如果按照前文安装Terraform教程已经配置了Chocolatey的话： choco install consul 安装完成后的验证： $ consul Usage: consul [--version] [--help] [] Available commands are: acl Interact with Consul's ACLs agent Runs a Consul agent catalog Interact with the catalog config Interact with Consul's Centralized Configurations connect Interact with Consul Connect debug Records a debugging archive for operators event Fire a new event exec Executes a command on Consul nodes force-leave Forces a member of the cluster to enter the \"left\" state info Provides debugging information for operators. intention Interact with Connect service intentions join Tell Consul agent to join cluster keygen Generates a new encryption key keyring Manages gossip layer encryption keys kv Interact with the key-value store leave Gracefully leaves the Consul cluster and shuts down lock Execute a command holding a lock login Login to Consul using an auth method logout Destroy a Consul token created with login maint Controls node or service maintenance mode members Lists the members of a Consul cluster monitor Stream logs from a Consul agent operator Provides cluster-level tools for Consul operators reload Triggers the agent to reload configuration files rtt Estimates network round trip time between nodes services Interact with services snapshot Saves, restores and inspects snapshots of Consul server state tls Builtin helpers for creating CAs and certificates validate Validate config files/directories version Prints the Consul version watch Watch for changes in Consul 安装完Consul后，我们可以启动一个测试版Consul服务： $ consul agent -dev Consul会在本机8500端口开放Http终结点，我们可以通过浏览器访问http://localhost:8500 ： 使用Backend 我们写一个可以免费执行的简单Terraform代码： terraform { required_version = \"~>0.13.5\" required_providers { ucloud = { source = \"ucloud/ucloud\" version = \">=1.22.0\" } } backend \"consul\" { address = \"localhost:8500\" scheme = \"http\" path = \"my-ucloud-project\" } } provider \"ucloud\" { public_key = \"JInqRnkSY8eAmxKFRxW9kVANYThfIW9g2diBbZ8R8\" private_key = \"8V5RClzreyKBxrJ2GsePjfDYHy55yYsIIy3Qqzjjah0C0LLxhXkKSzEKFWkATqu4U\" project_id = \"org-a2pbab\" region = \"cn-sh2\" } resource \"ucloud_vpc\" \"vpc\" { cidr_blocks = [\"10.0.0.0/16\"] } 注意要把代码中的public_key、private_key和project_id换成你自己的。 在terraform节中，我们添加了backend配置节，指定使用localhost:8500为地址(也就是我们刚才启动的测试版Consul服务)，指定使用http协议访问该地址，指定tfstate文件存放在Consul键值存储服务的my-ucloud-project路径下。 当我们执行完terraform apply后，我们访问http://localhost:8500/ui/dc1/kv ： 可以看到my-ucloud-project，点击进入： 可以看到，原本保存在工作目录下的tfstate文件的内容，被保存在了Consul的名为my-ucloud-project的键下。 让我们执行terraform destroy后，重新访问http://localhost:8500/ui/dc1/kv ： 可以看到，my-ucloud-project这个键仍然存在。让我们点击进去： 可以看到，它的内容为空，代表基础设施已经被成功销毁。 观察锁文件 那么在这个过程里，锁究竟在哪里？我们如何能够体验到锁的存在？让我们对代码进行一点修改： terraform { required_version = \"~>0.13.5\" required_providers { ucloud = { source = \"ucloud/ucloud\" version = \">=1.22.0\" } } backend \"consul\" { address = \"localhost:8500\" scheme = \"http\" path = \"my-ucloud-project\" } } provider \"ucloud\" { public_key = \"JInqRnkSY8eAmxKFRxW9kVANYThfIW9g2diBbZ8R8\" private_key = \"8V5RClzreyKBxrJ2GsePjfDYHy55yYsIIy3Qqzjjah0C0LLxhXkKSzEKFWkATqu4U\" project_id = \"org-a2pbab\" region = \"cn-sh2\" } resource \"ucloud_vpc\" \"vpc\" { cidr_blocks = [\"10.0.0.0/16\"] provisioner \"local-exec\" { command = \"sleep 1000\" } } 这次的变化是我们在ucloud_vpc的定义上添加了一个local-exec类型的provisioner。provisioner我们在后续的章节中会专门叙述，在这里读者只需要理解，Terraform进程在成功创建了该VPC后，会在执行Terraform命令行的机器上执行一条命令：sleep 1000，这个时间足以将Terraform进程阻塞足够长的时间，以便让我们观察锁信息了。 让我们执行terraform apply，这一次apply将会被sleep阻塞，而不会成功完成： An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # ucloud_vpc.vpc will be created + resource \"ucloud_vpc\" \"vpc\" { + cidr_blocks = [ + \"10.0.0.0/16\", ] + create_time = (known after apply) + id = (known after apply) + name = (known after apply) + network_info = (known after apply) + remark = (known after apply) + tag = \"Default\" + update_time = (known after apply) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes ucloud_vpc.vpc: Creating... ucloud_vpc.vpc: Provisioning with 'local-exec'... ucloud_vpc.vpc (local-exec): Executing: [\"/bin/sh\" \"-c\" \"sleep 1000\"] ucloud_vpc.vpc: Still creating... [10s elapsed] ... 让我们重新访问http://localhost:8500/ui/dc1/kv ： 这一次情况发生了变化，我们看到除了my-ucloud-project这个键之外，还多了一个同名的文件夹。让我们点击进入文件夹： 在这里我们成功观测到了.lock和.lockinfo文件。让我们点击.lock看看： Consul UI提醒我们，该键值对目前正被锁定，而它的内容是空。让我们查看.lockinfo的内容： .lockinfo里记录了锁ID、我们执行的操作，以及其他的一些信息。 让我们另起一个新的命令行窗口，在同一个工作目录下尝试另一次执行terraform apply： $ terraform apply Acquiring state lock. This may take a few moments... Error: Error locking state: Error acquiring the state lock: Lock Info: ID: 563ef038-610e-85cf-ca89-9e3b4a830b67 Path: my-ucloud-project Operation: OperationTypeApply Who: byers@ByersMacBook-Pro.local Version: 0.13.5 Created: 2020-11-16 11:53:50.473561 +0000 UTC Info: consul session: 9bd80a12-bc2f-1c5b-af0f-cdb07e5e69dc Terraform acquires a state lock to protect the state from being written by multiple users at the same time. Please resolve the issue above and try again. For most commands, you can disable locking with the \"-lock=false\" flag, but this is not recommended. 可以看到，同时另一个人试图对同一个tfstate执行变更的尝试失败了，因为它无法顺利获取到锁。 让我们用ctrl-c终止原先被阻塞的terraform apply的执行，然后重新访问http://localhost:8500/ui/dc1/kv ： 可以看到，包含锁的文件夹消失了。Terraform命令行进程在接收到ctrl-c信号时，会首先把当前已知的状态信息写入Backend内，然后释放Backend上的锁，再结束进程。但是如果Terraform进程是被强行杀死，或是机器掉电，那么在Backend上就会遗留一个锁，导致后续的操作都无法执行，这时我们需要用terraform force-unlock命令强行删除锁，我们将在后续的章节中详细叙述。 小贴士——假如一开始Backend配置写错了会怎么样 让我们假设我们拥有一个干净的工作目录，我们新建了一个main.tf代码文件，在terraform配置节当中配置了如下backend: backend \"consul\" { address = \"localhost:8600\" scheme = \"http\" path = \"my-ucloud-project\" } 我们把address参数写错了，端口号从8500写成了8600，这是我们执行一次terraform init： $ terraform init Initializing the backend... Successfully configured the backend \"consul\"! Terraform will automatically use this backend unless the backend configuration changes. Error: Failed to get existing workspaces: Get \"http://localhost:8600/v1/kv/my-ucloud-project-env:?keys=&separator=%2F\": EOF 并不奇怪，Terraform抱怨无法连接到localhost:8600。这时我们把backend配置的端口纠正回8500，重新执行init看看： $ terraform init Initializing the backend... Backend configuration changed! Terraform has detected that the configuration specified for the backend has changed. Terraform will now check for existing state in the backends. Error: Error inspecting states in the \"consul\" backend: Get \"http://localhost:8600/v1/kv/my-ucloud-project-env:?keys=&separator=%2F\": EOF Prior to changing backends, Terraform inspects the source and destination states to determine what kind of migration steps need to be taken, if any. Terraform failed to load the states. The data in both the source and the destination remain unmodified. Please resolve the above error and try again. 还是错误，Terraform还是试图连接localhost:8600，并且这次的报错信息提示我们需要帮助它解决错误，以便它能够决定如何进行状态数据的迁移。 这是因为Terraform发现Backend的配置发生了变化，所以它尝试从原先的Backend读取状态数据，并且尝试将之迁移到新的Backend，但因为原先的Backend是错的，所以它会再次抱怨连接不上localhost:8500。 如果我们检查此时的工作目录下的.terraform目录，会看到其中多了一个本地的terraform.tfstate。检查它的内容： { \"version\": 3, \"serial\": 2, \"lineage\": \"aa296584-3606-f9b0-78da-7c5563b46c7b\", \"backend\": { \"type\": \"consul\", \"config\": { \"access_token\": null, \"address\": \"localhost:8600\", \"ca_file\": null, \"cert_file\": null, \"datacenter\": null, \"gzip\": null, \"http_auth\": null, \"key_file\": null, \"lock\": null, \"path\": \"my-ucloud-project\", \"scheme\": \"http\" }, \"hash\": 3939494596 }, \"modules\": [ { \"path\": [ \"root\" ], \"outputs\": {}, \"resources\": {}, \"depends_on\": [] } ] } 可以看到它把最初的Backend配置记录在了里面，地址仍然是localhost:8600，这就导致了我们即使修正了Backend配置，也无法成功init。在这个场景下，解决方法也很简单，直接删除这个本地tfstate文件即可。 这个小问题引出了我们的下一个话题——状态迁移。 状态迁移 让我们先重启一下测试版Consul服务，清除旧有的状态。假如我们一开始没有声明backend： terraform { required_version = \"~>0.13.5\" required_providers { ucloud = { source = \"ucloud/ucloud\" version = \">=1.22.0\" } } } provider \"ucloud\" { public_key = \"JInqRnkSY8eAmxKFRxW9kVANYThfIW9g2diBbZ8R8\" private_key = \"8V5RClzreyKBxrJ2GsePjfDYHy55yYsIIy3Qqzjjah0C0LLxhXkKSzEKFWkATqu4U\" project_id = \"org-a2pbab\" region = \"cn-sh2\" } resource \"ucloud_vpc\" \"vpc\" { cidr_blocks = [\"10.0.0.0/16\"] } 然后我们执行terraform init，继而执行terraform apply，那么我们将成功创建云端资源，并且在工作目录下会有一个terraform.tfstate文件： { \"version\": 4, \"terraform_version\": \"0.13.5\", \"serial\": 1, \"lineage\": \"a0335546-0039-cccc-467b-5dc3050c8212\", \"outputs\": {}, \"resources\": [ { \"mode\": \"managed\", \"type\": \"ucloud_vpc\", \"name\": \"vpc\", \"provider\": \"provider[\\\"registry.terraform.io/ucloud/ucloud\\\"]\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"cidr_blocks\": [ \"10.0.0.0/16\" ], \"create_time\": \"2020-11-16T22:24:38+08:00\", \"id\": \"uvnet-ssgiofxv\", \"name\": \"tf-vpc-20201116142437539000000001\", \"network_info\": [ { \"cidr_block\": \"10.0.0.0/16\" } ], \"remark\": null, \"tag\": \"Default\", \"update_time\": \"2020-11-16T22:24:38+08:00\" }, \"private\": \"bnVsbA==\" } ] } ] } 随后我们加上了之前写过的指向本机测试Consul服务的backend声明，然后执行terraform init： $ terraform init Initializing the backend... Do you want to copy existing state to the new backend? Pre-existing state was found while migrating the previous \"local\" backend to the newly configured \"consul\" backend. No existing state was found in the newly configured \"consul\" backend. Do you want to copy this state to the new \"consul\" backend? Enter \"yes\" to copy and \"no\" to start with an empty state. Enter a value: yes Terraform成功地检测到backend类型从local变为了consul，并且确认了Consul里同名路径下没有状态文件存在，于是Terraform可以替我们把本机的状态文件迁移到新的Backend里，但这需要我们手工确认。输入yes并且回车： Enter a value: yes Successfully configured the backend \"consul\"! Terraform will automatically use this backend unless the backend configuration changes. Initializing provider plugins... - Using previously-installed ucloud/ucloud v1.22.0 Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. 这时让我们访问http://localhost:8500/ui/dc1/kv/my-ucloud-project/edit ： 本机的状态数据被成功地迁移到了Consul里(虽然和本机的文件并不完全相同，但状态数据是相同的)。 那假如试图迁移状态时，新backend的目标路径上已经存在其他tfstate会发生什么呢？我们简单地说一下结果，就是Terraform会把我们的tfstate和新backend上既有的其他tfstate下载到本机的一个临时目录下，然后要求我们人工核对以后决定是否覆盖既有的tfstate。 Backend配置的动态赋值 有些读者会注意到，到目前为止我所写的代码里的配置项基本都是硬编码的，Terraform是否支持运行时用变量动态赋值？答案是支持的，Terraform可以通过variable变量来传值给provider、data和resource。 但有一个例外，那就是backend配置。backend配置只允许硬编码，或者不传值。 这个问题是因为Terraform运行时本身设计的运行顺序导致的，一直到2019年05月官方才给出了解决方案，那就是“部分配置“(partial configuration)。 简单来说就是我们可以在tf代码的backend声明中不给出具体的配置： terraform { required_version = \"~>0.13.5\" required_providers { ucloud = { source = \"ucloud/ucloud\" version = \">=1.22.0\" } } backend \"consul\" { } } 而在另一个独立的文件中给出相关配置，例如我们在工作目录下创建一个名为backend.hcl的文件： address = \"localhost:8500\" scheme = \"http\" path = \"my-ucloud-project\" 本质上我们就是把原本属于backend consul节的属性赋值代码搬迁到一个独立的hcl文件内，然后我们执行terraform init时附加backend-config参数： $ terraform init -backend-config=backend.hcl 这样也可以初始化成功。通过这种打补丁的方式，我们可以复用他人预先写好的Terraform代码，在执行时把属于我们自己的Backend配置信息以独立的backend-config文件的形式传入来进行初始化。 Backend的权限控制以及版本控制 Backend本身并没有设计任何的权限以及版本控制，这方面完全依赖于具体的Backend实现。以AWS S3为例，我们可以针对不同的Bucket设置不同的IAM，用以防止开发测试人员直接操作生产环境，或是给予部分人员对状态信息的只读权限；另外我们也可以开启S3的版本控制功能，以防我们错误修改了状态文件(Terraform命令行有修改状态的相关指令)。 状态的隔离存储 我们讲完Backend，现在要讨论另一个问题。假设我们的Terraform代码可以创建一个通用的基础设施，比如说是云端的一个eks、aks集群，或者是一个基于S3的静态网站，那么我们可能要为很多团队创建并维护这些相似但要彼此隔离的Stack，又或者我们要为部署的应用维护开发、测试、预发布、生产四套不同的部署。那么该如何做到不同的部署，彼此状态文件隔离存储和管理呢？ 一种简单的方法就是分成不同的文件夹存储。 我们可以把不同产品不同部门使用的基础设施分成不同的文件夹，在文件夹内维护相同的代码文件，配置不同的backend-config，把状态文件保存到不同的Backend上。这种方法可以给予最大程度的隔离，缺点是我们需要拷贝许多份相同的代码。 第二种更加轻量级的方法就是Workspace。注意，Terraform开源版的Workspace与Terraform Cloud云服务的Workspace实际上是两个不同的概念，我们这里介绍的是开源版的Workspace。 Workspace允许我们在同一个文件夹内，使用同样的Backend配置，但可以维护任意多个彼此隔离的状态文件。还是我们刚才那个使用测试Consul服务作为Backend的例子： 当前我们有一个状态文件，名字是my-ucloud-project。然后我们在工作目录下执行这样的命令： $ terraform workspace new feature1 Created and switched to workspace \"feature1\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. 通过调用workspace命令，我们成功创建了名为feature1的Workspace。这时我们观察.terraform文件夹： .terraform ├── environment ├── modules │ └── modules.json └── plugins ├── registry.terraform.io │ ├── ucloud ...... 我们会发现多了一个environment文件，它的内容是feature1。这实际上就是Terraform用来保存当前上下文环境使用的是哪个Workspace的文件。 重新观察Consul存储会发现多了一个文件：my-ucloud-project-env:feature1。这就是Terraform为feature1这个Workspace创建的独立的状态文件。让我们执行一下apply，然后再看这个文件的内容： 可以看到，状态被成功写入了feature1的状态文件。 我们可以通过以下命令来查询当前Backend下所有的Workspace： $ terraform workspace list default * feature1 我们有default和feature1两个Workspace，当前我们工作在feature1上。我们可以用以下命令切换回default： $ terraform workspace select default Switched to workspace \"default\". 我们可以用以下命令确认我们成功切换回了default： $ terraform workspace show default 我们可以用以下命令删除feature1： $ terraform workspace delete feature1 Deleted workspace \"feature1\"! 再观察Consul存储，就会发现feature1的状态文件被删除了： 目前支持多工作区的Backend有： AzureRM Consul COS GCS Kubernetes Local Manta Postgres Remote S3 该使用哪种隔离 相比起多文件夹隔离的方式来说，基于Workspace的隔离更加简单，只需要保存一份代码，在代码中不需要为Workspace编写额外代码，用命令行就可以在不同工作区之间来回切换。 但是Workspace的缺点也同样明显，由于所有工作区的Backend配置是一样的，所以有权读写某一个Workspace的人可以读取同一个Backend路径下所有其他Workspace；另外Workspace是隐式配置的(调用命令行)，所以有时人们会忘记自己工作在哪个Workspace下。 Terraform官方为Workspace设计的场景是：有时开发人员想要对既有的基础设施做一些变更，并进行一些测试，但又不想直接冒险修改既有的环境。这时他可以利用Workspace复制出一个与既有环境完全一致的平行环境，在这个平行环境里做一些变更，并进行测试和实验工作。 Workspace对应的源代码管理模型里的主干——分支模型，如果团队希望维护的是不同产品之间不同的基础设施，或是开发、测试、预发布、生产环境，那么最好还是使用不同的文件夹以及不同的backend-config进行管理。 "},"3.Terraform代码的书写.html":{"url":"3.Terraform代码的书写.html","title":"Terraform代码的书写","keywords":"","body":"Terraform代码的书写 我们将在本章讲解Terraform配置文件的编写。 Terraform早期仅支持使用HCL(Hashicorp Configuration Language)语法的.tf文件，近些年来也开始支持JSON。HashiCorp甚至修改了他们的json解析器，使得他们的json可以支持注释，但HCL相比起JSON来说有着更好的可读性，所以我们还是会以HCL来讲解。其实我个人是不太喜欢用JSON编写Terraform代码的，有些团队使用JSON是因为他们是用其他代码来生成相应的JSON格式的Terraform代码(比如自研的GUI工具，通过拖拽的方式定义基础设施，继而生辰相关代码)。我个人不太喜欢这种方式，因为它鼓励用户从零开始拖拽出所需的所有基础设施，而不是通过组装成熟的可复用的模块代码。我个人认为应该像对待业务逻辑代码一样对待基础设施代码。 这里特别之处一点，我们将在这一章节提到模块(Module)的概念，但我们会在后续单独的章节专门讲解模块。在本章内，读者可以简单地将一个模块理解成一个含有多个Terraform代码文件的目录，不包含其子目录。 本章内容基本是对官方文档的翻译，英语阅读能力好的读者应该直接阅读官方文档获取最权威的信息。 "},"3.1.类型.html":{"url":"3.1.类型.html","title":"类型","keywords":"","body":"类型 Terraform的某些类型之间存在隐式类型转换规则，如果无法隐式转换类型，那么不同类型数据间的赋值将会报错。 Terraform类型分为原始类型与复杂类型两大类。 原始类型 原始类型分三类：string、number、bool。 string代表一组Unicode字符串，例如：\"hello\"。 number代表数字，可以为整数，也可以为小数。 bool代表布尔值，要么为true，要么为false。bool值可以被用做逻辑判断。 number和bool都可以和string进行隐式转换，当我们把number或bool类型的值赋给string类型的值，或是反过来时，Terraform会自动替我们转换类型，其中： true值会被转换为\"true\"，反之亦然 false值会被转换为\"false\"，反之亦然 15会被转换为\"15\"，3.1415会被转换为\"3.1415\"，反之亦然 复杂类型 复杂类型是一组值所组成的符合类型，有两类复杂类型。 一种是集合类型。一个集合包含了一组同一类型的值。集合内元素的类型成为元素类型。一个集合变量在构造时必须确定集合类型。集合内所有元素的类型必须相同。 Terraform支持三种集合： list(...)：列表是一组值的连续集合，可以用下标访问内部元素，下标从0开始。例如名为l的list，l[0]就是第一个元素。list类型的声明可以是list(number)、list(string)、list(bool)等，括号中的类型即为元素类型。 map(...)：字典类型(或者叫映射类型)，代表一组键唯一的键值对，键类型必须是string，值类型任意。map(number)代表键为string类型而值为number类型，其余类推。map值有两种声明方式，一种是类似{\"foo\": \"bar\", \"bar\": \"baz\"}，另一种是{foo=\"bar\", bar=\"baz\"}。键可以不用双引号，但如果键是以数字开头则例外。多对键值对之间要用逗号分隔，也可以用换行符分隔。推荐使用=号(Terraform代码规范中规定按等号对齐，使用等号会使得代码在格式化后更加美观) set(...)：集合类型，代表一组不重复的值。 以上集合类型都支持通配类型缩写，例如list等价于list(any)，map等价于map(any)，set等价于set(any)。any代表支持任意的元素类型，前提是所有元素都是一个类型。例如，将list(number)赋给list(any)是合法的，list(string)赋给list(any)也是合法的，但是list内部所有的元素必须是同一种类型的。 第二种复杂类型是结构化类型。一个结构化类型允许多个不同类型的值组成一个类型。结构化类型需要提供一个schema结构信息作为参数来指明元素的结构。 Terraform支持两种结构化类型： object(...)：对象是指一组由具有名称和类型的属性所构成的符合类型，它的schema信息由{ \\=\\, \\=\\,...}的形式描述，例如object({age=number, name=string})，代表由名为\"age“类型为number，以及名为\"name\"类型为string两个属性组成的对象。赋给object类型的合法值必须含有所有属性值，但是可以拥有多余的属性(多余的属性在赋值时会被抛弃)。例如对于object({age=number,name=string})来说，{ age=18 } 是一个非法值，而{ age=18, name=\"john\", gender=\"male\" } 是一个合法值，但赋值时gender会被抛弃 tuple(...)：元组类似list，也是一组值的连续集合，但每个元素都有独立的类型。元组同list一样，也可以用下标访问内部元素，下标从0开始。元组schema用[\\, \\, ...]的形式描述。元组的元素数量必须与schema声明的类型数量相等，并且每个元素的类型必须与元组schema相应位置的类型相等。例如，tuple([string, number, bool])类型的一个合法值可以是[\"a\", 15, true] 复杂类型也支持隐式类型转换。 Terraform会尝试转换相似的类型，转换规则有： object和map：如果一个map的键集合含有object规定的所有属性，那么map可以被转换为object，map里多余的键值对会被抛弃。由map -> object -> map的转换可能会丢失数据。 tuple和list：当一个list元素的数量正好等于一个tuple声明的长度时，list可以被转换为tuple。例如：值为[\"18\", \"true\", \"john\"]的list转换为tuple([number,bool, string])的结果为[18, true, \"john\"] set和tuple：当一个list或是tuple被转换为一个set，那么重复的值将被丢弃，并且值原有的顺序也将丢失。如果一个set被转换到list或是tuple，那么元素将按照以下顺序排列：如果set的元素是string，那么将按照字段顺序排列；其他类型的元素不承诺任何特定的排列顺序。 复杂类型转换时，元素类型将在可能的情况下发生隐式转换，类似上述list到tuple转换举的例子。 如果类型不匹配，Terraform会报错，例如我们试图把object({name = [\"Kristy\", \"Claudia\", \"Mary Anne\", \"Stacey\"], age = 12})转换到map(string)类型，这是不合法的，因为name的值为list，无法转换为string。 any any是Terraform中非常特殊的一种类型约束，它本身并非一个类型，而只是一个占位符。每当一个值被赋予一个由any约束的复杂类型时，Terraform会尝试计算出一个最精确的类型来取代any。 例如我们把[\"a\", \"b\", \"c\"]赋给list(any)，它在Terraform中实际的物理类型首先被编译成tuple([string, string, string])，然后Terraform认为tuple和list相似，所以会尝试将它转换为list(string)。然后Terraform发现list(string)符合list(any)的约束，所以会用string取代any，于是赋值后最终的类型是list(string)。 由于即使是list(any)，所有元素的类型也必须是一样的，所以某些类型转换到list(any)时会对元素进行隐式类型转换。例如将[\"a\", 1, \"b\"]赋给list(any)，Terraform发现1可以转换到\"1\"，所以最终的值是[\"a\", \"1\", \"b\"]，最终的类型会是list(string)。再比如我们想把[\"a\", \\[\\], \"b\"]转换成list(any)，由于Terraform无法找到一个一个合适的目标类型使得所有元素都能成功隐式转换过去，所以Terraform会报错，要求所有元素都必须是同一个类型的。 声明类型时如果不想有任何的约束，那么可以用any： variable \"no_type_constraint\" { type = any } 这样的话，Terraform可以将任何类型的数据赋予它。 null 存在一种特殊值是无类型的，那就是null。null代表数据缺失。如果我们把一个参数设置为null，Terraform会认为你忘记为它赋值。如果该参数有默认值，那么Terraform会使用默认值；如果没有又恰巧该参数是必填字短，Terraform会报错。null在条件表达式中非常有用，你可以在某项条件不满足时跳过对某参数的赋值。 "},"3.2.配置语法.html":{"url":"3.2.配置语法.html","title":"配置语法","keywords":"","body":"配置语法 这里讲的仍然是HCL的语法，但我们只讲一些关键语法。如果读者有兴趣了解完整信息可以访问HCL语法规约 参数 参数赋值就是将一个值赋给一个特定的名称： image_id = \"abc123\" 等号前的标识符就是参数名，等号后的表达式就是参数值。参数赋值时Terraform会检查类型是否匹配。参数名是确定的，参数值可以是确定的字面量硬编码，也可以是一组表达式，用以通过其他的值加以计算得出结果值。 块 一个块是包含一组其他内容的容器，例如： resource \"aws_instance\" \"example\" { ami = \"abc123\" network_interface { # ... } } 一个块有一个类型(上面的例子里类型就是resource)。每个块类型都定义了类型关键字后面要跟多少标签，例如resource块规定了后面要跟两个标签——在例子里就是aws_instance和example。一个块类型可以规定任意多个标签，也可以没有标签，比如内嵌的network_interface块。 在块类型及其后续标签之后，就是块体。块体必须被包含在一对花括号中间。在块体中可以进一步定义各种参数和其他的块。 Terraform规范定义了有限多个顶级块类型，也就是可以游离于任何其他块独立定义在配置文件中的块。大部分的Terraform功能(例如resource, variable, output, data等)都是顶级块。 标识符 参数名、块类型名以及其他Terraform规范中定义的结构的名称，例如resource、variable等，都是标识符。 合法的标识符可以包含字母、数字、下划线(_)以及减号(-)。标识符首字母不可以为数字。 要了解完整的标识符规范，请访问Unicode标识符语法。 注释 Terraform支持三种注释： # 单行注释，其后的内容为注释 // 单行注释，其后的内容为注释 /* 和 */，多行注释，可以注释多行 默认情况下单行注释优先使用#。自动化格式整理工具会自动把//替换成#。 编码以及换行 Terraform配置文件必须始终使用UTF-8编码。分隔符必须使用ASCII符号，其他标识符、注释以及字符串字面量均可使用非ASCII字符。 Terraform兼容Unix风格的换行符以及Windows风格的换行符，但是理想状态下应使用Unix风格换行符。 "},"3.3.输入变量.html":{"url":"3.3.输入变量.html","title":"输入变量","keywords":"","body":"输入变量 在前面的例子中，我们在代码中都是使用字面量硬编码的，如果我们想要在创建、修改基础设施时动态传入一些值呢？比如说在代码中定义Provider时用变量替代硬编码的访问密钥，或是由创建基础设施的用户来决定创建什么样尺寸的主机？我们需要的是输入变量。 如果我们把一组Terraform代码想像成一个函数，那么输入变量就是函数的入参。输入变量用variable块进行定义： variable \"image_id\" { type = string } variable \"availability_zone_names\" { type = list(string) default = [\"us-west-1a\"] } variable \"docker_ports\" { type = list(object({ internal = number external = number protocol = string })) default = [ { internal = 8300 external = 8300 protocol = \"tcp\" } ] } 这些都是合法的输入参数定义。紧跟variable关键字的就是变量名。在一个Terraform模块(同一个文件夹中的所有Terraform代码文件，不包含子文件夹)中变量名必须是唯一的。我们在代码中可以通过var.的方式引用变量的值。有一组关键字不可以被用作输入变量的名字： source version providers count for_each lifecycle depends_on locals 输入变量只能在声明该变量的目录下的代码中使用。 输入变量块中可以定义一些属性。 类型 可以在输入变量块中通过type定义类型，例如： variable \"name\" { type = string } variable \"ports\" { type = list(number) } 定义了类型的输入变量只能被赋予符合类型约束的值。 默认值 默认值定义了当Terraform无法获得一个输入变量得到值的时候会使用的默认值。例如： variable \"name\" { type = string default = \"John Doe\" } 当Terraform无法通过其他途径获得name的值时，var.name的值为\"John Doe\"。 描述 可以在输入变量中定义一个描述，简单地向调用者描述该变量的意义和用法： variable \"image_id\" { type = string description = \"The id of the machine image (AMI) to use for the server.\" } 如果在执行terraform plan或是terraform apply时Terraform不知道某个输入变量的值，Terraform会在命令行界面上提示我们为输入变量设置一个值。例如上面的输入变量代码，执行terraform apply时： $ terraform apply var.image_id The id of the machine image (AMI) to use for the server. Enter a value: 为了使的代码的使用者能够准确理解输入变量的意义和用法，我们应该站在使用者而非代码维护者的角度编写输入变量的描述。描述并不是注释！ 断言 输入变量的断言是Terraform 0.13.0开始引入的新功能，在过去，Terraform只能用类型约束确保输入参数的类型是正确的，曾经有不少人试图通过奇技淫巧来实现更加复杂的变量校验断言。如今Terraform终于正式添加了相关的功能。 variable \"image_id\" { type = string description = \"The id of the machine image (AMI) to use for the server.\" validation { condition = length(var.image_id) > 4 && substr(var.image_id, 0, 4) == \"ami-\" error_message = \"The image_id value must be a valid AMI id, starting with \\\"ami-\\\".\" } } condition参数是一个bool类型的参数，我们可以用一个表达式来定义如何界定输入变量是合法的。当contidion为true时输入变量合法，反之不合法。condition表达式中只能通过var.\\引用当前定义的变量，并且它的计算不能产生错误。 假如表达式的计算产生一个错误是输入变量验证的一种判定手段，那么可以使用can函数来判定表达式的执行是否抛错。例如： variable \"image_id\" { type = string description = \"The id of the machine image (AMI) to use for the server.\" validation { # regex(...) fails if it cannot find a match condition = can(regex(\"^ami-\", var.image_id)) error_message = \"The image_id value must be a valid AMI id, starting with \\\"ami-\\\".\" } } 上述例子中，如果输入的image_id不符合正则表达式的要求，那么regex函数调用会抛出一个错误，这个错误会被can函数捕获，输出false。 condition表达式如果为false，Terraform会返回error_message中定义的错误信息。error_message应该完整描述输入变量校验失败的原因，以及输入变量的合法约束条件。 在命令行输出中隐藏值 该功能于 Terraofrm v0.14.0 开始引入。 将变量设置为 sensitive 可以防止我们在配置文件中使用变量时 Terraform 在 plan 和 apply 命令的输出中展示与变量相关的值。 Terraform 仍然会将敏感数据记录在状态文件中，任何可以访问状态文件的人都可以读取到明文的敏感数据值。 声明一个变量包含敏感数据值需要将 sensitive 参数设置为 true： variable \"user_information\" { type = object({ name = string address = string }) sensitive = true } resource \"some_resource\" \"a\" { name = var.user_information.name address = var.user_information.address } 任何使用了敏感变量的表达式都将被视为敏感的，因此在上面的示例中，resource “some_resource” “a”的两个参数也将在计划输出中被隐藏： Terraform will perform the following actions: # some_resource.a will be created + resource \"some_resource\" \"a\" { + name = (sensitive) + address = (sensitive) } Plan: 1 to add, 0 to change, 0 to destroy. 在某些情况下，我们会在嵌套块中使用敏感变量，Terraform 可能会将整个块视为敏感的。这发生在那些包含有要求值是唯一的内嵌块的资源中，公开这种内嵌块的部分内容可能会暗示兄弟块的内容。 # some_resource.a will be updated in-place ~ resource \"some_resource\" \"a\" { ~ nested_block { # At least one attribute in this block is (or was) sensitive, # so its contents will not be displayed. } } Provider 还可以将资源属性声明为敏感属性，这将导致 Terraform 将其从常规输出中隐藏。 如果打算使用敏感值作为输出值的一部分，Terraform 将要求您将输出值本身标记为敏感值，以确认确实打算将其导出。 Terraform 可能暴露敏感变量的情况 sensitive 变量是一个以配置文件为中心的概念，值被毫无混淆地发送给 Provider。如果该值被包含在错误消息中，则 Provider 报错时可能会暴露该值。例如，即使 “foo” 是敏感值，Provider 也可能返回以下错误：\"Invalid value 'foo' for field\" 如果将资源属性用作、或是作为 Provider 定义的资源 ID 的一部分，则 apply 将公开该值。在下面的示例中，前缀属性已设置为 sensitive 变量，但随后该值（“jae”）作为资源 ID 的一部分公开： # random_pet.animal will be created + resource \"random_pet\" \"animal\" { + id = (known after apply) + length = 2 + prefix = (sensitive) + separator = \"-\" } Plan: 1 to add, 0 to change, 0 to destroy. ... random_pet.animal: Creating... random_pet.animal: Creation complete after 0s [id=jae-known-mongoose] 禁止输入变量为空 该功能自 Terraform v1.1.0 开始被引入 输入变量的 nullable 参数控制模块调用者是否可以将 null 分配给变量。 variable \"example\" { type = string nullable = false } nullable 的默认值为 true。当 nullable 为 true 时，null 是变量的有效值，并且模块代码必须始终考虑变量值为 null 的可能性。将 null 作为模块输入参数传递将覆盖输入变量上定义的默认值。 将 nullable 设置为 false 可确保变量值在模块内永远不会为空。如果 nullable 为 false 并且输入变量定义有默认值，则当模块输入参数为 null 时，Terraform 将使用默认值。 nullable 参数仅控制变量的直接值可能为 null 的情况。对于集合或对象类型的变量，例如列表或对象，调用者仍然可以在集合元素或属性中使用 null，只要集合或对象本身不为 null。 对输入变量赋值 命令行参数 对输入变量赋值有几种途径，一种是在调用terraform plan或是terraform apply命令时以参数的形式传入： $ terraform apply -var=\"image_id=ami-abc123\" $ terraform apply -var='image_id_list=[\"ami-abc123\",\"ami-def456\"]' $ terraform plan -var='image_id_map={\"us-east-1\":\"ami-abc123\",\"us-east-2\":\"ami-def456\"}' 可以在一条命令中使用多个-var参数。 参数文件 第二种方法是使用参数文件。参数文件的后缀名可以是.tfvars或是.tfvars.json。.tfvars文件使用HCL语法，.tfvars.json使用JSON语法。 以.tfvars为例，参数文件中用HCL代码对需要赋值的参数进行赋值，例如： image_id = \"ami-abc123\" availability_zone_names = [ \"us-east-1a\", \"us-west-1c\", ] 后缀名为.tfvars.json的文件用一个JSON对象来对输入变量赋值，例如： { \"image_id\": \"ami-abc123\", \"availability_zone_names\": [\"us-west-1a\", \"us-west-1c\"] } 调用terraform命令时，通过-var-file参数指定要用的参数文件，例如： terraform apply -var-file=\"testing.tfvars\" terraform apply -var-file=\"testing.tfvars.json\" 有两种情况，你无需指定参数文件： 当前模块内有名为terraform.tfvars或是terraform.tfvars.json的文件 当前模块内有一个或多个后缀名为.auto.tfvars或是.auto.tfvars.json的文件 Terraform会自动使用这两种自动参数文件对输入参数赋值。 环境变量 可以通过设置名为TF_VAR_的环境变量为输入变量赋值，例如： $ export TF_VAR_image_id=ami-abc123 $ terraform plan ... 在环境变量名大小写敏感的操作系统上，Terraform要求环境变量中的\\与Terraform代码中定义的输入变量名大小写完全一致。 环境变量传值非常适合在自动化流水线中使用，尤其适合用来传递敏感数据，类似密码、访问密钥等。 交互界面传值 在前面介绍断言的例子中我们看到过，当我们从命令行界面执行terraform操作，Terraform无法通过其他途径获取一个输入变量的值，而该变量也没有定义默认值时，Terraform会进行最后的尝试，在交互界面上要求我们给出变量值。 输入变量赋值优先级 当上述的赋值方式同时存在时，同一个变量可能会被赋值多次。Terraform会使用新值覆盖旧值。 Terraform加载变量值的顺序是： 环境变量 terraform.tfvars文件(如果存在的话) terraform.tfvars.json文件(如果存在的话) 所有的.auto.tfvars或者.auto.tfvars.json文件，以字母顺序排序处理 通过-var或是-var-file命令行参数传递的输入变量，按照在命令行参数中定义的顺序加载 假如以上方式均未能成功对变量赋值，那么Terraform会尝试使用默认值；对于没有定义默认值的变量，Terraform会采用交互界面方式要求用户输入一个。对于某些Terraform命令，如果执行时带有-input=false参数禁用了交互界面传值方式，那么就会报错。 复杂类型传值 通过参数文件传值时，可以直接使用HCL或是JSON语法对复杂类型传值，例如list或map。 对于某些场景下必须使用-var命令行参数，或是环境变量传值时，可以用单引号引用HCL语法的字面量来定义复杂类型，例如： export TF_VAR_availability_zone_names='[\"us-west-1b\",\"us-west-1d\"]' 由于采用这种方法需要手工处理引号的转义，所以这种方法比较容易出错，复杂类型的传值建议尽量通过参数文件。 "},"3.4.输出值.html":{"url":"3.4.输出值.html","title":"输出值","keywords":"","body":"输出值 我们在介绍输入变量时提到过，如果我们把一组Terraform代码想像成一个函数，那么输入变量就是函数的入参；函数可以有入参，也可以有返回值，同样的，Terraform代码也可以有返回值，这就是输出值。 大部分语言的的函数只支持无返回值或是单返回值，但是Terraform支持多返回值。在当前模块apply一段Terraform代码，运行成功后命令行会输出代码中定义的返回值。另外我们也可以通过terraform output命令来输出当前模块对应的状态文件中的返回值。 输出值的声明 输出值的声明使用输出块，例如： output \"instance_ip_addr\" { value = aws_instance.server.private_ip } output关键字后紧跟的就是输出值的名称。在当前模块内的所有输出值的名字都必须是唯一的。output块内的value参数即为输出值，它可以像是上面的例子里那样某个resource的输出属性，也可以是任意合法的表达式。 输出值只有在执行terraform apply后才会被计算，光是使用terraform plan并不会计算输出值。 Terraform代码中无法引用本目录下定义的输出值。 output块还有一些可选的属性： description output \"instance_ip_addr\" { value = aws_instance.server.private_ip description = \"The private IP address of the main server instance.\" } 与输入变量的description类似，我们不再赘述。 sensitive 一个输出值可以标记sensitive为true，表示该输出值含有敏感信息。被标记sensitive的输出值只是在执行terraform apply命令成功后会打印\"\\\"以取代真实的输出值，执行terraform output时也会输出\"\\\"，但仍然可以通过执行terraform output -json看到实际的敏感值。 需要注意的是，标记为sensitive输出值仍然会被记录在状态文件中，任何有权限读取状态文件的人仍然可以读取到敏感数据。 depends_on 关于depends_on的内容将在resource章节里详细介绍，所以这里我们只是粗略地介绍一下。 Terraform会解析代码所定义的各种data、resource，以及他们之间的依赖关系，例如，创建虚拟机时用的image_id参数是通过data查询而来的，那么虚拟机实例就依赖于这个镜像的data，Terraform会首先创建data，得到查询结果后，再创建虚拟机resource。一般来说，data、resource之间的创建顺序是由Terraform自动计算的，不需要代码的编写者显式指定。但有时有些依赖关系无法通过分析代码得出，这时我们可以在代码中通过depends_on显式声明依赖关系。 一般output很少会需要显式依赖某些资源，但有一些特殊场景，例如在当前代码中调用一个模块(可以理解成调用另一个目录中的Terraform代码创建一些资源)时，调用者希望在模块资源全部创建完毕以后才继续后续的创建工作，这时我们可以为模块设计一个output，通过depends_on显式声明依赖关系，以确保该output必须在所有模块资源成功创建以后才能被读取，这样我们就可以在模块尺度上控制资源的创建顺序。 depends_on的用法如下： output \"instance_ip_addr\" { value = aws_instance.server.private_ip description = \"The private IP address of the main server instance.\" depends_on = [ # Security group rule must be created before this IP address could # actually be used, otherwise the services will be unreachable. aws_security_group_rule.local_access, ] } 我们不鼓励针对output定义depends_on，只能作为最后的手段加以应用。如果不得不针对output定义depends_on，请务必通过注释说明原因，方便后人进行维护。 "},"3.5.局部值.html":{"url":"3.5.局部值.html","title":"局部值","keywords":"","body":"局部值 有时我们会需要用一个比较复杂的表达式计算某一个值，并且反复使用之，这时我们把这个复杂表达式赋予一个局部值，然后反复引用该局部值。如果说输入变量相当于函数的入参，输出值相当于函数的返回值，那么局部值就相当于函数内定义的局部变量。 局部值通过locals块定义，例如： locals { service_name = \"forum\" owner = \"Community Team\" } 一个locals块可以定义多个局部值，也可以定义任意多个locals块。赋给局部值的可以是更复杂的表达式，也可以是其他data、resource的输出、输入变量，甚至是其他的局部值： locals { # Ids for multiple sets of EC2 instances, merged together instance_ids = concat(aws_instance.blue.*.id, aws_instance.green.*.id) } locals { # Common tags to be assigned to all resources common_tags = { Service = local.service_name Owner = local.owner } } 引用局部值的表达式是local.(注意，虽然局部值定义在locals块内，但引用是务必使用local而不是locals)，例如： resource \"aws_instance\" \"example\" { # ... tags = local.common_tags } 局部值只能在同一模块内的代码中引用。 局部值可以帮助我们避免重复复杂的表达式，提升代码的可读性，但如果过度使用也有可能增加代码的复杂度，使得代码的维护者更难理解所使用的表达式和值。适度使用局部值，仅用于反复引用同一复杂表达式的场景，未来当我们需要修改该表达式时局部值将使得修改变得相当轻松。 "},"3.6.资源.html":{"url":"3.6.资源.html","title":"资源","keywords":"","body":"资源 资源是Terraform最重要的组成部分，而本节亦是本教程最重要的一节。资源通过resource块来定义，一个resource可以定义一个或多个基础设施资源对象，例如VPC、虚拟机，或是DNS记录、Consul的键值对数据等。 资源语法 资源通过resource块定义，我们首先讲解通过resource块定义单个资源对象的场景。 resource \"aws_instance\" \"web\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" } 紧跟resource关键字的是资源类型，在上面的例子里就是aws_instance。后面是资源的Local Name，例子里就是web。Local Name可以在同一模块内的代码里被用来引用该资源，但类型加Local Name的组合在当前模块内必须是唯一的，不同类型的两个资源Local Name可以相同。随后的花括号内的内容就是块体，创建资源所用到的各种参数的值就在块体内定义。例子中我们定义了虚拟机所使用的镜像id以及虚拟机的尺寸。 资源参数 不同资源定义了不同的可赋值的属性，官方文档将之称为参数(Argument)，有些参数是必填的，有些参数是可选的。使用某项资源前可以通过阅读相关文档了解参数列表以及他们的含义、赋值的约束条件。 参数值可以是简单的字面量，也可以是一个复杂的表达式。 资源类型的文档 每一个Terraform Provider都有自己的文档，用以描述它所支持的资源类型种类，以及每种资源类型所支持的属性列表。 大部分公共的Provider都是通过Terraform Registry连带文档一起发布的。当我们在Terraform Registry站点上浏览一个Provider的页面时，我们可以点击\"Documentation\"链接来浏览相关文档。Provider的文档都是版本化的，我们可以选择特定版本的Provider文档。 需要注意的是，Provider文档曾经是直接托管在terraform.io站点上的，也就是Terraform核心主站的一部分，有些Provider的文档目前依然托管在那里，但目前Terraform Rregistry才是所有公共Provider文档的主站(唯一的例外是用来读取其他Terraform状态数据的内建的terraform provider，它的文档目前不在Terraform Registry上)。 资源的行为 一个resource块声明了作者想要创建的一个确切的基础设施对象，并且设定了各项属性的值。如果我们正在编写一个新的Terraform代码文件，那么代码所定义的资源仅仅只在代码中存在，并没有与之对应的实际的基础设施资源存在。 对一组Terraform代码执行terraform apply可以创建、更新或者销毁实际的基础设施对象，Terraform会制定并执行变更计划，以使得实际的基础设施符合代码的定义。 每当Terraform按照一个resource块创建了一个新的基础设施对象，这个实际的对象的id会被保存进Terraform状态中，使得将来Terraform可以根据变更计划对它进行更新或是销毁操作。如果一个resource块描述的资源在状态文件中已有记录，那么Terraform会比对记录的状态与代码描述的状态，如果有必要，Terraform会制定变更计划以使得资源状态能够符合代码的描述。 这种行为适用于所有资源而无关其类型。创建、更新、销毁一个资源的细节会根据资源类型而不同，但是这个行为规则却是普适的。 访问资源输出属性 资源不但可以通过参数传值，成功创建的资源还对外输出一些通过调用API才能获得的只读数据，经常包含了一些我们在实际创建一个资源之前无法获知的数据，比如云主机的id等，官方文档将之称为属性(Attribute)。我们可以在同一模块内的代码中引用资源的属性来创建其他资源或是表达式。在表达式中引用资源属性的语法是..。 要获取一个资源类型输出的属性列表，我们可以查阅对应的Provider文档，一般在文档中会专门记录资源的输出属性列表。 敏感的资源属性 在为资源类型定义架构时，Provider 开发着可以将某些属性标记为 sensitive，在这种情况下，Terraform 将在展示涉及该属性的计划时显示占位符标记(sensitive) 而不是实际值。 标记为 sensitive 的 Provider 属性的行为类似于声明为 sensitive 的输入变量，Terraform 将隐藏计划中的值，还将隐藏从该值派生出的任何其他敏感值。但是，该行为存在一些限制，如 Terraform 可能暴露敏感变量。 如果使用资源属性中的敏感值作为输出值的一部分，Terraform 将要求将输出值本身标记为 sensitive，以确认确实打算将其导出。 Terraform 仍会在状态中记录敏感值，因此任何可以访问状态数据的人都可以以明文形式访问敏感值。 注意：Terraform 从 v0.15 开始将从敏感资源属性派生的值视为敏感值本身。早期版本的 Terraform 将隐藏敏感资源属性的直接值，但不会自动隐藏从敏感资源属性派生的其他值。 资源的依赖关系 我们在介绍输出值的depends_on的时候已经简单介绍过了依赖关系。一般来说在Terraform代码定义的资源之间不会有特定的依赖关系，Terraform可以并行地对多个无依赖关系的资源执行变更，默认情况下这个并行度是10。 然而，创建某些资源所需要的信息依赖于另一个资源创建后输出的属性，又或者必须在某些资源成功创建后才可以被创建，这时资源之间就存在依赖关系。 大部分资源间的依赖关系可以被Terraform自动处理，Terraform会分析resource块内的表达式，根据表达式的引用链来确定资源之间的引用，进而计算出资源在创建、更新、销毁时的执行顺序。大部分情况下，我们不需要显式指定资源之间的依赖关系。 然而，有时候某些依赖关系是无法从代码中推导出来的。例如，Terraform必须要创建一个访问控制权限资源，以及另一个需要该权限才能成功创建的资源。后者的创建依赖于前者的成功创建，然而这种依赖在代码中没有表现为数据引用关联，这种情况下，我们需要用depends_on来显式声明这种依赖关系。 元参数 resource块支持几种元参数声明，这些元参数可以被声明在所有类型的resource块内，它们将会改变资源的行为： depends_on：显式声明依赖关系 count：创建多个资源实例 for_each：迭代集合，为集合中每一个元素创建一个对应的资源实例 provider：指定非默认Provider实例 lifecycle：自定义资源的生命周期行为 provisioner 和 connection：在资源创建后执行一些额外的操作 下面我们将逐一讲解他们的用法。 depends_on 使用depends_on可以显式声明资源之间哪些Terraform无法自动推导出的隐含的依赖关系。只有当资源间确实存在依赖关系，但是彼此间又没有数据引用的场景下才有必要使用depends_on。 使用depends_on的例子是这样的： resource \"aws_iam_role\" \"example\" { name = \"example\" # assume_role_policy is omitted for brevity in this example. See the # documentation for aws_iam_role for a complete example. assume_role_policy = \"...\" } resource \"aws_iam_instance_profile\" \"example\" { # Because this expression refers to the role, Terraform can infer # automatically that the role must be created first. role = aws_iam_role.example.name } resource \"aws_iam_role_policy\" \"example\" { name = \"example\" role = aws_iam_role.example.name policy = jsonencode({ \"Statement\" = [{ # This policy allows software running on the EC2 instance to # access the S3 API. \"Action\" = \"s3:*\", \"Effect\" = \"Allow\", }], }) } resource \"aws_instance\" \"example\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" # Terraform can infer from this that the instance profile must # be created before the EC2 instance. iam_instance_profile = aws_iam_instance_profile.example # However, if software running in this EC2 instance needs access # to the S3 API in order to boot properly, there is also a \"hidden\" # dependency on the aws_iam_role_policy that Terraform cannot # automatically infer, so it must be declared explicitly: depends_on = [ aws_iam_role_policy.example, ] } 我们来分段解释一下这个场景，首先我们声明了一个AWS IAM角色，将角色绑定在一个主机实例配置文件上： resource \"aws_iam_role\" \"example\" { name = \"example\" # assume_role_policy is omitted for brevity in this example. See the # documentation for aws_iam_role for a complete example. assume_role_policy = \"...\" } resource \"aws_iam_instance_profile\" \"example\" { # Because this expression refers to the role, Terraform can infer # automatically that the role must be created first. role = aws_iam_role.example.name } 虚拟机的声明代码中的这个赋值使得Terraform能够判断出虚拟机依赖于主机实例配置文件： resource \"aws_instance\" \"example\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" # Terraform can infer from this that the instance profile must # be created before the EC2 instance. iam_instance_profile = aws_iam_instance_profile.example 至此，Terraform规划出的创建顺序是IAM角色->主机实例配置文件->主机实例。但是我们又为这个IAM角色添加了对S3存储服务的完全控制权限： resource \"aws_iam_role_policy\" \"example\" { name = \"example\" role = aws_iam_role.example.name policy = jsonencode({ \"Statement\" = [{ # This policy allows software running on the EC2 instance to # access the S3 API. \"Action\" = \"s3:*\", \"Effect\" = \"Allow\", }], }) } 也就是说，虚拟机实例由于绑定了主机实例配置文件，从而在运行时拥有了一个IAM角色，而这个IAM角色又被赋予了S3的权限。但是虚拟机实例的声明代码中并没有引用S3权限的任何输出属性，这将导致Terraform无法理解他们之间存在依赖关系，进而可能会并行地创建两者，如果虚拟机实例被先创建了出来，内部的程序开始运行时，它所需要的S3权限却还没有创建完成，那么就将导致程序运行错误。为了确保虚拟机创建时S3权限一定已经存在，我们可以用depends_on显式声明它们的依赖关系： # However, if software running in this EC2 instance needs access # to the S3 API in order to boot properly, there is also a \"hidden\" # dependency on the aws_iam_role_policy that Terraform cannot # automatically infer, so it must be declared explicitly: depends_on = [ aws_iam_role_policy.example, ] depends_on的赋值必须是包含同一模块内声明的其他资源名称的列表，不允许包含其他表达式，例如不允许使用其他资源的输出属性，这是因为Terraform必须在计算资源间关系之前就能理解列表中的值，为了能够安全地完成表达式计算，所以限制只能使用资源实例的名称。 depends_on只能作为最后的手段使用，如果我们使用depends_on，我们应该用注释记录我们使用它的原因，以便今后代码的维护者能够理解隐藏的依赖关系。 count 一般来说，一个resource块定义了一个对应的实际基础设施资源对象。但是有时候我们希望创建多个相似的对象，比如创建一组虚拟机。Terraform提供了两种方法实现这个目标：count与for_each。 count参数可以是任意自然数，Terraform会创建count个资源实例，每一个实例都对应了一个独立的基础设施对象，并且在执行Terraform代码时，这些对象是被分别创建、更新或者销毁的： resource \"aws_instance\" \"server\" { count = 4 # create four similar EC2 instances ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" tags = { Name = \"Server ${count.index}\" } } 我们可以在resource块中的表达式里使用count对象来获取当前的count索引号。count对象只有一个属性： count.index：代表当前对象对应的count下标索引(从0开始) 如果一个resource块定义了count参数，那么Terraform会把这种多资源实例对象与没有count参数的单资源实例对象区别开： 访问单资源实例对象：.(例如：aws_instance.server) 访问多资源实例对象：.[] (例如：aws_instance.server[0]，aws_instance.server[1]) 声明了count或for_each的资源必须使用下标索引或者键来访问。 count参数可以是任意自然数，然而与resource的其他参数不同，count的值在Terraform进行任何远程资源操作(实际的增删改查)之前必须是已知的，这也就意味着赋予count参数的表达式不可以引用任何其他资源的输出属性(例如由其他资源对象创建时返回的一个唯一的ID)。count的表达式中可以引用来自data返回的输出属性，只要该data可以不依赖任何其他resource进行查询。 for_each for_each是Terraform 0.12.6开始引入的新特性。一个resource块不允许同时声明count与for_each。for_each参数可以是一个map或是一个set(string)，Terraform会为集合中每一个元素都创建一个独立的基础设施资源对象，和count一样，每一个基础设施资源对象在执行Terraform代码时都是独立创建、修改、销毁的。 使用map的例子： resource \"azurerm_resource_group\" \"rg\" { for_each = { a_group = \"eastus\" another_group = \"westus2\" } name = each.key location = each.value } 使用set(string)的例子： resource \"aws_iam_user\" \"the-accounts\" { for_each = toset( [\"Todd\", \"James\", \"Alice\", \"Dottie\"] ) name = each.key } 我们可以在声明了for_each参数的resource块内使用each对象来访问当前的迭代器对象： each.key：map的键，或是set中的值 each.value：map的值，或是set中的值 如果for_each的值是一个set，那么each.key和each.value是相等的。 使用for_each时，map的所有键、set的所有string值都必须是已知的，也就是状态文件中已有记录的值。所以有时候我们可能需要在执行terraform apply时添加-target参数，实现分步创建。另外，for_each所使用的键集合不能够包含或依赖非纯函数，也就是反复执行会返回不同返回值的函数，例如uuid、bcrypt、timestamp等。 当一个resource声明了for_each时，Terraform会把这种多资源实例对象与没有count参数的单资源实例对象区别开： 访问单资源实例对象：.(例如：aws_instance.server) 访问多资源实例对象：.[] (例如：aws_instance.server[\"ap-northeast-1\"]，aws_instance.server[\"ap-northeast-2\"]) 声明了count或for_each的资源必须使用下标索引或者键来访问。 由于Terraform没有用以声明set的字面量，所以我们有时需要使用toset函数把list(string)转换为set(string)： locals { subnet_ids = toset([ \"subnet-abcdef\", \"subnet-012345\", ]) } resource \"aws_instance\" \"server\" { for_each = local.subnet_ids ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" subnet_id = each.key # note: each.key and each.value are the same for a set tags = { Name = \"Server ${each.key}\" } } 在这里我们用toset把一个list(string)转换成了set(string)，然后赋予for_each。在转换过程中，list中所有重复的元素会被抛弃，只剩下不重复的元素，例如toset([\"b\", \"a\", \"b\"])的结果只有\"a\"和\"b\"，并且set的元素没有特定顺序。 如果我们要把一个输入变量赋予for_each，我们可以直接定义变量的类型约束来避免显式调用toset转换类型： variable \"subnet_ids\" { type = set(string) } resource \"aws_instance\" \"server\" { for_each = var.subnet_ids # (and the other arguments as above) } 在for_each和count之间选择 如果创建的资源实例彼此之间几乎完全一致，那么count比较合适。如果彼此之间的参数差异无法直接从count的下标派生，那么使用for_each会更加安全。 在Terraform引入for_each之前，我们经常使用count.index搭配length函数和list来创建多个资源实例： variable \"subnet_ids\" { type = list(string) } resource \"aws_instance\" \"server\" { # Create one instance for each subnet count = length(var.subnet_ids) ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" subnet_id = var.subnet_ids[count.index] tags = { Name = \"Server ${count.index}\" } } 这种实现方法是脆弱的，因为资源仍然是以他们的下标而不是实际的string值来区分的。如果我们从subnet_ids列表的中间移除了一个元素，那么从该位置起后续所有的aws_instance都会发现它们的subnet_id发生了变化，结果就是所有后续的aws_instance都需要更新。这种场景下如果使用for_each就更为妥当，如果使用for_each，那么只有被移除的subnet_id对应的aws_instance会被销毁。 provider 关于provider的定义我们在前面介绍Provider的章节已经提到过了，如果我们声明了同一类型Provider的多个实例，那么我们在创建资源时可以通过指定provider参数选择要使用的Provider实例。如果没有指定provider参数，那么Terraform默认使用资源类型名中第一个单词所对应的Provider实例，例如google_compute_instance的默认Provider实例就是google，aws_instance的默认Provider就是aws。 指定provider参数的例子： # default configuration provider \"google\" { region = \"us-central1\" } # alternate configuration, whose alias is \"europe\" provider \"google\" { alias = \"europe\" region = \"europe-west1\" } resource \"google_compute_instance\" \"example\" { # This \"provider\" meta-argument selects the google provider # configuration whose alias is \"europe\", rather than the # default configuration. provider = google.europe # ... } provider参数期待的赋值是或是.，不需要双引号。因为在Terraform开始计算依赖路径图时，provider关系必须是已知的，所以除了这两种以外的表达式是不被接受的。 lifecycle 通常一个资源对象的生命周期在前面“资源的行为”一节中已经描述了，但是我们可以用lifecycle块来定一个不一样的行为方式，例如： resource \"azurerm_resource_group\" \"example\" { # ... lifecycle { create_before_destroy = true } } lifecycle块和它的内容都属于元参数，可以被声明于任意类型的资源块内部。Terraform支持如下几种lifecycle： create_before_destroy (bool)：默认情况下，当Terraform需要修改一个由于服务端API限制导致无法直接升级的资源时，Terraform会删除现有资源对象，然后用新的配置参数创建一个新的资源对象取代之。create_before_destroy参数可以修改这个行为，使得Terraform首先创建新对象，只有在新对象成功创建并取代老对象后再销毁老对象。这并不是默认的行为，因为许多基础设施资源需要有一个唯一的名字或是别的什么标识属性，在新老对象并存时也要符合这种约束。有些资源类型有特别的参数可以为每个对象名称添加一个随机的前缀以防止冲突。Terraform不能默认采用这种行为，所以在使用create_before_destroy前你必须了解每一种资源类型在这方面的约束。 prevent_destroy (bool)：这个参数是一个保险措施，只要它被设置为true时，Terraform会拒绝执行任何可能会销毁该基础设施资源的变更计划。这个参数可以预防意外删除关键资源，例如错误地执行了terraform destroy，或者是意外修改了资源的某个参数，导致Terraform决定删除并重建新的资源实例。在resource块内声明了prevent_destroy = true会导致无法执行terraform destroy，所以对它的使用要节制。需要注意的是，该措施无法防止我们删除resource块后Terraform删除相关资源，因为对应的prevent_destroy = true声明也被一并删除了。 ignore_changes (list(string))：默认情况下，Terraform检测到代码描述的配置与真实基础设施对象之间有任何差异时都会计算一个变更计划来更新基础设施对象，使之符合代码描述的状态。在一些非常罕见的场景下，实际的基础设施对象会被Terraform之外的流程所修改，这就会使得Terraform不停地尝试修改基础设施对象以弥合和代码之间的差异。这种情况下，我们可以通过设定ignore_changes来指示Terraform忽略某些属性的变更。ignore_changes的值定义了一组在创建时需要按照代码定义的值来创建，但在更新时不需要考虑值的变化的属性名，例如： resource \"aws_instance\" \"example\" { # ... lifecycle { ignore_changes = [ # Ignore changes to tags, e.g. because a management agent # updates these based on some ruleset managed elsewhere. tags, ] } } 你也可以忽略map中特定的元素，例如tags[\"Name\"]，但是要注意的是，如果你是想忽略map中特定元素的变更，那么你必须首先确保map中含有这个元素。如果一开始map中并没有这个键，而后外部系统添加了这个键，那么Terraform还是会把它当成一次变更来处理。比较好的方法是你在代码中先为这个键创建一个占位元素来确保这个键已经存在，这样在外部系统修改了键对应的值以后Terraform会忽略这个变更。 resource \"aws_instance\" \"example\" { # ... tags = { # Initial value for Name is overridden by our automatic scheduled # re-tagging process; changes to this are ignored by ignore_changes # below. Name = \"placeholder\" } lifecycle { ignore_changes = [ tags[\"Name\"], ] } } 除了使用一个list(string)，也可以使用关键字\"all\"，这时Terraform会忽略资源一切属性的变更，这样Terraform只会创建或销毁一个对象，但绝不会尝试更新一个对象。你只能在ignore_changes里忽略所属的resource的属性，ignore_changes不可以赋予它自身或是其他任何元参数。 lifecycle配置影响了Terraform如何构建并遍历依赖图。作为结果，lifecycle内赋值仅支持字面量，因为它的计算过程发生在Terraform计算的极早期。这就是说，例如prevent_destroy、create_before_destroy的值只能是true或者false，ignore_changes的列表内只能是硬编码的属性名。 provisioner和connection 某些基础设施对象需要在创建后执行特定的操作才能正式工作。比如说，主机实例必须在上传了配置或是由配置管理工具初始化之后才能正常工作。 像这样创建后执行的操作可以使用预置器(Provisioner)。预置器是由Terraform所提供的另一组插件，每种预置器可以在资源对象创建后执行不同类型的操作。 使用预置器需要节制，因为他们采取的操作并非Terraform声明式的风格，所以Terraform无法对他们执行的变更进行建模和保存。 预置器也可以声明为资源销毁前执行，但会有一些限制。 作为元参数，provisioner和connection可以声明在任意类型的resource块内。 举一个例子： resource \"aws_instance\" \"web\" { # ... provisioner \"file\" { source = \"conf/myapp.conf\" destination = \"/etc/myapp.conf\" connection { type = \"ssh\" user = \"root\" password = var.root_password host = self.public_ip } } } 我们在aws_instance中定义了类型为file的预置器，该预置器可以本机文件或文件夹拷贝到目标机器的指定路径下。我们在预置器内部定义了connection块，类型是ssh。我们对connection的host赋值self.public_ip，在这里self代表预置器所在的母块，也就是aws_instance.web，所以self.public_ip代表着aws_instance.web.public_ip，也就是创建出来的主机的公网ip。 file类型预置器支持ssh和winrm两种类型的connection。 预置器根据运行的时机分为两种类型，创建时预置器以及销毁时预置器。 创建时预置器 默认情况下，资源对象被创建时会运行预置器，在对象更新、销毁时则不会运行。预置器的默认行为时为了引导一个系统。 如果创建时预置器失败了，那么资源对象会被标记污点(我们将在介绍terraform taint命令时详细介绍)。一个被标记污点的资源在下次执行terraform apply命令时会被销毁并重建。Terrform的这种设计是因为当预置器运行失败时标志着资源处于半就绪的状态。由于Terraform无法衡量预置器的行为，所以唯一能够完全确保资源被正确初始化的方式就是删除重建。 我们可以通过设置on_failure参数来改变这种行为。 销毁时预置器 如果我们设置预置器的when参数为destroy，那么预置器会在资源被销毁时执行： resource \"aws_instance\" \"web\" { # ... provisioner \"local-exec\" { when = destroy command = \"echo 'Destroy-time provisioner'\" } } 销毁时预置器在资源被实际销毁前运行。如果运行失败，Terraform会报错，并在下次运行terraform apply操作时重新执行预置器。在这种情况下，需要仔细关注销毁时预置器以使之能够安全地反复执行。 销毁时预置器只有在存在于代码中的情况下才会在销毁时被执行。如果一个resource块连带内部的销毁时预置器块一起被从代码中删除，那么被删除的预置器在资源被销毁时不会被执行。要解决这个问题，我们需要使用多个步骤来绕过这个限制： 修改资源声明代码，添加count = 0参数 执行terraform apply，运行删除时预置器，然后删除资源实例 删除resource块 重新执行terraform apply，此时应该不会有任何变更需要执行 该限制在未来将会得到解决，但目前来说我们必须节制使用销毁时预置器。 预置器失败行为 默认情况下，预置器运行失败会导致terraform apply执行失败。可以通过设置on_failure参数来改变这一行为。可以设置的值为： continue：忽视错误，继续执行创建或是销毁 fail：报错并终止执行变更(这是默认行为)。如果这是一个创建时预置器，则在对应资源对象上标记污点 样例： resource \"aws_instance\" \"web\" { # ... provisioner \"local-exec\" { command = \"echo The server's IP address is ${self.private_ip}\" on_failure = continue } } 本地资源 虽然大部分资源类型都对应的是通过远程基础设施API控制的一个资源对象，但也有一些资源对象他们只存在于Terraform进程自身内部，用来计算生成某些结果，并将这些结果保存在状态中以备日后使用。 比如说，我们可以用tls_private_key生成公私钥，用tls_self_signed_cert生成自签名证书，或者是用random_id生成随机id。虽不像其他“真实”基础设施对象那般重要，但这些本地资源也可以成为连接其他资源有用的黏合剂。 本地资源的行为与其他类型资源是一致的，但是他们的结果数据仅存在于Terraform状态文件中。“销毁”这种资源只是将结果数据从状态中删除。 操作超时设置 有些资源类型提供了特殊的timeouts内嵌块参数，它允许我们配置我们允许操作持续多长时间，超时将被认定为失败。比如说，aws_db_instance资源允许我们分别为create，update，delete操作设置超时时间。 超时完全由资源对应的Provider来处理，但支持超时设置的Provider一般都遵循相同的传统，那就是由一个名为timeouts的嵌入块参数定义超时设置，timeouts块内可以分别设置不同操作的超时时间。超时时间由string描述，比如\"60m\"代表60分钟，\"10s\"代表10秒，\"2h\"代表2小时。 resource \"aws_db_instance\" \"example\" { # ... timeouts { create = \"60m\" delete = \"2h\" } } 可配置超时的操作类别由每种支持超时设定的资源类型自行决定。大部分资源类型不支持设置超时。使用超时前请先查阅相关文档。 "},"3.7.数据源.html":{"url":"3.7.数据源.html","title":"数据源","keywords":"","body":"数据源 数据源允许查询或计算一些数据以供其他地方使用。使用数据源可以使得Terraform代码使用在Terraform管理范围之外的一些信息，或者是读取其他Terraform代码保存的状态。 每一种Provider都可以在定义一些资源类型的同时定义一些数据源。 使用数据源 数据源通过一种特殊的资源访问：data资源。数据源通过data块声明： data \"aws_ami\" \"example\" { most_recent = true owners = [\"self\"] tags = { Name = \"app-server\" Tested = \"true\" } } 一个data块请求Terraform从一个指定的数据源aws_ami读取指定数据并且把结果输出到Local Name为example的实例中。我们可以在同一模块内的代码中通过数据源名称来引用数据源，但无法从模块外部直接访问数据源。 同资源类似，一个数据源类型以及它的名称一同构成了该数据源的标识符，所以数据源类型加名称的组合在同一模块内必须是唯一的。 在data块体(花括号中间的内容)是传给数据源的查询条件。查询条件参数的种类取决于数据源的类型，在上述例子中，most_recent、owners和tags都是定义查询aws_ami数据源时使用的查询条件。 与数据源这种特殊资源不同的是，我们在上一节介绍的主要资源(使用resource块定义的)是一种“托管资源”。这两种资源都可以接收参数并对外输出属性，但托管资源会触发Terraform对基础设施对象进行增删改操作，而数据源只会触发读取操作。简单来说，我们一般说的“资源”就是特指托管资源。 数据源参数 每一种数据源资源都关联到一种外部数据源，数据源类型决定了它接收的查询参数以及输出的数据。每一种数据源类型都属于一个Provider。大部分data块内的数据源参数都是由对应的数据源类型定义的，这些参数的赋值可以使用完整的Terraform表达式能力或其他Terraform语言的功能。 然而类似资源，Terraform也为所有类型的数据源定义了一些元参数。这些元参数的限制和功能我们将在后续节当中叙述。 数据源行为 如果数据源的查询参数涉及到的表达式只引用了字面量或是在执行terraform plan时就已知的数据(比如输入变量)，那么数据源会在执行Terraform的\"refersh\"阶段时被读取，然后Terraform会构建变更计划。这保证了在制定变更计划时Terraform可以使用这些数据源的返回数据。 如果查询参数的表达式引用了那些只有执行部分执行变更计划以后才能知晓的数据，比如另一个还未被创建的托管资源的输出，那么数据源的读取操作会被推迟到\"apply\"阶段，任何引用该数据源输出的表达式的值在执行到数据源被读取完之前都是未知的。 本地数据源 虽然绝大多数数据源都对应了一个通过远程基础设施API访问的外部数据源，但是也有一些特殊的数据源仅存在于Terraform进程内部，计算并对外输出一些数据。 比如说，本地数据源有template_file、local_file、aws_iam_policy_document等。 本地数据源的行为与其他数据源完全一致，但他们输出的结果数据只是临时存在于Terraform运行时，每次计算一个新的变更计划时这些值都会被重新计算。 数据源的依赖关系 数据源有着与资源一样的依赖机制，我们也可以在data块内设置depends_on元参数来显式声明依赖关系，在此不再赘述。 多数据源实例 与资源一样，数据源也可以通过设置count、for_each元参数来创建一组多个数据源实例，并且Terraform也会把每个数据源实例单独创建并读取相应的外部数据，对count.index与each的使用也是一样的，在count与for_each之间选择的原则也是一样的。 指定特定Provider实例 同资源一样，数据源也可以通过provider元参数指定使用特定Provider实例，在此不再赘述。 生命周期 同资源不一样，数据源目前不可以通过设置lifecycle块来定制化生命周期，但数据源内部lifecycle被设置为保留关键字以备将来可以支持该功能。 例子 一个数据源定义例子如下： # Find the latest available AMI that is tagged with Component = web data \"aws_ami\" \"web\" { filter { name = \"state\" values = [\"available\"] } filter { name = \"tag:Component\" values = [\"web\"] } most_recent = true } 引用数据源 引用数据源数据的语法是data...： resource \"aws_instance\" \"web\" { ami = data.aws_ami.web.id instance_type = \"t1.micro\" } "},"3.8.表达式.html":{"url":"3.8.表达式.html","title":"表达式","keywords":"","body":"表达式 表达式用来在配置文件中进行一些计算。最简单的表达式就是字面量，比如\"hello\"，或者5。Terraform也支持一些更加复杂的表达式，比如引用其他resource的输出值、数学计算、布尔条件计算，以及一些内建的函数。 Terraform配置中很多地方都可以使用表达式，但某些特定的场景下限制了可以使用的表达式的类型，例如只准使用特定数据类型的字面量，或是禁止使用resource的输出值。 我们在类型章节中已经基本介绍了类型以及类型相关的字面量，下面我们来介绍一些其他的表达式。 下标和属性 list和tuple可以通过下标访问成员，例如local.list[3]、var.tuple[2]。map和object可以通过属性访问成员，例如local.object.attrname、local.map.keyname。由于map的key是用户定义的，可能无法成为合法的Terraform标识符，所以访问map成员时我们推荐使用方括号：local.map[\"keyname\"]。 引用命名值 Terraform中定义了多种命名值，表达式中的每一个命名值都关联到一个具体的值，我们可以用单一命名值作为一个表达式，或是组合多个命名值来计算出一个新值。 命名值有如下种类： .：表示一个资源对象。凡是不符合后面列出的命名值模式的表达式都会被Terraform解释为一个托管资源。如果资源声明了count元参数，那么该表达式表示的是一个对象实例的list。如果资源声明了for_each元参数，那么该表达式表示的是一个对象实例的map。 var.：表示一个输入变量 local.：表示一个局部值 module..：表示一个模块的一个输出值 data..：表示一个数据源实例。如果数据源声明了count元参数，那么该表达式表示的是一个数据源实例list。如果数据源声明了for_each元参数，那么该表达式表示的是一个数据源实例map。 path.module：表示当前模块在文件系统中的路径 path.root：表示根模块(调用Terraform命令行执行的代码文件所在的模块)在文件系统中的路径 path.cwd：表示当前工作目录的路径。一般来说该路径等同于path.root，但在调用Terraform命令行时如果指定了代码路径，那么二者将会不同。 terraform.workspace：当前使用的Workspace(我们在状态管理的\"状态的隔离存储\"中介绍过) 虽然这些命名表达式可以使用.号来访问对象的各种属性，但实际上他们实际类型并不是我们在类型章节里提到过的object。两者的区别在于，object同时支持使用.或者[\"\"]两种方式访问对象成员属性，而上述命名表达式仅支持.。 局部命名值 在某些特定表达式或上下文当中，有一些特殊的命名值可以被使用，他们是局部命名值。几种比较常见的局部命名值有： count.index：表达当前count下标序号 each.key：表达当前for_each迭代器实例 self：在预置器中指代声明预置器的资源 命名值的依赖关系 构建资源或是模块时经常会使用含有命名值的表达式赋值，Terraform会分析这些表达式并自动计算出对象之间的依赖关系。 引用资源输出属性 最常见的引用类型就是引用一个resource或data块定义的对象的输出属性。由于这些资源与数据源对象结构可能非常复杂，所以对它们的输出属性的引用表达式也可能非常复杂。 比如下面这个例子： resource \"aws_instance\" \"example\" { ami = \"ami-abc123\" instance_type = \"t2.micro\" ebs_block_device { device_name = \"sda2\" volume_size = 16 } ebs_block_device { device_name = \"sda3\" volume_size = 20 } } aws_instance文档列出了该类型所支持的所有输入参数和内嵌块，以及对外输出的属性列表。所有这些不同的资源类型Schema都可以在引用中使用，如下所示： ami参数可以在可以在其他地方用aws_instance.example.ami表达式来引用 id属性可以用aws_instance.example.id的表达式来引用 内嵌的ebs_block_device参数可以通过后面会介绍的展开表达式(splat expression)来访问，比如我们获取所有的ebs_block_device的device_name列表：aws_instance.example.ebs_block_device[*].device_name 在aws_instance类型里的内嵌块并没有任何输出属性，但如果ebs_block_device添加了一个名为\"id\"的输出属性，那么可以用aws_instance.example.ebs_block_device[*].id表达式来访问含有所有id的列表 有时多个内嵌块会各自包含一个逻辑键来区分彼此，类似用资源名访问资源，我们也可以用内嵌块的名字来访问特定内嵌块。假如aws_instance类型有一个假想的内嵌块类型device并规定device可以赋予这样的一个逻辑键，那么代码看起来就会是这样的： device \"foo\" { size = 2 } device \"bar\" { size = 4 } 我们可以使用键来访问特定块的数据，例如：aws_instance.example.device[\"foo\"].size 要获取一个device名称到device大小的映射，可以使用for表达式： {for k, device in aws_instance.example.device : k => device.size} 当一个资源声明了count参数，那么资源本身就成了一个资源对象列表而非单个资源。这种情况下要访问资源输出属性，要么使用展开表达式，要么使用下标索引： aws_instance.example[*].id：返回所有instance的id列表 aws_instance.example[0].id：返回第一个instance的id 当一个资源声明了for_each参数，那么资源本身就成了一个资源对象字典而非单个资源。这种情况下要访问资源的输出属性，要么使用特定键，要么使用for表达式： aws_instance.example[\"a\"].id：返回\"a\"对应的实例的id [for value in aws_instance.example: value.id]：返回所有instance的id 注意不像使用count，使用for_each的资源集合不能直接使用展开表达式，展开表达式只能适用于列表。你可以把字典转换成列表后再使用展开表达式： values(aws_instance.example)[*].id 尚不知晓的值 当Terraform在计算变更计划时，有些资源输出属性无法立即求值，因为他们的值取决于远程API的返回值。比如说，有一个远程对象可以在创建时返回一个生成的唯一id，Terraform无法在创建它之前就预知这个值。 为了允许在计算变更阶段就能计算含有这种值的表达式，Terraform使用了一个特殊的\"尚不知晓(unknown value)\"占位符来代替这些结果。大部分时候你不需要特意理会它们，因为Terraform语言会自动处理这些尚不知晓的值，比如说使两个尚不知晓的值相加得到的会是一个尚不知晓的值。 然而，有些情况下表达式中含有尚不知晓的值会有明显的影响： count元参数不可以为尚不知晓，因为变更计划必须明确地知晓到底要维护多少个目标实例 如果尚不知晓的值被用于数据源，那么数据源在计算变更计划阶段就无法读取，它会被推迟到执行阶段读取。这种情况下，在计划阶段该数据源的一切输出均为尚不知晓 如果声明module块时传递给模块输入变量的表达式使用了尚不知晓值，那么在模块代码中任何使用了该输入变量值的表达式的值都将是尚不知晓 如果模块输出值表达式中含有尚不知晓值，任何使用该模块输出值的表达式都将是尚不知晓 Terraform会尝试验证尚不知晓值的数据类型是否合法，但仍然有可能无法正确检查数据类型，导致执行阶段发生错误 尚不知晓值在执行terraform plan时会被输出为\"(not yet known)\"。 算数和逻辑操作符 一个操作符是一种用以转换或合并一个或多个表达式的表达式。操作符要么是把两个值计算为第三个值，也就是二元操作符；要么是把一个值转换成另一个值，也就是一元操作符。 二元操作符位于两个表达式的中间，类似1+2。一元操作符位于一个表达式的前面，类似!true。 Terraform语言支持一组算数和逻辑操作符，它们的功能类似于JavaScript或Ruby里的操作符功能。 当一个表达式中含有多个操作符时，它们的优先级顺序时： !，- (负号) *，/，% +，- (减号) >，>=，， ==，!= && || 可以使用小括号覆盖默认优先级。如果没有小括号，高优先级操作符会被先计算，例如1+2*3会被解释成1+(2*3)而不是(1+2)*3。 不同的操作符可以按它们之间相似的行为被归纳为几组，每一组操作符都期待被给予特定类型的值。Terraform会在类型不符时尝试进行隐式类型转换，如果失败则会抛错。 算数操作符 a + b：返回a与b的和 a - b：返回a与b的差 a * b：返回a与b的积 a / b：返回a与b的商 a % b：返回a与b的模。该操作符一般仅在a与b是整数时有效 -a：返回a与-1的商 相等性操作符 a == b：如果a与b类型与值都相等返回true，否则返回false a != b：与==相反 比较操作符 a ：如果a比b小则为true，否则为false a > b：如果a比b大则为true，否则为false a ：如果a比b小或者相等则为true，否则为false a >= b：如果a比b大或者相等则为true，否则为false 逻辑操作符 a || b：a或b中有至少一个为true则为true，否则为false a && b：a与比都为true则为true，否则为false !a：如果a为true则为false，如果a为false则为true 条件表达式 条件表达式是判断一个布尔表达式的结果以便于在后续两个值当中选择一个： condition ? true_val : false_val 如果condition表达式为true，那么结果是true_value，反之则为false_value。 一个常见的条件表达式用法是使用默认值替代非法值： var.a != \"\" ? var.a : \"default-a\" 如果输入变量a的值是空字符串，那么结果会是default-a，否则返回输入变量a的值。 条件表达式的判断条件可以使用上述的任意操作符。供选择的两个值也可以是任意类型，但它们的类型必须相同，这样Terraform才能判断条件表达式的输出类型。 函数调用 Terraform支持在计算表达式时使用一些内建函数，函数调用表达式类似操作符，通用语法是： (, ) 函数名标明了要调用的函数。每一个函数都定义了数量不等、类型不一的入参以及不同类型的返回值。 有些函数定义了不定长的入参表，例如，min函数可以接收任意多个数值类型入参，返回其中最小的数值： min(55, 3453, 2) 展开函数入参 如果想要把列表或元组的元素作为参数传递给函数，那么我们可以使用展开符： min([55, 2453, 2]...) 展开符使用的是三个独立的.号组成的...，不是Unicode中的省略号…。展开符是一种只能用在函数调用场景下的特殊语法。 有关完整的内建函数我们可能会在今后撰写相应的章节介绍。 for表达式 for表达式是将一种复杂类型映射成另一种复杂类型的表达式。输入类型值中的每一个元素都会被映射为一个或零个结果。 举例来说，如果var.list是一个字符串列表，那么下面的表达式将会把列表元素全部转为大写： [for s in var.list : upper(s)] 在这里for表达式迭代了var.list中每一个元素(就是s)，然后计算了upper(s)，最后构建了一个包含了所有upper(s)结果的新元组，元组内元素顺序与源列表相同。 for表达式周围的括号类型决定了输出值的类型。上面的例子里我们使用了方括号，所以输出类型是元组。如果使用的是花括号，那么输出类型是对象，for表达式内部冒号后面应该使用以=>符号分隔的表达式： {for s in var.list : s => upper(s)} 该表达式返回一个对象，对象的成员属性名称就是源列表中的元素，值就是对应的大写值。 一个for表达式还可以包含一个可选的if子句用以过滤结果，这可能会减少返回的元素数量： [for s in var.list : upper(s) if s != \"\"] 被for迭代的也可以是对象或者字典，这样的话迭代器就会被表示为两个临时变量： [for k, v in var.map : length(k) + length(v)] 最后，如果返回类型是对象(使用花括号)那么表达式中可以使用...符号实现group by： {for s in var.list : substr(s, 0, 1) => s... if s != \"\"} 展开表达式(Splat Expression) 展开表达式提供了一种类似for表达式的简洁表达方式。比如说var.list包含一组对象，每个对象有一个属性id，那么读取所有id的for表达式会是这样： [for o in var.list : o.id] 与之等价的展开表达式是这样的： var.list[*].id 这个特殊的[*]符号迭代了列表中每一个元素，然后返回了它们在.号右边的属性值。 展开表达式只能被用于列表(所以使用for_each参数的资源不能使用展开表达式，因为它的类型是字典)。然而，如果一个展开表达式被用于一个既不是列表又不是元组的值，那么这个值会被自动包装成一个单元素的列表然后被处理。 比如说，var.single_object[*].id 等价于 [var.single_object][*].id。大部分场景下这种行为没有什么意义，但在访问一个不确定是否会定义count参数的资源时，这种行为很有帮助，例如： aws_instance.example[*].id 上面的表达式不论aws_instance.example定义了count与否都会返回实例的id列表，这样如果我们以后为aws_instance.example添加了count参数我们也不需要修改这个表达式。 遗留的旧有展开表达式 曾经存在另一种旧的展开表达式语法，它是一种比较弱化的展开表达式，现在应该尽量避免使用。 这种旧的展开表达式使用.*而不是[*]： var.list.*.interfaces[0].name 要特别注意该表达式与现有的展开表达式结果不同，它的行为等价于： [for o in var.list : o.interfaces][0].name 而现有[*]展开表达式的行为等价于： [for o in var.list : o.interfaces[0].name] 注意两者右方括号的位置。 dynamic块 在顶级块，例如resource块当中，一般只能以类似name = expression的形式进行一对一的赋值。大部分情况下这已经够用了，但某些资源类型包含了可重复的内嵌块，无法使用表达式循环赋值： resource \"aws_elastic_beanstalk_environment\" \"tfenvtest\" { name = \"tf-test-name\" # can use expressions here setting { # but the \"setting\" block is always a literal block } } 你可以用dynamic块来动态构建重复的setting这样的内嵌块： resource \"aws_elastic_beanstalk_environment\" \"tfenvtest\" { name = \"tf-test-name\" application = \"${aws_elastic_beanstalk_application.tftest.name}\" solution_stack_name = \"64bit Amazon Linux 2018.03 v2.11.4 running Go 1.12.6\" dynamic \"setting\" { for_each = var.settings content { namespace = setting.value[\"namespace\"] name = setting.value[\"name\"] value = setting.value[\"value\"] } } } dynamic可以在resource、data、provider和provisioner块内使用。一个dynamic块类似于for表达式，只不过它产生的是内嵌块。它可以迭代一个复杂类型数据然后为每一个元素生成相应的内嵌块。在上面的例子里： dynamic的标签(也就是\"setting\")确定了我们要生成的内嵌块种类 for_each参数提供了需要迭代的复杂类型值 iterator参数(可选)设置了用以表示当前迭代元素的临时变量名。如果没有设置iterator，那么临时变量名默认就是dynamic块的标签(也就是setting) labels参数(可选)是一个表示块标签的有序列表，用以按次序生成一组内嵌块。有labels参数的表达式里可以使用临时的iterator变量 内嵌的content块定义了要生成的内嵌块的块体。你可以在content块内部使用临时的iterator变量 由于for_each参数可以是集合或者结构化类型，所以你可以使用for表达式或是展开表达式来转换一个现有集合的类型。 iterator变量(上面的例子里就是setting)有两个属性： key：迭代容器如果是map，那么就是当前元素的键；迭代容器如果是list，那么就是当前元素在list中的下标序号；如果是由for_each表达式产出的set，那么key和value是一样的，这时我们不应该使用key。 value：当前元素的值 一个dynamic块只能生成属于当前块定义过的内嵌块参数。无法生成诸如lifecycle、provisioner这样的元参数，因为Terraform必须在确保对这些元参数求值的计算是成功的。 for_each的值必须是不为空的map或者set。如果你需要根据内嵌数据结构或者多个数据结构的元素组合来声明资源实例集合，你可以使用Terraform表达式和函数来生成合适的值。 dynamic块的最佳实践 过度使用dynamic块会导致代码难以阅读以及维护，所以我们建议只在需要构造可重用的模块代码时使用dynamic块。尽可能手写内嵌块。 字符串字面量 Terraform有两种不同的字符串字面量。最通用的就是用一对双引号包裹的字符，比如\"hello\"。在双引号之间，反斜杠\\被用来进行转义。Terraform支持的转义符有： Sequence Replacement \\n 换行 \\r 回车 \\t 制表符 \\\" 双引号 (不会截断字符串) \\\\ 反斜杠 \\uNNNN 普通字符映射平面的Unicode字符(NNNN代表四位16进制数) \\UNNNNNNNN 补充字符映射平面的Unicode字符(NNNNNNNN代表八位16进制数) 另一种字符串表达式被称为\"heredoc\"风格，是受Unix Shell语言启发。它可以使用自定义的分隔符更加清晰地表达多行字符串： 上面例子里的heredoc风格字符串要求内容必须对齐行头，这在块内声明时看起来会比较奇怪： block { value = 为了改进可读性，Terraform也支持缩进的heredoc，只要把 block { value = 上面的例子里，Terraform会以最靠近行头的行作为基准来调整行头缩进，得到的字符串是这样的： hello world heredoc中的反斜杠不会被解释成转义，而只会是简单的反斜杠。 双引号和heredoc两种字符串都支持字符串模版，模版的形式是${...}以及%{...}。如果想要表达${或者%{的字面量，那么可以重复第一个字符：$${和%%{ 。 字符串模版 字符串模版允许我们在字符串中嵌入表达式，或是通过其他值动态构造字符串。 插值(Interpolation) 一个${...}序列被称为插值，插值计算花括号之间的表达式的值，有必要的话将之转换为字符串，然后插入字符串模版，形成最终的字符串： \"Hello, ${var.name}!\" 上面的例子里，输入变量var.name的值被访问后插入了字符串模版，产生了最终的结果，比如：\"Hello, Juan!\" 命令(Directive) 一个%{...}序列被称为命令，命令可以是一个布尔表达式或者是对集合的迭代，类似条件表达式以及for表达式。有两种命令： if \\ / else /endif 命令根据布尔表达式的结果在两个模版中选择一个： \"Hello, %{ if var.name != \"\" }${var.name}%{ else }unnamed%{ endif }!\" else部分可以省略，这样如果布尔表达结果为false那么就会插入空字符串。 for \\ in \\ / endfor 命令迭代一个结构化对象或者集合，用每一个元素渲染模版，然后把它们拼接起来： for关键字后紧跟的名字被用作代表迭代器元素的临时变量，可以用来在内嵌模版中使用。 为了在不添加额外空格和换行的前提下提升可读性，所有的模版序列都可以在首尾添加~符号。如果有~符号，那么模版序列会去除字符串左右的空白(空格以及换行)。如果~出现在头部，那么会去除字符串左侧的空白；如果出现在尾部，那么会去除字符串右边的空白： 上面的例子里，命令符后面的换行符被忽略了，但是server ${ip}后面的换行符被保留了，这确保了每一个元素生成一行输出： server 10.1.16.154 server 10.1.16.1 server 10.1.16.34 当使用模版命令时，我们推荐使用heredoc风格字符串，用多行模版提升可读性。双引号字符串内最好只使用插值。 Terraform插值 Terraform曾经只支持在表达式中使用插值，例如 resource \"aws_instance\" \"example\" { ami = var.image_id # ... } 这种语法是在Terraform 0.12后才被支持的。在Terrafor 0.11及更早的版本中，这段代码只能被写成这样： resource \"aws_instance\" \"example\" { ami = \"${var.image_id}\" # ... } Terraform 0.12保持了向前兼容，所以现在这样的代码也仍然是合法的。读者们也许会在一些Terraform代码和文档中继续看到这样的写法，但请尽量避免继续这样书写纯插值字符串，而是直接使用表达式。 "},"3.9.重载文件.html":{"url":"3.9.重载文件.html","title":"重载文件","keywords":"","body":"重载文件 一般来说Terraform会加载模块内所有的.tf和.tf.json文件，并要求文件内定义了一组无重复的对象。如果两个文件尝试定义同一个对象，那么Terraform会报错。 在某些少见场景中，能够用单独的文件重载已有对象配置的特定部分将会十分有用。比如说，由工程师编写的配置文件能够在运行时被程序生成的JSON文件部分重载。 为支持这些少见场景，Terrform会对后缀名为override.tf和override.tf.json的代码文件进行特殊处理。对于名为override.tf和override.tf.json的代码文件也会进行相同的特殊处理。 Terraform一开始加载代码文件时会跳过这些重载文件，然后才会按照字典序一个一个处理重载文件。对重载文件中定义的所有顶级块(resource、data等)，Terraform会尝试找到对应的已有对象并且将重载内容合并进已有对象。 重载文件只应使用于特殊场景，过度使用会使得读者在阅读原始代码文件时被迫还要阅读所有的重载文件才能理解对象配置，从而降低了代码的可读性。使用重载文件时，请在原始文件被重载的部分添加相应注释，提醒未来的读者哪些部分会被重载文件修改。 例子 如果我们有一个名为example.tf的代码文件： resource \"aws_instance\" \"web\" { instance_type = \"t2.micro\" ami = \"ami-408c7f28\" } 然后我们创建一个名为override.tf的文件： resource \"aws_instance\" \"web\" { ami = \"foo\" } Terraform随后会合并两者，实际的配置会是这样的： resource \"aws_instance\" \"web\" { instance_type = \"t2.micro\" ami = \"foo\" } 合并行为 不同的块类型有着些微不同的合并行为，某些特定块内的特殊构造会以特殊形式被合并。 一般来说： 重载文件内的顶级块会和普通文件内同类型同名的顶级块合并 重载文件内的顶级块配置册参数会覆盖普通文件内对应块内的同名参数 重载块内的内嵌块会取代普通文件内对应块内的所有同类型内嵌块。所有重载块内没有定义的内嵌块在普通文件内保持不变 内嵌块的内容不会进行合并 合并后的块仍然需要符合对应块类型的所有验证规则 如果有多个重载文件定义了同一个顶级块，那么重载效果是叠加的，后加载的重载块会在先前加载的重载块生效的基础上合并。重载操作首先按照文件名的字典序其次是在重载文件中的位置决定执行顺序。 有一些针对特定顶级块类型的特殊合并行为规则，我们将重载文件中定义的块称为重载块，重载块在普通文件中对应的块称为源块： 合并resource块以及合并data块 在resource块内，所有lifecycle块的内容会按照参数逐条合并。比如说，一个重载块只定义了create_before_destroy参数而源块定义了ignore_changes，那么create_before_destroy被合并的同时igonore_changes将会被保留。 如果重载的resource块包含了一个或多个provisioner，那么源块内所有的provisioner会被忽略。 如果重载的resource块内包含了一个connection块，那么它将会完全覆盖所有源块内定义的connection块 不允许在重载块内定义depends_on参数，那将会引发一个错误。 合并variable块 variable块内参数的合并遵循上述的标准流程，但对于type和default参数的处理会有一些特殊的考虑。 如果源块定义了default值而重载块修改了变量的type，Terraform会尝试将default值转换成新类型，如果转换失败则会报错。 同样的，如果源块定义了type参数而重载块修改了default值，那么新的default值必须能够被转换成原先的类型。 合并output块 不允许在重载块内定义depends_on参数，这会引发一个错误。 合并locals块 所有的locals块都定义了一个或多个命名值。针对locals的合并会是按照命名值的名字逐条执行的，不论命名值是在哪个locals块内被定义的。 合并terraform块 如果重载块定义了required_providers参数，那么它的值会被逐条合并，这就允许重载块在不影响其他Provider的情况下调整单个Provider的版本约束。 重载块内的requeired_version和required_providers里的配置完全覆盖源块内的相应配置。如果源块和重载块都定义了required_version，那么源块的配置会被完全忽略。 "},"3.10.代码风格规范.html":{"url":"3.10.代码风格规范.html","title":"代码风格规范","keywords":"","body":"代码风格规范 Terraform推荐以下代码规范： 使用两个空格缩进 同一缩进层级的多个赋值语句以等号对齐： ami = \"abc123\" instance_type = \"t2.micro\" 当块体内同时有参数赋值以及内嵌块时，请先编写参数赋值，然后是内嵌块。参数与内嵌块之间空一行分隔 对于同时包含参数赋值以及元参数赋值的块，请先编写元参数赋值语句，然后是参数赋值语句，之间空一行分隔。元参数块请置于块体的最后，空一行分隔： resource \"aws_instance\" \"example\" { count = 2 # meta-argument first ami = \"abc123\" instance_type = \"t2.micro\" network_interface { # ... } lifecycle { # meta-argument block last create_before_destroy = true } } 顶层块之间应空一行分隔。内嵌块之间也应该空一行分隔，除非是相同类型的内嵌块(比如resource块内部多个provisioner块) 同类型块之间尽量避免插入其他类型块，除非不同类型块共同组成了一个有语义的家族(比方说，aws_instnace资源内的root_block_device、ebs_block_device、ephemeral_block_device内嵌块共同构成了描述AWS块存储的块家族，所以他们可以被混合编写)。 "},"4.Terraform模块.html":{"url":"4.Terraform模块.html","title":"Terraform模块","keywords":"","body":"Terraform模块 到目前为止我们介绍了一些代码书写的知识，但我们创建的所有资源和数据源的代码都是我们在代码文件中编写出来的。我们有没有办法不通过复制粘贴代码从而直接使用别人编写好的Terraform代码来创建一组资源呢？ Terraform对此给出的答案就是模块(Module)。简单来讲模块就是包含一组Terraform代码的文件夹，我们之前篇章中编写的代码实际上也是在模块中。要想真正理解模块的功能，我们需要去体验一下模块的使用。 Terraform模块是编写高质量Terraform代码，提升代码复用性的重要手段，可以说，一个成熟的生产环境应该是由数个可信成熟的模块组装而成的。我们将在本章介绍关于模块的知识。 "},"4.1.创建模块.html":{"url":"4.1.创建模块.html","title":"创建模块","keywords":"","body":"创建模块 实际上所有包含Terraform代码文件的文件夹都是一个Terraform模块。我们如果直接在一个文件夹内执行terraform apply或者terraform plan命令，那么当前所在的文件夹就被称为根模块(root module)。我们也可以在执行Terraform命令时通过命令行参数指定根模块的路径。 模块结构 旨在被重用的模块与我们编写的根模块使用的是相同的Terraform代码和代码风格规范。一般来讲，在一个模块中，会有： 一个README文件，用来描述模块的用途。文件名可以是README或者README.md，后者应采用Markdown语法编写。可以考虑在README中用可视化的图形来描绘创建的基础设施资源以及它们之间的关系。README中不需要描述模块的输入输出，因为工具会自动收集相关信息。如果在README中引用了外部文件或图片，请确保使用的是带有特定版本号的绝对URL路径以防止未来指向错误的版本 一个LICENSE描述模块使用的许可协议。如果你想要公开发布一个模块，最好考虑包含一个明确的许可证协议文件，许多组织不会使用没有明确许可证协议的模块 一个examples文件夹用来给出一个调用样例(可选) 一个variables.tf文件，包含模块所有的输入变量。输入变量应该有明确的描述说明用途 一个outputs.tf文件，包含模块所有的输出值。输出值应该有明确的描述说明用途 嵌入模块文件夹，出于封装复杂性或是复用代码的目的，我们可以在modules子目录下建立一些嵌入模块。所有包含README文件的嵌入模块都可以被外部用户使用；不含README文件的模块被认为是仅在当前模块内使用的(可选) 一个main.tf，它是模块主要的入口点。对于一个简单的模块来说，可以把所有资源都定义在里面；如果是一个比较复杂的模块，我们可以把创建的资源分布到不同的代码文件中，但引用嵌入模块的代码还是应保留在main.tf里 其他定义了各种基础设施对象的代码文件(可选) 如果模块含有多个嵌入模块，那么应避免它们彼此之间的引用，由根模块负责组合它们。 由于examples/中的代码经常会被拷贝到其他项目中进行修改，所有在examples/代码中引用本模块时使用的引用路径应使用外部调用者可以使用的路径，而非相对路径。 一个最小化模块推荐的结构是这样的： $ tree minimal-module/ . ├── README.md ├── main.tf ├── variables.tf ├── outputs.tf 一个更完整一些的模块结构可以是这样的： $ tree complete-module/ . ├── README.md ├── main.tf ├── variables.tf ├── outputs.tf ├── ... ├── modules/ │ ├── nestedA/ │ │ ├── README.md │ │ ├── variables.tf │ │ ├── main.tf │ │ ├── outputs.tf │ ├── nestedB/ │ ├── .../ ├── examples/ │ ├── exampleA/ │ │ ├── main.tf │ ├── exampleB/ │ ├── .../ 避免过深的模块结构 我们刚才提到可以在modules/子目录下创建嵌入模块。Terraform倡导\"扁平\"的模块结构，只应保持一层嵌入模块，防止在嵌入模块中继续创建嵌入模块。应将嵌入模块设计成易于组合的结构，使得在根模块中可以通过组合各个嵌入模块创建复杂的基础设施。 "},"4.2.使用模块.html":{"url":"4.2.使用模块.html","title":"使用模块","keywords":"","body":"引用模块 在Terraform代码中引用一个模块，使用的是module块。 每当在代码中新增、删除或者修改一个module块之后，都要执行terraform init命令来获取模块代码并安装到本地磁盘上。 模块源 module块定义了一个source参数，指定了模块的源；Terraform目前支持如下模块源： 本地路径 Terraform Registry GitHub Bitbucket 通用Git、Mercurial仓库 HTTP地址 S3 buckets GCS buckets 我们后面会一一讲解这些模块源的使用。source使用的是URL风格的参数，但某些源支持在source参数中通过额外参数指定模块版本。 出于消除重复代码的目的我们可以重构我们的根模块代码，将一些拥有重复模式的代码重构为可反复调用的嵌入模块，通过本地路径来引用。 许多的模块源类型都支持从当前系统环境中读取认证信息，例如环境变量或系统配置文件。我们在介绍模块源的时候会介绍到这方面的信息。 我们建议每个模块把期待被重用的基础设施声明在各自的根模块位置上，但是直接引用其他模块的嵌入模块也是可行的。 本地路径 使用本地路径可以使我们引用同一项目内定义的子模块： module \"consul\" { source = \"./consul\" } 一个本地路径必须以./或者../为前缀来标明要使用的本地路径，以区别于使用Terraform Registry路径。 本地路径引用模块和其他源类型有一个区别，本地路径引用的模块不需要下载相关源代码，代码已经存在于本地相关路径的磁盘上了。 Terraform Registry Registry目前是Terraform官方力推的模块仓库方案，采用了Terraform定制的协议，支持版本化管理和使用模块。 官方提供的公共仓库保存和索引了大量公共模块，在这里可以很容易地搜索到各种官方和社区提供的高质量模块。 读者也可以通过Terraform Cloud服务维护一个私有模块仓库，或是通过实现Terraform模块注册协议来实现一个私有仓库。 公共仓库的的模块可以用//形式的源地址来引用，在公共仓库上的模块介绍页面上都包含了确切的源地址，例如： module \"consul\" { source = \"hashicorp/consul/aws\" version = \"0.1.0\" } 对于那些托管在其他仓库的模块，在源地址头部添加/ 部分，指定私有仓库的主机名： module \"consul\" { source = \"app.terraform.io/example-corp/k8s-cluster/azurerm\" version = \"1.1.0\" } 如果你使用的是SaaS版本的Terraform Cloud，那么托管在上面的私有仓库的主机名是 app.terraform.io 。如果使用的是私有部署的Terraform企业版，那么托管在上面的私有仓库的主机名就是Terraform企业版服务的主机名。 模块仓库支持版本化。你可以在module块中指定模块的版本约束。 如果要引用私有仓库的模块，你需要首先通过配置命令行工具配置文件来设置访问凭证。 GitHub Terraform发现source参数的值如果是以github.com为前缀时，会将其自动识别为一个GitHub源： module \"consul\" { source = \"github.com/hashicorp/example\" } 上面的例子里会自动使用HTTPS协议克隆仓库。如果要使用SSH协议，那么请使用如下的地址： module \"consul\" { source = \"git@github.com:hashicorp/example.git\" } GitHub源的处理与后面要介绍的通用Git仓库是一样的，所以他们获取git凭证和通过ref参数引用特定版本的方式都是一样的。如果要访问私有仓库，你需要额外配置git凭证。 Bitbucket Terraform发现source参数的值如果是以bitbucket.org为前缀时，会将其自动识别为一个Bitbucket源： module \"consul\" { source = \"bitbucket.org/hashicorp/terraform-consul-aws\" } 这种捷径方法只针对公共仓库有效，因为Terraform必须访问ButBucket API来了解仓库使用的是Git还是Mercurial协议。 Terraform根据仓库的类型来决定将它作为一个Git仓库还是Mercurial仓库来处理。后面的章节会介绍如何为访问仓库配置访问凭证以及指定要使用的版本号。 通用Git仓库 可以通过在地址开头加上特殊的git::前缀来指定使用任意的Git仓库。在前缀后跟随的是一个合法的Git URL。 使用HTTPS和SSH协议的例子： module \"vpc\" { source = \"git::https://example.com/vpc.git\" } module \"storage\" { source = \"git::ssh://username@example.com/storage.git\" } Terraform使用git clone命令安装模块代码，所以Terraform会使用本地Git系统配置，包括访问凭证。要访问私有Git仓库，必须先配置相应的凭证。 如果使用了SSH协议，那么会自动使用系统配置的SSH证书。通常情况下我们通过这种方法访问私有仓库，因为这样可以不需要交互式提示就可以访问私有仓库。 如果使用HTTP/HTTPS协议，或是其他需要用户名、密码作为凭据，你需要配置Git凭据存储来选择一个合适的凭据源。 默认情况下，Terraform会克隆默认分支。可以通过ref参数来指定版本： module \"vpc\" { source = \"git::https://example.com/vpc.git?ref=v1.2.0\" } ref参数会被用作git checkout命令的参数，可以是分支名或是tag名。 使用SSH协议时，我们更推荐ssh://的地址。你也可以选择scp风格的语法，故意忽略ssh://的部分，只留git::，例如： module \"storage\" { source = \"git::username@example.com:storage.git\" } 通用Mercurial仓库 可以通过在地址开头加上特殊的hg::前缀来指定使用任意的Mercurial仓库。在前缀后跟随的是一个合法的Mercurial URL： module \"vpc\" { source = \"hg::http://example.com/vpc.hg\" } Terraform会通过运行hg clone命令从Mercurial仓库安装模块代码，所以Terraform会使用本地Mercurial系统配置，包括访问凭证。要访问私有Mercurial仓库，必须先配置相应的凭证。 如果使用了SSH协议，那么会自动使用系统配置的SSH证书。通常情况下我们通过这种方法访问私有仓库，因为这样可以不需要交互式提示就可以访问私有仓库。 类似Git源，我们可以通过ref参数指定非默认的分支或者标签来选择特定版本： module \"vpc\" { source = \"hg::http://example.com/vpc.hg?ref=v1.2.0\" } HTTP地址 当我们使用HTTP或HTTPS地址时，Terraform会向指定URL发送一个GET请求，期待返回另一个源地址。这种间接的方法使得HTTP可以成为一个更复杂的模块源地址的指示器。 然后Terraform会再发送一个GET请求到之前响应的地址上，并附加一个查询参数terraform-get=1，这样服务器可以选择当Terraform来查询时可以返回一个不一样的地址。 如果相应的状态码是成功的(200范围的成功状态码)，Terraform就会通过以下位置来获取下一个访问地址： 响应头部的X-Terraform-Get值 如果响应内容是一个HTML页面，那么会检查名为terraform-get的 html meta元素： 不管用哪种方式返回的地址，Terraform都会像本章提到的其他的源地址那样处理它。 如果HTTP/HTTPS地址需要认证凭证，可以在HOME文件夹下配置一个.netrc文件，详见相关文档 也有一种特殊情况，如果Terraform发现地址有着一个常见的存档文件的后缀名，那么Terraform会跳过terraform-get=1重定向的步骤，直接将响应内容作为模块代码使用。 module \"vpc\" { source = \"https://example.com/vpc-module.zip\" } 目前支持的后缀名有： zip tar.bz2和tbz2 tar.gz和tgz tar.xz和txz 如果HTTP地址不以这些文件名结尾，但又的确指向模块存档文件，那么可以使用archive参数来强制按照这种行为处理地址： module \"vpc\" { source = \"https://example.com/vpc-module?archive=zip\" } S3 Bucket 你可以把模块存档保存在AWS S3桶里，使用s3::作为地址前缀，后面跟随一个S3对象访问地址 module \"consul\" { source = \"s3::https://s3-eu-west-1.amazonaws.com/examplecorp-terraform-modules/vpc.zip\" } Terraform识别到s3::前缀后会使用AWS风格的认证机制访问给定地址。这使得这种源地址也可以搭配其他提供了S3协议兼容的对象存储服务使用，只要他们的认证方式与AWS相同即可。 保存在S3桶内的模块存档文件格式必须与上面HTTP源提到的支持的格式相同，Terraform会下载并解压缩模块代码。 模块安装器会从以下位置寻找AWS凭证，按照优先级顺序排列： AWS_ACCESS_KEY_ID和AWS_SECRET_ACCESS_KEY环境变量 HOME目录下.aws/credentials文件内的默认profile 如果是在AWS EC2主机内运行的，那么会尝试使用搭载的IAM主机实例配置。 GCS Bucket 你可以把模块存档保存在谷歌云GCS储桶里，使用gcs::作为地址前缀，后面跟随一个GCS对象访问地址： module \"consul\" { source = \"gcs::https://www.googleapis.com/storage/v1/modules/foomodule.zip\" } 模块安装器会使用谷歌云SDK的凭据来访问GCS。要设置凭据，你可以： 通过GOOGLE_APPLICATION_CREDENTIALS环境变量配置服务账号的密钥文件 如果是在谷歌云主机上运行的Terraform，可以使用默认凭据。访问相关文档获取完整信息 可以使用命令行gcloud auth application-default login设置 直接引用子文件夹中的模块 引用版本控制系统或是对象存储服务中的模块时，模块本身可能存在于存档文件的一个子文件夹内。我们可以使用特殊的\"//\"语法来指定Terraform使用存档内特定路径作为模块代码所在位置，例如： hashicorp/consul/aws//modules/consul-cluster git::https://example.com/network.git//modules/vpc https://example.com/network-module.zip//modules/vpc s3::https://s3-eu-west-1.amazonaws.com/examplecorp-terraform-modules/network.zip//modules/vpc 如果源地址中包含又参数，例如指定特定版本号的ref参数，那么把子文件夹路径放在参数之前： git::https://example.com/network.git//modules/vpc?ref=v1.2.0 Terraform会解压缩整个存档文件后，读取特定子文件夹。所以，对于一个存在于子文件夹中的模块来说，通过本地路径引用同一个存档内的另一个模块是安全的。 使用模块 我们刚才介绍了如何用source指定模块源，下面我们继续讲解如何在代码中使用一个模块。 我们可以把模块理解成类似函数，如同函数有输入参数表和输出值一样，我们之前介绍过Terraform代码有输入变量和输出值。我们在module块的块体内除了source参数，还可以对该模块的输入变量赋值： module \"servers\" { source = \"./app-cluster\" servers = 5 } 在这个例子里，我们将会创建./app-cluster文件夹下Terraform声明的一系列资源，该模块的servers输入变量的值被我们设定成了5。 在代码中新增、删除或是修改一个某块的source，都需要重新运行terraform init命令。默认情况下，该命令不会升级已安装的模块(例如source未指定版本，过去安装了旧版本模块代码，那么执行terraform init不会自动更新到新版本)；可以执行terraform init -upgrade来强制更新到最新版本模块。 访问模块输出值 在模块中定义的资源和数据源都是被封装的，所以模块调用者无法直接访问它们的输出属性。然而，模块可以声明一系列输出值，来选择性地输出特定的数据供模块调用者使用。 举例来说，如果./app-cluster模块定义了名为instance_ids的输出值，那么模块的调用者可以像这样引用它： resource \"aws_elb\" \"example\" { # ... instances = module.servers.instance_ids } 其他的模块元参数 除了source以外，目前Terraform还支持在module块上声明其他一些可选元参数： version：指定引用的模块版本，在后面的部分会详细介绍 count和for_each：这是Terraform 0.13开始支持的特性，类似resource与data，我们可以创建多个module实例 providers：通过传入一个map我们可以指定模块中的Provider配置，我们将在后面详细介绍 depends_on：创建整个模块和其他资源之间的显式依赖。直到依赖项创建完毕，否则声明了依赖的模块内部所有的资源及内嵌的模块资源都会被推迟处理。模块的依赖行为与资源的依赖行为相同 除了上述元参数以外，lifecycle参数目前还不能被用于模块，但关键字被保留以便将来实现。 模块版本约束 使用registry作为模块源时，可以使用version元参数约束使用的模块版本： module \"consul\" { source = \"hashicorp/consul/aws\" version = \"0.0.5\" servers = 3 } version元参数的格式与Provider版本约束的格式一致。在满足版本约束的前提下，Terraform会使用当前已安装的最新版本的模块实例。如果当前没有满足约束的版本被安装过，那么会下载符合约束的最新的版本。 version元参数只能配合registry使用，公共的或者私有的模块仓库都可以。其他类型的模块源可能支持版本化，也可能不支持。本地路径模块不支持版本化。 多实例模块 可以通过在module块上声明for_each或者count来创造多实例模块。在使用上module上的for_each和count与资源、数据源块上的使用是一样的。 # my_buckets.tf module \"bucket\" { for_each = toset([\"assets\", \"media\"]) source = \"./publish_bucket\" name = \"${each.key}_bucket\" } # publish_bucket/bucket-and-cloudfront.tf variable \"name\" {} # this is the input parameter of the module resource \"aws_s3_bucket\" \"example\" { # Because var.name includes each.key in the calling # module block, its value will be different for # each instance of this module. bucket = var.name # ... } resource \"aws_iam_user\" \"deploy_user\" { # ... } 这个例子定义了一个位于./publish_bucket目录下的本地子模块，模块创建了一个S3存储痛，封装了桶的信息以及其他实现细节。 我们通过for_each参数声明了模块的多个实例，传入一个map或是set作为参数值。另外，因为我们使用了for_each，所以在module块里可以使用each对象，例子里我们使用了each.key。如果我们使用的是count参数，那么我们可以使用count.index。 子模块里创建的资源在执行计划或UI中的名称会以module.module_name[module index]作为前缀。如果一个模块没有声明count或者for_each，那么资源地址将不包含module index。 在上面的例子里，./publish_bucket模块包含了aws_s3_bucket.example资源，所以两个S3桶实例的名字分别是module.bucket[\"assets\"].aws_s3_bucket.example 以及 module.bucket[\"media\"].aws_s3_bucket.example。 模块内的Provider 当代码中声明了多个模块时，资源如何与Provider实例关联就需要特殊考虑。 每一个资源都必须关联一个Provider配置。不像Terraform其他的概念，Provider配置在Terraform项目中是全局的，可以跨模块共享。Provider配置声明只能放在根模块中。 Provider有两种方式传递给子模块：隐式继承，或是显式通过module块的providers参数传递。 一个旨在被复用的模块不允许声明任何provider块，只有使用\"代理Provider\"模式的情况除外，我们后面会介绍这种模式。 出于向前兼容Terraform 0.10及更早版本的考虑，Terraform目前在模块代码中只用到了Terraform 0.10及更早版本的功能时，不会针对模块代码中声明provider块报错，但这是一个不被推荐的遗留模式。一个含有自己的provider块定义的遗留模块与for_each、count和depends_on等0.13引入的新特性是不兼容的。 Provider配置被用于相关资源的所有操作，包括销毁远程资源对象以及更新状态信息等。Terraform会在状态文件中保存针对最近用来执行所有资源变更的Provider配置的引用。当一个resource块被删除时，状态文件中的相关记录会被用来定位到相应的配置，因为原来包含provider参数(如果声明了的话)的resource块已经不存在了。 这导致了，你必须确保删除所有相关的资源配置定义以后才能删除一个Provider配置。如果Terraform发现状态文件中记录的某个资源对应的Provider配置已经不存在了会报错，要求你重新给出相关的Provider配置。 模块内的Provider版本限制 虽然Provider配置信息在模块间共享，每个模块还是得声明各自的模块需求，这样Terraform才能决定一个适用于所有模块配置的Provider版本。 为了定义这样的版本约束要求，可以在terraform块中使用required_providers块： terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \">= 2.7.0\" } } } 有关Provider的source和版本约束的信息我们已经在前文中有所记述，在此不再赘述。 隐式Provider继承 为了方便，在一些简单的代码中，一个子模块会从调用者那里自动地继承默认的Provider配置。这意味着显式provider块声明仅位于根模块中，并且下游子模块可以简单地声明使用该类型Provider的资源，这些资源会自动关联到根模块的Provider配置上。 例如，根模块可能只含有一个provider块和一个module块： provider \"aws\" { region = \"us-west-1\" } module \"child\" { source = \"./child\" } 子模块可以声明任意关联aws类型Provider的资源而无需额外声明Provider配置： resource \"aws_s3_bucket\" \"example\" { bucket = \"provider-inherit-example\" } 当每种类型的Provider都只有一个实例时我们推荐使用这种方式。 要注意的是，只有Provider配置会被子模块继承，Provider的source或是版本约束条件则不会被继承。每一个模块都必须声明各自的Provider需求条件，这在使用非HashiCorp的Provider时尤其重要。 显式传递Provider 当不同的子模块需要不同的Provider实例，或者子模块需要的Provider实例与调用者自己使用的不同时，我们需要在module块上声明providers参数来传递子模块要使用的Provider实例。例如： # The default \"aws\" configuration is used for AWS resources in the root # module where no explicit provider instance is selected. provider \"aws\" { region = \"us-west-1\" } # An alternate configuration is also defined for a different # region, using the alias \"usw2\". provider \"aws\" { alias = \"usw2\" region = \"us-west-2\" } # An example child module is instantiated with the alternate configuration, # so any AWS resources it defines will use the us-west-2 region. module \"example\" { source = \"./example\" providers = { aws = aws.usw2 } } module块里的providers参数类似resource块里的provider参数，区别是前者接收的是一个map而不是单个string，因为一个模块可能含有多个不同的Provider。 providers的map的键就是子模块中声明的Provider需求中的名字，值就是在当前模块中对应的Provider配置的名字。 如果module块内声明了providers参数，那么它将重载所有默认的继承行为，所以你需要确保给定的map覆盖了子模块所需要的所有Provider。这避免了显式赋值与隐式继承混用时带来的混乱和意外。 额外的Provider配置(使用alias参数的)将永远不会被子模块隐式继承，所以必须显式通过providers传递。比如，一个模块配置了两个AWS区域之间的网络打通，所以需要配置一个源区域Provider和目标区域Provider。这种情况下，根模块代码看起来是这样的： provider \"aws\" { alias = \"usw1\" region = \"us-west-1\" } provider \"aws\" { alias = \"usw2\" region = \"us-west-2\" } module \"tunnel\" { source = \"./tunnel\" providers = { aws.src = aws.usw1 aws.dst = aws.usw2 } } 子目录./tunnel必须包含像下面的例子那样声明\"Provider代理\"，声明模块调用者必须用这些名字传递的Provider配置： provider \"aws\" { alias = \"src\" } provider \"aws\" { alias = \"dst\" } ./tunnel模块中的每一种资源都应该通过provider参数声明它使用的是aws.src还是aws.dst。 Provider代理配置块 一个Provider代理配置只包含alias参数，它就是一个模块间传递Provider配置的占位符，声明了模块期待显式传递的额外(带有alias的)Provider配置。 需要注意的是，一个完全为空的Provider配置块也是合法的，但没有必要。只有在模块内需要带alias的Provider时才需要代理配置块。如果模块中只是用默认Provider时请不要声明代理配置块，也不要仅为了声明Provider版本约束而使用代理配置块。 "},"4.3.模块元参数.html":{"url":"4.3.模块元参数.html","title":"模块元参数","keywords":"","body":"模块元参数 在 Terraform 0.13 之前，模块在使用上存在一些限制。例如我们通过模块来创建 EC2 主机，可以这样： module \"ec2_instance\" { source = \"terraform-aws-modules/ec2-instance/aws\" version = \"~> 3.0\" name = \"single-instance\" ami = \"ami-ebd02392\" instance_type = \"t2.micro\" key_name = \"user1\" monitoring = true vpc_security_group_ids = [\"sg-12345678\"] subnet_id = \"subnet-eddcdzz4\" tags = { Terraform = \"true\" Environment = \"dev\" } } 如果我们要创建两台这样的主机怎么办？在 Terraform 0.13 之前的版本中，由于 Module 不支持元参数，所以我们只能手动拷贝模块代码： module \"ec2_instance_0\" { source = \"terraform-aws-modules/ec2-instance/aws\" version = \"~> 3.0\" name = \"single-instance-0\" ami = \"ami-ebd02392\" instance_type = \"t2.micro\" key_name = \"user1\" monitoring = true vpc_security_group_ids = [\"sg-12345678\"] subnet_id = \"subnet-eddcdzz4\" tags = { Terraform = \"true\" Environment = \"dev\" } } module \"ec2_instance_1\" { source = \"terraform-aws-modules/ec2-instance/aws\" version = \"~> 3.0\" name = \"single-instance-1\" ami = \"ami-ebd02392\" instance_type = \"t2.micro\" key_name = \"user1\" monitoring = true vpc_security_group_ids = [\"sg-12345678\"] subnet_id = \"subnet-eddcdzz4\" tags = { Terraform = \"true\" Environment = \"dev\" } } 自从 Terraform 0.13 开始，模块也像资源一样，支持count、for_each、depends_on三种元参数。比如我们可以这样： module \"ec2_instance\" { count = 2 source = \"terraform-aws-modules/ec2-instance/aws\" version = \"~> 3.0\" name = \"single-instance-${count.index}\" ami = \"ami-ebd02392\" instance_type = \"t2.micro\" key_name = \"user1\" monitoring = true vpc_security_group_ids = [\"sg-12345678\"] subnet_id = \"subnet-eddcdzz4\" tags = { Terraform = \"true\" Environment = \"dev\" } } 要注意的是 Terraform 0.13 之后在模块上声明depends_on，列表中也可以传入另一个模块。声明depends_on的模块中的所有资源的创建都会发生在被依赖的模块中所有资源创建完成之后。 "},"4.4.重构.html":{"url":"4.4.重构.html","title":"重构","keywords":"","body":"重构 请注意，本节介绍的通过 moved 块进行模块重构的功能是从 Terraform v1.1 开始被引入的。如果要在之前的版本进行这样的操作，必须通过 terraform state mv 命令来完成。 对一些旨在被人复用的老模块来说，最初的模块结构和资源名称可能会逐渐变得不再合适。例如，我们可能发现将以前的一个子模块分割成两个单独的模块会更合理，这需要将现有资源的一个子集移动到新的模块中。 Terraform 将以前的状态与新代码进行比较，资源与每个模块或资源的唯一地址相关联。因此，默认情况下，移动或重命名对象会被 Terraform 理解为销毁旧地址的对象并在新地址创建新的对象。 当我们在代码中添加 moved 块以记录我们移动或重命名对象过去的地址时，Terraform 会将旧地址的现有对象视为现在属于新地址。 moved 块语法 moved 块只包含 from 和 to 参数，没有名称： moved { from = aws_instance.a to = aws_instance.b } 上面的例子演示了模块先前版本中的 aws_instance.a 如今以 aws_instance.b 的名字存在。 在为 aws_instance.b 创建新的变更计划之前，Terraform 会首先检查当前状态中是否存在地址为 aws_instance.a 的记录。如果存在该记录，Terraform 会将之重命名为 aws_instance.b 然后继续创建变更计划。最终生成的变更计划中该对象就好像一开始就是以 aws_instance.b 的名字被创建的，防止它在执行变更时被删除。 from 和 to 的地址使用一种特殊的地址语法，该语法允许选定模块、资源以及子模块中的资源。下面是几种不同的重构场景中所需要的地址语法： 重命名一个资源 考虑模块代码中这样一个资源： resource \"aws_instance\" \"a\" { count = 2 # (resource-type-specific configuration) } 第一次应用该代码时 Terraform 会创建 aws_instance.a[0] 以及 aws_instance.a[1]。 如果随后我们修改了该资源的名称，并且把旧名字记录在一个 moved 块里： resource \"aws_instance\" \"b\" { count = 2 # (resource-type-specific configuration) } moved { from = aws_instance.a to = aws_instance.b } 当下一次应用使用了该模块的代码时，Terraform 会把所有地址为 aws_instance.a 的对象看作是一开始就以 aws_instance.b 的名字创建的：aws_instance.a[0] 会被看作是 aws_instance.b[0]，aws_instance.a[1] 会被看作是 aws_instance.b[1]。 新创建的模块实例中，因为从来就不存在 aws_instance.a，于是会忽略 moved 块而像通常那样直接创建 aws_instance.b[0] 以及 aws_instance.b[1]。 为资源添加 count 或 for_each 声明 一开始代码中有这样一个单实例资源： resource \"aws_instance\" \"a\" { # (resource-type-specific configuration) } 应用该代码会使得 Terraform 创建了一个地址为 aws_instance.a 的资源对象。 随后我们想要在该资源上添加 for_each 来创建多个实例。为了保持先前关联到 aws_instance.a 的资源对象不受影响，我们必须添加一个 moved 块来指定新代码中原先的对象实例所关联的键是什么： locals { instances = tomap({ big = { instance_type = \"m3.large\" } small = { instance_type = \"t2.medium\" } }) } resource \"aws_instance\" \"a\" { for_each = local.instances instance_type = each.value.instance_type # (other resource-type-specific configuration) } moved { from = aws_instance.a to = aws_instance.a[\"small\"] } 上面的代码会防止 Terraform 在变更计划中销毁已经存在的 aws_instance.a 对象，并且将其看作是以 aws_instance.a[\"small\"] 的地址创建的。 当 moved 块的两个地址中的至少一个包含实例键时，如上例中的 [\"small\"]，Terraform 将这两个地址理解为引用资源的特定实例而不是整个资源。这意味着您可以使用 moved 在键之间切换以及在 count、for_each 之间切换时添加和删除键。 下面的例子演示了几种其他类似的记录了资源实例键变更的合法 moved 块： # Both old and new configuration used \"for_each\", but the # \"small\" element was renamed to \"tiny\". moved { from = aws_instance.b[\"small\"] to = aws_instance.b[\"tiny\"] } # The old configuration used \"count\" and the new configuration # uses \"for_each\", with the following mappings from # index to key: moved { from = aws_instance.c[0] to = aws_instance.c[\"small\"] } moved { from = aws_instance.c[1] to = aws_instance.c[\"tiny\"] } # The old configuration used \"count\", and the new configuration # uses neither \"count\" nor \"for_each\", and you want to keep # only the object at index 2. moved { from = aws_instance.d[2] to = aws_instance.d } 注意：当我们在原先没有声明 count 的资源上添加 count 时，Terraform 会自动将原先的对象移动到第 0 个位置，除非我们通过一个 moved 块显式声明该资源。然而，我们建议使用 moved 块显式声明资源的移动，使得读者在未来阅读模块的代码时能够更清楚地了解到这些变更。 重命名对模块的调用 我们可以用类似重命名资源的方式来重命名对模块的调用。假设我们开始用以下代码调用一个模块： module \"a\" { source = \"../modules/example\" # (module arguments) } 当应用该代码时，Terraform 会在模块内声明的资源路径前面加上一个模块路径前缀 module.a。比方说，模块内的 aws_instance.example 的完整地址为 module.a.aws_instance.example。 如果我们随后打算修改模块名称，我们可以直接修改 module 块的标签，并且在一个 moved 块内部记录该变更： module \"b\" { source = \"../modules/example\" # (module arguments) } moved { from = module.a to = module.b } 当下一次应用包含该模块调用的代码时，Terraform 会将所有路径前缀为 module.a 的对象看作从一开始就是以 module.b 为前缀创建的。module.a.aws_instance.example 会被看作是 module.b.aws_instance.example。 该例子中的 moved 块中的两个地址都代表对模块的调用，而 Terraform 识别出将原模块地址中所有的资源移动到新的模块地址中。如果该模块声明时使用了 count 或是 for_each，那么该移动也将被应用于所有的实例上，不需要逐个指定。 为模块调用添加 count 或 for_each 声明 考虑一下单实例的模块： module \"a\" { source = \"../modules/example\"q # (module arguments) } 应用该段代码会导致 Terraform 创建的资源地址都拥有 module.a 的前缀。 随后如果我们可能需要再通过添加 count 来创建多个资源实例。为了保留先前的 aws_instance.a 实例不受影响，我们可以添加一个 moved 块来设置在新代码中该实例的对应的键。 module \"a\" { source = \"../modules/example\" count = 3 # (module arguments) } moved { from = module.a to = module.a[2] } 上面的代码引导 Terraform 将所有 module.a 中的资源看作是从一开始就是以 module.a[2] 的前缀被创建的。结果就就是，Terraform 生成的变更计划中只会创建 module.a[0] 以及 module.a[1]。 当 moved 块的两个地址中的至少一个包含实例键时，例如上面例子中的 [2]那样，Terraform 会理解将这两个地址理解为对模块的特定实例的调用而非对模块所有实例的调用。这意味着我们可以使用 moved 块在不同键之间切换来添加或是删除键，该机制可用于 count 和 for_each，或删除模块上的这种声明。 将一个模块分割成多个模块 随着模块提供的功能越来越多，最终模块可能变得过大而不得不将之拆分成两个独立的模块。 我们看一下下面的这个例子： resource \"aws_instance\" \"a\" { # (other resource-type-specific configuration) } resource \"aws_instance\" \"b\" { # (other resource-type-specific configuration) } resource \"aws_instance\" \"c\" { # (other resource-type-specific configuration) } 我们可以将该模块分割为三个部分： aws_instance.a 现在归属于模块 \"x\"。 aws_instance.b 也属于模块 \"x\"。 aws_instance.c 现在归属于模块 \"y\"。 要在不替换绑定到旧资源地址的现有对象的情况下实现此重构，我们需要： 编写模块 \"x\"，将属于它的两个资源拷贝过去。 编写模块 \"y\"，将属于它的一个资源拷贝过去。 编辑原有模块代码，删除这些资源，只包含有关迁移现有资源的非常简单的配置代码。 新的模块 \"x\" 和 \"y\" 应该只包含 resource 块： # module \"x\" resource \"aws_instance\" \"a\" { # (other resource-type-specific configuration) } resource \"aws_instance\" \"b\" { # (other resource-type-specific configuration) } # module \"y\" resource \"aws_instance\" \"c\" { # (other resource-type-specific configuration) } 而原有模块则被修改成只包含有向下兼容逻辑的垫片，调用两个新模块，并使用 moved 块定义哪些资源被移动到新模块中去了： module \"x\" { source = \"../modules/x\" # ... } module \"y\" { source = \"../modules/y\" # ... } moved { from = aws_instance.a to = module.x.aws_instance.a } moved { from = aws_instance.b to = module.x.aws_instance.b } moved { from = aws_instance.c to = module.y.aws_instance.c } 当一个原模块的调用者升级模块版本到这个“垫片”版本时，Terraform 会注意到这些 moved 块，并将那些关联到老地址的资源对象看作是从一开始就是由新模块创建的那样。 该模块的新用户可以选择使用这个垫片模块，或是独立调用两个新模块。我们需要通知老模块的现有用户老模块已被废弃，他们将来的开发中需要独立使用这两个新模块。 多模块重构的场景是不多见的，因为它违反了父模块将其子模块视为黑盒的典型规则，不知道在其中声明了哪些资源。这种妥协的前提是假设所有这三个模块都由同一个人维护并分布在一个模块包中。 为避免独立模块之间的耦合，Terraform 只允许声明在同一个目录下的模块间的移动。换句话讲，Terraform 不允许将资源移动到一个 source 地址不是本地路径的模块中去。 Terraform 使用定义 moved 块的模块实例的地址的地址来解析 moved 块中的相对地址。例如，如果上面的原模块已经是名为 module.original 的子模块，则原模块中对 module.x.aws_instance.a 的引用在根模块中将被解析为 module.original.module.x.aws_instance.a。一个模块只能针对它自身或是它的子模块中的资源声明 moved 块。 如果需要引用带有 count 或 for_each 元参数的模块中的资源，则必须指定要使用的特定实例键以匹配资源配置的新位置： moved { from = aws_instance.example to = module.new[2].aws_instance.example } 删除 moved 块 随着时间的推移，一些老模块可能会积累大量 moved 块。 删除 moved 块通常是一种破坏性变更，因为删除后所有使用旧地址引用的对象都将被删除而不是被移动。我们强烈建议保留历史上所有的 moved 块来保存用户从任意版本升级到当前版本的升级路径信息。 如果我们决定要删除 moved 块，需要谨慎行事。对于组织内部的私有模块来说删除 moved 块可能是安全的，因为我们可以确认所有用户都已经使用新版本模块代码运行过 terraform apply 了。 如果我们需要多次重命名或是移动一个对象，我们建议使用串联的 moved 块来记录完整的变更信息，新的块引用已有的块： moved { from = aws_instance.a to = aws_instance.b } moved { from = aws_instance.b to = aws_instance.c } 像这样记录下移动的序列可以使 aws_instance.a 以及 aws_instance.b 两种地址的资源都得到成功更新，Terraform 会将他们视作从一开始就是以 aws_instance.c 的地址创建的。 "},"4.5.设计新模块的模式.html":{"url":"4.5.设计新模块的模式.html","title":"设计新模块的模式","keywords":"","body":"设计新模块的模式 Terraform 模块是独立的基础设施即代码片段，抽象了基础设施部署的底层复杂性。Terraform 用户通过使用预置的配置代码加速采用 IaC，并降低了使用门槛。所以，模块的作者应尽量遵循诸如清晰的代码结构以及 DRY(\"Dont't Repeat Yourself\")原则的代码最佳实践。 本篇指导讨论了模块架构的原则，用以帮助读者编写易于组合、易于分享及重用的基础设施模块。这些架构建议对使用任意版本 Terraform 的企业都有助益，某些诸如“私有模块注册表(Registry)”的模式仅在 Terraform Cloud 以及企业版中才能使用。（本文不对相关内容进行翻译） 本文是对 Terraform 模块文档的补充和扩展。 通过阅读文本，读者可以： 学习有关 Terraform 模块创建的典型工作流程和基本原则。 探索遵循这些原则的示例场景。 学习如何通过协作改进 Terraform 模块 了解如何创建一套使用模块的工作流程。 模块创建的工作流 要创建一个新模块，第一步是寻找一个早期采纳者团队，收集他们的需求。 与这支早期采纳团队一起工作使我们可以通过使用输入变量以及输出值来确保模块足够灵活，从而打磨模块的功能。此外，还可以用最小的代码变更代价吸纳其他有类似需求的团队加入进来。这消除了代码重复，并缩短了交付时间。 完成以上任务后，需要谨记两点： 将需求范围划分成合适的模块。 创建模块的最小可行产品(Minimum Viable Product, MVP) 将需求范围划分成合适的模块 创建新 Terraform 模块时最具挑战的方面之一是决定要包含哪些基础设施资源。 模块设计应该是有主见的，并且被设计成能很好地完成一个目标。如果一个模块的功能或目的很难解释，那么这个模块可能太复杂了。在最初确定模块的范围时，目标应当足够小且简单，易于开始编写。 当构建一个模块时，需要考虑以下三个方面： 封装：一组始终被一起部署的基础设施资源 在模块中包含更多的基础设施资源简化了终端用户部署基础设施的工作，但会使得模块的目的与需求变得更难理解。 职责：限制模块职责的边界 如果模块中的基础设施资源由多个组来负责，使用该模块可能会意外违反职责分离原则。模块中仅包含职责边界内的一组资源可以提升基础设施资源的隔离性，并保护我们的基础设施。 变化频率：隔离长短生命周期基础设施资源 举例来说，数据库基础设施资源相对来说较为静态，而团队可能在一天内多次部署更新应用程序服务器。在同一个模块中同时管理数据库与应用程序服务器使得保存状态数据的重要基础设施没有必要地暴露在数据丢失的风险之中。 创建模块的最小可行产品 如同所有类型的代码一样，模块的开发永远不会完成，永远会有新的模块需求以及变更。拥抱变化，最初的模块版本应致力于满足最小可行产品（MVP）的标准。以下是在设计最小可行产品时需要谨记的指导清单： 永远致力于交付至少可以满足 80% 场景的模块 模块中永远不要处理边缘场景。边缘场景是很少见的。一个模块应该是一组可重用的代码。 在最小可行产品中避免使用条件表达式。最小可行产品应缩小范围，不应该同时完成多种任务。 模块应该只将最常被修改的参数公开为输入变量。一开始时，模块应该只提供最可能需要的输入变量。 尽可能多输出 在最小可行产品中输出尽可能多的信息，哪怕目前没有用户需要这些信息。这使得那些通常使用多个模块的终端用户在使用该模块时更加轻松，可以使用一个模块的输出作为下一个模块的输入。 请记住在模块的 README 文档中记录输出值的文档。 探索遵循这些原则的一个示例场景 某团队想要通过 Terraform 创建一套包含 Web 层应用、App 层应用的基础设施。 他们想要使用一个专用的 VPC，并遵循传统的三层架构设计。他们的 Web 层应用需要一个自动伸缩组（AutoScaling Group）。他们的 App 层服务需要一个自动伸缩组，一个 S3 存储桶以及一个数据库。下面的架构图描述了期望的结果： 该场景中，一个负责从零开始撰写 Terraform 代码的团队，负责编写一组用以配置基础设施及应用的模块。负责应用程序的团队成员将使用这些模块来配置他们需要的基础设施。 请注意，虽然该示例使用了 AWS 命名，但所描述的模式适用于所有云平台。 经过对应用程序团队的需求进行审核，模块团队将该应用基础设施分割成如下模块：网络、Web、App、数据库、路由，以及安全。 当 Terraform 模块团队完成模块开发后，他们应该将模块导入到私有模块注册表中，并且向对应的团队成员宣传模块的使用方法。举例来说，负责网络的团队成员将会使用开发的网络模块来部署和配置相应的应用程序网络。 网络模块 网络模块负责网络基础设施。它包含了网络访问控制列表（ACL）以及 NAT 网关。它也可以包含应用程序所需的 VPC、子网、对等连接以及 Direct Connect 等。 该模块包含这些资源是因为它们需要特定权限并且变化频率较低。 只有应用程序团队中有权创建或修改网络资源的成员可以使用该模块。 该模块的资源不会经常变更。将它们组合在单独的模块中可以保护它们免于暴露在没有必要的数据丢失的风险之中。 网络模块返回一组其他工作区（Workspace）以及模块可以使用的输出值。如果 VPC 的创建过程是由多个方面组成的，我们可能最终会需要将该模块进一步切割成拥有不同功能的不同模块。 应用程序模块 本场景中有两个应用程序模块 —— 一个是 Web 层模块，另一个是 App 层模块。 Terraform 模块团队完成这两个模块的开发后，它们应被分发给对应的团队成员来部署他们的应用。随着应用程序团队的成员变得越来越熟悉 Terraform 代码，它们可以提出基础设施方面的增强建议，或是通过 Pull Request 配合他们自己的应用代码发布提交对基础设施的变更请求。 Web 模块 Web 模块创建和管理运行 Web 应用程序所需的基础设施。它包含了负载均衡器和自动伸缩组，同时也可以包含应用程序中使用的 EC2 虚拟机实例、S3 存储桶、安全组，以及日志系统。该模块接收一个通过 Packer 预构建的包含最新 Web 层应用发布版本代码的虚拟机镜像的 AMI ID 作为输入。 该模块包含这些资源是因为它们是高度封装的，并且它们变化频率较高。 此模块中的资源高度内聚，并且与 Web 应用程序紧密相关（例如，此模块需要一个包含最新 Web 层应用程序代码版本的 AMI）。结果就是它们被编制进同一个模块，这样 Web 应用团队的成员们就可以轻松地部署它们。 该模块的资源变更频率较高（每次发布更新版本都需要更新对应基础设施资源）。通过将它们组合在单独的模块中，我们降低了将其他模块的资源暴露在没有必要的数据丢失的风险中的可能性。 App 模块 App 模块创建和管理运行 App 层应用所需的基础设施。它包含了负载均衡器和自动伸缩组，同时也包含了应用程序中使用的 EC2 虚拟机实例、S3 存储桶、安全组，以及日志系统。该模块接收一个通过 Packer 预构建的包含最新 App 层应用发布版本代码的虚拟机镜像的 AMI ID 作为输入。 该模块包含这些资源是因为它们是高度封装的，并且它们变化频率较高。 此模块中的资源高度内聚，并且与 App 应用程序紧密相关。结果就是它们被编制进同一个模块，这样 App 层应用团队的成员们就可以轻松地部署它们。 该模块的资源变更频率较高（每次发布更新版本都需要更新对应基础设施资源）。通过将它们组合在单独的模块中，我们降低了将其他模块的资源暴露在没有必要的数据丢失的风险中的可能性。 数据库模块 数据库模块创建并管理了运行数据库所需的基础设施资源。它包含了应用程序所需的 RDS 实例，也包含了所有关联的存储、备份以及日志资源。 该模块包含这些资源是因为它们需要特定权限并且变化频率较低。 只有应用程序团队中有权创建或修改数据库资源的成员可以使用该模块。 该模块的资源不会经常变更。将它们组合在单独的模块中可以保护它们免于暴露在没有必要的数据丢失的风险之中。 路由模块 路由模块创建并管理网络路由所需的基础设施资源。它包含了公共托管区域（Hosted Zone）、Route 53 以及路由表，也可以包含私有托管区域。 该模块包含这些资源是因为它们需要特定权限并且变化频率较低。 只有应用程序团队中有权创建或修改路由资源的成员可以使用该模块。 该模块的资源不会经常变更。将它们组合在单独的模块中可以保护它们免于暴露在没有必要的数据丢失的风险之中。 安全模块 安全模块创建并管理所有安全所需的基础设施资源。它包含一组 IAM 资源，也可以包含安全组（Security Group）及多因素认证（MFA）。 该模块包含这些资源是因为它们需要特定权限并且变化频率较低。 只有应用程序团队中有权创建或修改 IAM 或是安全资源的成员可以使用该模块。 该模块的资源不会经常变更。将它们组合在单独的模块中可以保护它们免于暴露在没有必要的数据丢失的风险之中。 创建模块的提示 除了范围界定之外，我们在创建模块时还应牢记以下几点： 嵌套模块 嵌套模块是指在当前模块中对另一个模块的引用。嵌套模块可以是外部的，也可以是当前工作空间内的。使用嵌套模块是一项强大的功能；然而我们必须谨慎实践以避免引入错误。 对于所有类型的嵌套模块，请考虑以下事项： 嵌套模块可以加速开发速度，但可能会引发未知以及意料之外的结果。请在文档中清晰地记录输入变量、模块行为以及输出值。 通常来说，不要让主模块的嵌套深度超过两层。常用且简单的工具模块，例如专门用来定义 Tag 的模块，则不受此限制制约。 嵌套模块必须包含必要的用来创建指定的资源配置的输入参数以及输出值。 输入参数以及输出值的命名应遵循一致的命名约定，以使得模块可以更容易地被分享，以及将一个模块的的输出值作为另一个模块的输入参数。 嵌套模块可能会导致代码冗余。必须同时在父模块与嵌套模块中声明输入参数和输出值。 嵌套的外部模块 当我们需要使用那些定义了被多个应用程序堆栈、应用程序和团队复用的标准化资源的通用模块时，嵌套的外部模块会很有用。外部模块通被集中管理和版本化控制，以使得消费者在使用新版本之前可以对其进行验证。当我们依赖或希望使用位于外部的子模块时，请注意以下几点： 外部模块必须被独立维护，并可供任何需要调用它的模块使用。使用模块注册表可以确保这一点。 根据模块注册要求，嵌套模块将拥有自己的版本控制代码仓库，独立于调用模块进行版本控制。 对嵌套模块的变更可能会影响调用模块，即使调用模块的调用代码及版本没有发生变化，这会破坏调用代码的信任。 对调用模块如何使用外部模块在文档中进行记录，使得模块行为以及调用关系可以被轻松理解。 对外部模块的变更应该是向后兼容的。如果向后兼容是不可能的，则应清楚地记录需要对任何调用模块进行的更改，并将之分发给所有模块使用者以避免意外。 嵌套的嵌入模块 在当前工作空间中嵌入一个模块使得我们能够清晰地分离模块的逻辑组件，或是创建可在调用模块执行期间多次调用的可重用代码块。在下面的例子中，ec2-instance 是一个嵌入模块，根模块的 main.tf 引用了该模块： root-module-directory ├── README.md ├── main.tf └── ec2-instances └── main.tf 如果我们需要或者倾向于使用嵌入模块，需要考虑以下几点： 在“根模块”中添加嵌入模块意味着子模块与根模块被放在一起进行版本控制。 任何影响两个模块间兼容性的变更都会被快速发现，因为它们必须被一同测试和发布。 （嵌入的）子模块不能被代码树之外的其他模块调用，所以可能会增加重复的代码。举例来说，如果嵌入的 ec2-instance 模块是用来创建一台被用在多个地方的标准化的计算实例，该模块无法以这种形式被分享。 标签化模块名并记录在文档中 为我们的模块创建并遵循一个命名约定将使得模块易于理解与使用。这将促进模块的采用和贡献。以下是一个用以提升模块元素一致性的建议列表： 使用一个对人类来说一致且易于理解的模块命名约定。举例来说： terraform cloud provider function full name terraform aws consul cluster terraform-aws-consul_cluser terraform aws security module terraform-aws-security terraform azure database terraform-azure-database 使用人类可以理解的输入变量命名约定。模块是编写一次并多次使用的代码，因此请完整命名所有内容以提升可读性，并在编写代码时在文档中进行记录。 对所有模块进行文档记录。确保文档中包含有： 必填的输入变量：这些输入变量应该是经过深思熟虑后的选择。如果这些输入变量值未定义，模块运行将失败。只在必要时为这些输入变量设置默认值。例如 var.vpc_id 永远不应该有默认值，因为每次使用模块时值都会不同。 可选的输入变量：这些输入变量应该有一个合理的，适用于大多数场景的默认值，同时又可以根据需求进行调整。公告输入变量的默认值。例如 var.elb_idle_timeout 会有一个合理的默认值，但调用者也可以根据需求修改它的值。 输出值：列出模块的所有输出值，并将重要的输出和信息性的输出包装在对用户友好的输出模板中。 定义并使用一个一致的模块结构 虽然模块结构是一个品味问题，我们应当将模块的结构记录在文档中，并且在我们的所有模块之间保持统一的结构。为了要维持模块结构的一致： 定义一组模块必须包含的 .tf 文件，定义它们应包含哪些内容 为模块定义一个 .gitignore(或类似作用的)文件 创建供样例代码所使用的输入变量值的标准方式（例如一个 terraform.tfvars.example 文件） 使用具有固定子目录的一致的目录结构，即使它们可能是空的 所有模块目录都必须包含一个 README 文件详细记述目录存在的目的以及如何使用其中的文件 模块的协作 随着团队模块的开发工作，简化我们的协作。 为每个模块创建路线图 从用户处收集需求信息，并按受欢迎程度进行优先级排序。 不使用模块的最常见原因是“它不符合我的要求”。收集这些需求并将它们添加到路线图或对用户的工作流程提出建议。 检查每一项需求以确认它引用的用例是否正确。 公布和维护需求列表。分享该列表并让用户参与列表管理过程。 不要为边缘用例排期。 将每一个决策记录进文档。 在公司内部采用开源社区原则。一些用户希望尽可能高效地使用这些模块，而另一些用户则希望帮助创建这些模块。 创建一个社区 维护一份清晰和公开的贡献指引 最终，我们将允许可信的社区成员获得某些模块的所有权 使用源代码控制系统追踪模块 一个 Terraform 模块应遵守所有良好的代码实践： 将模块置于源代码控制中以管理版本发布、协作、变更的审计跟踪。 为所有 main 分支的发布版本建立版本标签，记录文档（最起码在 CHANGELOG 及 README 中记录）。 对 main 分支的所有变更进行代码审查 鼓励模块的用户通过版本标签引用模块 为每一个模块指派一位负责人 一个代码仓库只负责一个模块 这对于模块的幂等性和作为库的功能至关重要。 我们应该对模块打上版本标签或是版本化控制。打上版本标签或是版本化的模块应该是不可变的。 发布到私有模块注册表的模块必须要有版本标签。 开发一套模块消费工作流 定义和宣传一套消费者团队使用模块时应遵循的可重复工作流程。这个工作流程，就像模块本身一样，应该考虑到用户的需求。 阐明团队应该如何使用模块 分散的安全性：如果每个模块都在自己的存储库中进行版本控制，则可以使用存储库 RBAC 来管理谁拥有写访问权限，从而允许相关团队管理相关的基础设施（例如网络团队拥有对网络模块的写访问权限）。 培育代码社区：鉴于上述建议，模块开发的最佳实践是允许对存储在私有模块存储库中的模块的所有模块存储库提出 Pull Request。这促进了组织内的代码社区，保持模块内容的相关性和最大的灵活性，并有助于保持模块注册表的长期有效性。 "},"5.Terraform命令行.html":{"url":"5.Terraform命令行.html","title":"Terraform命令行","keywords":"","body":"Terraform命令行 我们在前面的的章节中主要介绍了如何书写和组织Terraform代码，下面我们要介绍一下如何使用Terraform命令行工具来应用这些代码，并且管理和操作我们的云端基础设施。 Terraform是用Go语言编写的，所以它的交付物只有一个可执行命令行文件：terraform。在Terraform执行发生错误时，terraform进程会返回一个非零值，所以在脚本代码中我们可以轻松判断执行是否成功。 我们可以在命令行中输入terraform来查看所有可用的子命令： $ terraform Usage: terraform [-version] [-help] [args] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you're just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. Common commands: apply Builds or changes infrastructure console Interactive console for Terraform interpolations destroy Destroy Terraform-managed infrastructure env Workspace management fmt Rewrites config files to canonical format get Download and install modules for the configuration graph Create a visual graph of Terraform resources import Import existing infrastructure into Terraform init Initialize a Terraform working directory login Obtain and save credentials for a remote host logout Remove locally-stored credentials for a remote host output Read an output from a state file plan Generate and show an execution plan providers Prints a tree of the providers used in the configuration refresh Update local state file against real resources show Inspect Terraform state or plan taint Manually mark a resource for recreation untaint Manually unmark a resource as tainted validate Validates the Terraform files version Prints the Terraform version workspace Workspace management All other commands: 0.12upgrade Rewrites pre-0.12 module source code for v0.12 0.13upgrade Rewrites pre-0.13 module source code for v0.13 debug Debug output management (experimental) force-unlock Manually unlock the terraform state push Obsolete command for Terraform Enterprise legacy (v1) state Advanced state management 通过 -chdir 参数切换工作目录 运行Terraform时一般要首先切换当前工作目录到包含有想要执行的根模块.tf代码文件的目录下（比如使用cd命令），这样Terraform才能够自动发现要执行的代码文件以及参数文件。 在某些情况下——尤其是将Terraform封装进某些自动化脚本时，如果能够从其他路径直接执行特定路径下的根模块代码将会十分的方便。为了达到这一目的，Terraform目前支持一个全局参数-chdir=...，你可以在任意子命令的参数中使用该参数指定要执行的代码路径： $ terraform -chdir=environments/production apply -chdir参数指引Terraform在执行具体子命令之前切换工作目录，这意味着使用该参数后Terraform将会在指定路径下读写文件，而非当前工作目录下的文件。 在两种场景下Terraform会坚持使用当前工作目录而非指定的目录，即使是我们通过-chdir指定了一个目标路径： Terraform处理命令行配置文件中的设置而非执行某个具体的子命令时，该阶段发生在解析-chdir参数之前 如果你需要使用当前工作目录下的文件作为你配置的一部分时，你可以通过在代码中使用path.cwd变量获得对当前工作路径的引用，而不是-chdir所指定的路径。可以通过使用path.root来获取代表根模块所在的路径。 自动补全 如果你使用的是bash或是zsh，那么可以轻松安装自动补全： $ terraform -install-autocomplete 卸载自动补全也很容易： $ terraform -uninstall-autocomplete 目前自动补全并没有覆盖到所有子命令。 版本信息 Terraform命令行会与HashiCorp的Checkpoint服务交互来检查当前版本是否有更新或是关键的安全公告。 可以通过执行terraform version命令来检查是否有新版本可用。 Checkpoint服务 Terraform会收集一些不涉及用户身份信息或是主机信息的数据发送给Checkpoint服务。一个匿名ID会被发送到Checkpoint来消除重复的告警信息。我们可以关闭与Checkpoint的交互。 我们可以设置CHECKPOINT_DISABLE环境变量的值为任意非空值来完全关闭HashiCorp所有产品与Checkpoint的交互。另外，我们也可以通过设置命令行配置文件来关闭这些功能： disable_checkpoint：设置为true可以完全关闭与Checkpoint的交互 disable_checkpoint_signature：设置为true可以阻止向Checkpoint发送匿名ID "},"5.1.命令行配置文件.html":{"url":"5.1.命令行配置文件.html","title":"命令行配置文件","keywords":"","body":"命令行配置文件(.terraformrc或terraform.rc) 命令行配置文件为每个用户配置了命令行的行为，适用于所有的Terraform工作目录，这与我们编写的Terraform代码是分开的。 位置 配置文件的位置取决于用户使用的操作系统： Windows平台上，文件名必须是terraform.rc，位置必须在相关用户的%APPDATA%目录下。这个目录的物理路径取决于Windows的版本以及系统配置；在PowerShell中查看$env:APPDATA可以找到对应的路径 在其他操作系统上，文件名必须是.terraformrc(注意第一个是\".\")，位置必须是在相关用户的HOME目录 在Windows上创建配置文件时，要注意Windows Explorer默认隐藏文件扩展名的行为。Terraform不会把terraform.rc.txt文件识别为命令行配置文件，而默认情况下Windows Explorer会将它的文件名显示为terraform.rc(隐藏了扩展名的缘故)。可以在PowerShell或命令行中使用dir命令来确认文件名。 可以通过设置TF_CLI_CONFIG_FILE环境变量的方式来修改配置文件的位置。 配置文件语法 配置文件本身如同.tf文件那样也采用HCL语法，但使用不同的属性和块。以下是常见语法的演示，后续的部分会详细介绍这些配置项： plugin_cache_dir = \"$HOME/.terraform.d/plugin-cache\" disable_checkpoint = true 可用配置 命令行配置文件中可以设置的配置项有： credentials：使用Terraform Cloud服务或Terraform企业版时使用的凭据 credentials_helper：配置一个外部的用于读写Terraform Cloud或Terraform企业版凭据的帮助程序 disable_checkpoint：设置为true可以完全关闭与Checkpoint的交互 disable_checkpoint_signature：设置为true可以阻止向Checkpoint发送匿名ID plugin_cache_dir：开启插件缓存，我们在介绍Provider的章节中介绍过 provider_installation：定制化执行terraform init时安装插件的行为 鉴于本教程无意涉及与Terraform Cloud或企业版相关的部分，所以我们会略过对credentials和credentials_helper的介绍；插件缓存的相关知识我们在Provider章节中已做过介绍，在此先偷懒略过。感兴趣的读者可以自行查阅相关文档 Provider的安装 默认情况下Terraform从官方Provider Registry下载安装Provider插件。Provider在Registry中的原始地址采用类似registry.terraform.io/hashicorp/aws的编码规则。通常为了简便，Terraform允许省略地址中的主机名部分registry.terraform.io，所以我们可以直接使用地址hashicorp/aws。 有时无法直接从官方Registry下载插件，例如我们要在一个与公网隔离的环境中运行Terraform时。为了允许Terraform工作在这样的环境下，有一些可选方法允许我们从其他地方获取Provider插件。 显式安装方法配置 可以在命令行配置文件中定义一个provider_installation块来修改Terraform默认的插件安装行为，命令Terraform使用本地的Registry镜像服务，或是使用一些用户修改过的插件。 通常provider_installation块的结构如下： provider_installation { filesystem_mirror { path = \"/usr/share/terraform/providers\" include = [\"example.com/*/*\"] } direct { exclude = [\"example.com/*/*\"] } } provider_installation块中每一个内嵌块都指定了一种安装方式。每一种安装方式都可以同时包含include与exclude模式来指定安装方式使用的Provider类型。在上面的例子里，我们把所有原先位于example.com这个Registry存储中的Provider设置成只能从本地文件系统的/usr/share/terraform/providers镜像存储中寻找并安装，而其他的Provider只能从它们原先的Registry存储下载安装。 如果你为一种安装方式同时设置了include与exclude，那么exclude模式将拥有更高的优先级。举例：包含registry.terraform.io/hashicorp/*但排除registry.terraform.io/hashicorp/dns将对所有hashicorp空间下的插件有效，但是hashicorp/dns除外。 和Terraform代码文件中Provider的source属性一样的是，在provider_installation里你也可以省略registry.terraform.io/的前缀，甚至是使用通配符时亦是如此。比如，registry.terraform.io/hashicorp/*和hashicorp/*是等价的；*/*是registry.terraform.io/*/*的缩写，而不是*/*/*的缩写。 目前支持的安装方式如下： direct：要求直接从原始的Registry服务下载。该方法不需要额外参数。 filesystem_mirror：一个本地存有Provider插件拷贝的目录。该方法需要一个额外的参数path来指定存有插件拷贝的目录路径。 Terraform期待给定路径的目录内通过路径来描述插件的一些元信息。支持一下两种目录结构： 打包式布局： HOSTNAME/NAMESPACE/TYPE/terraform-provider-TYPE_VERSION_TARGET.zip的格式指定了一个从原始Registry获取的包含插件的发行版zip文件 解压式布局：HOSTNAME/NAMESPACE/TYPE/VERSION/TARGET式一个包含有Provider插件发行版zip文件解压缩后内容物的目录 这两种布局下，VERSION都是代表着插件版本的字符串，比如2.0.0；TARGET则指定了插件发行版对应的目标平台，例如darwin_amd64、linux_arm、windows_amd64等等。 如果使用解压式布局，Terraform在安装插件时会尝试创建一个到镜像目录的符号连接来避免拷贝文件夹。打包式布局则不会这样做，因为Terraform必须在安装插件时解压发行版文件。 你可以指定多个filesystem_mirror块来指定多个不同的目录。 network_mirror：指定一个HTTPS服务地址提供Provider插件的拷贝，不论这些插件原先属于哪些Registry服务。该方法需要一个额外参数url来指定镜像服务的地址，url地址必须使用https:作为前缀，以斜杠结尾。 Terraform期待该地址指定的服务实现了Provider网络镜像协议，这是一种被设计用来托管插件拷贝的网站所需要实现的协议，在此我们不展开讨论。 需要特别注意的是，请不要使用不可信的network_mirror地址。Terraform会验证镜像站点的TLS证书以确认身份，但一个拥有合法TLS证书的镜像站可能会提供包含恶意内容的插件文件。 dev_overrides：指定使用本地的开发版本插件。有时我们想要对Provider代码做一些修改，为了调试本地代码编译后的插件，可以使用dev_overrides指定使用本地编译的版本。 例如，我们想要调试本地修改过的UCloud Provider插件，我们可以从github上克隆该项目源代码，修改完代码后，编译一个可执行版本(以Mac OS为例)： $ GOOS=darwin GOARCH=arm64 go build -o bin/terraform-provider-ucloud $ chmod +x bin/terraform-provider-ucloud 然后编写如下provider_installation配置： provider_installation{ dev_overrides { \"ucloud/ucloud\" = \"PATH_TO_PROJECT/terraform-provider-ucloud/\" } } 当Terraform代码中要求了source为ucloud/ucloud的Provider时，执行terraform init仍然会报错，抱怨找不到ucloud/ucloud这个Provider，但执行terraform plan或是terraform apply等操作时可以顺利执行，此时Terraform会使用路径指定的本地Provider插件。这种方式比较适合于调试本地Provider插件代码。 对于上述的几种插件安装方式，Terraform会尝试通过include和exclude模式匹配Provider，遍历匹配的安装方式，选择一个符合Terraform代码中对插件版本约束的最新版本。如果你拥有一个插件的特定版本的本地镜像，并且你希望Terraform只使用这个本地镜像，那么你需要移除direct安装方式，或是在direct中通过exclude参数排除特定的Provider。 隐式的本地镜像目录 如果命令行配置文件中没有包含provider_installation块，那么Terraform会生成一个隐式的配置。该隐式配置包含了一个filesystem_mirror方法以及一个direct方法。 在不同的操作系统上，Terraform会选择不同的路径作为隐式filesystem_mirror路径： Windows：%APPDATA%/terraform.d/plugins以及%APPDATA%/HashiCorp/Terraform/plugins Mac OS X：$HOME/.terraform.d/plugins/，~/Library/Application Support/io.terraform/plugins以及/Library/Application Support/io.terraform/plugins Linux以及其他Unix风格系统：$HOME/.terraform.d/plugins/，以及配置的XDG基础目录后接terraform/plugins。如果没有设置XDG环境变量，Terraform会使用~/.local/share/terraform/plugins，/usr/local/share/terraform/plugins，以及/usr/share/terraform/plugins Terraform会在启动时为上述路径的每一个目录创建一个隐式filesystem_mirror块。另外如果当前工作目录下包含有terraform.d/plugins目录，那么也会为它创建一个隐式filesystem_mirror块。 相对于任意多个隐式filesystem_mirror块，Terraform同时也会创建一个隐式direct块。Terraform会扫描所有文件系统镜像目录，对找到的Provider自动从direct块中排除出去（这种自动的exclude行为只对隐式direct块有效。如果你在provider_installation块中显式指定了direct块，那么你需要自己显式定义exclude规则）。 "},"5.2.环境变量.html":{"url":"5.2.环境变量.html","title":"环境变量","keywords":"","body":"环境变量 Terraform使用一系列的环境变量来定制化各方面的行为。如果只是想简单使用Terraform，我们并不需要设置这些环境变量；但他们可以在一些不常见的场景下帮助我们改变Terraform的默认行为，或者是出于调试目的修改输出日志的级别。 TF_LOG 该环境变量可以设定Terraform内部日志的输出级别，例如： $ export TF_LOG=TRACE Terraform日志级别有TRACE、DEBUG、INFO、WARN和ERROR。TRACE包含的信息最多也最冗长，如果TF_LOG被设定为这五级以外的值时Terraform会默认使用TRACE。 如果在使用Terraform的过程中遇到未知的错误并怀疑是Terraform或相关插件的bug，请设置TF_LOG级别后收集输出的日志并提交给相关人员。 有志于获取Terraform认证的读者请注意，该知识点近乎属于必考。 TF_LOG_PATH 该环境变量可以设定日志文件保存的位置。注意，如果TF_LOG_PATH被设置了，那么TF_LOG也必须被设置。举例来说，想要始终把日志输出到当前工作目录，我们可以这样： $ export TF_LOG_PATH=./terraform.log TF_INPUT 该环境变量设置为\"false\"或\"0\"时，等同于运行terraform相关命令行命令时添加了参数-input=false。如果你想在自动化环境下避免Terraform通过命令行的交互式提示要求给定输入变量的值而是直接报错时(无default值的输入变量，无法通过任何途径获得值)可以设置该环境变量： $ export TF_INPUT=0 TF_VAR_name 我们在介绍输入变量赋值时介绍过，可以通过设置名为TF_VAR_name的环境变量来为名为\"name\"的输入变量赋值： $ export TF_VAR_region=us-west-1 $ export TF_VAR_ami=ami-049d8641 $ export TF_VAR_alist='[1,2,3]' $ export TF_VAR_amap='{ foo = \"bar\", baz = \"qux\" }' TF_CLI_ARGS以及TF_CLI_ARGS_name TF_CLI_ARGS的值指定了附加给命令行的额外参数，这使得在自动化CI环境下可以轻松定制Terraform的默认行为。 该参数的值会被直接插入在子命令后(例如plan)以及通过命令行指定的参数之前。这种做法确保了环境变量参数优先于通过命令行传递的参数。 例如，执行这样的命令：TF_CLI_ARGS=\"-input=false\" terraform apply -force ，它等价于手工执行terraform apply -input=false -force 。 TF_CLI_ARGS变量影响所有的Terraform命令。如果你只想影响某个特定的子命令，可以使用TF_CLI_ARGS_name变量。例如：TF_CLI_ARGS_plan=\"-refresh=false\" ，就只会针对plan子命令起作用。 该环境变量的值会与通过命令行传入的参数一样被解析，你可以在值里使用单引号和双引号来定义字符串，多个参数之间以空格分隔。 TF_DATA_DIR TF_DATA_DIR可以修改Terraform保存在每个工作目录下的数据的位置。一般来说，Terraform会把这些数据写入当前工作目录下的.terraform文件夹内，但这一位置可以通过设置TF_DATA_DIR来修改。 大部分情况下我们不应该设置该变量，但有时我们不得不这样做，比如默认路径下我们无权写入数据时。 该数据目录被用来保存下一次执行任意命令时需要读取的数据，所以必须被妥善保存，并确保所有的Terraform命令都可以一致地读写它，否则Terraform会找不到Provider插件、模块代码以及其他文件。 TF_IN_AUTOMATION 如果该变量被设置为非空值，Terraform会意识到自己运行在一个自动化环境下，从而调整自己的输出以避免给出关于该执行什么子命令的建议。这可以使得输出更加一致且减少非必要的信息量。 TF_REGISTRY_DISCOVERY_RETRY 该变量定义了尝试从registry拉取插件或模块代码遇到错误时的重试次数。 TF_REGISTRY_CLIENT_TIMEOUT 该变量定义了发送到registry连接请求的超时时间，默认值为10秒。可以这样设置超时： $ export TF_REGISTRY_CLIENT_TIMEOUT=15 TF_CLI_CONFIG_FILE 该变量设定了Terraform命令行配置文件的位置： $ export TF_CLI_CONFIG_FILE=\"$HOME/.terraformrc-custom\" "},"5.3.资源地址.html":{"url":"5.3.资源地址.html","title":"资源地址","keywords":"","body":"资源地址 在编码时我们有时会需要引用一些资源的输出属性或是一些模块的输出值，这都涉及到如何在代码中引用特定模块或是资源。另外在执行某些命令行操作时也需要我们显式指定一些目标资源，这时我们要掌握Terraform的资源路径规则。 一个资源地址是用以在一个庞大的基础设施中精确引用一个特定资源对象的字符串。一个地址由两部分组成：[module path][resource spec]。 模块路径 一个模块路径在模块树上定位了一个特定模块。它的形式是这样的：module.module_name[module index] module：module关键字标记了这时一个子模块而非根模块。在路径中可以包含多个module关键字 module_name：用户定义的模块名 [module index]：(可选)访问多个子模块中特定实例的索引，由方括号包围 一个不包含具体资源的地址，例如module.foo代表了模块内所有的资源(如果只是单个模块而不是多实例模块)，或者是多实例模块的所有实例。要指代特定模块实例的所有资源，需要在地址中附带下标，例如module.foo[0]。 如果地址中模块部分被省略，那么地址就指代根模块资源。 一个多module关键字应用于多实例模块的例子：module.foo[0].module.bar[\"a\"]。 要注意的是，由于模块的count和for_each元参数是Terraform 0.13开始引进的，所以多实例模块地址也只能在0.13及之后的版本使用。 资源地址形式 一个资源地址定位了代码中特定资源对象，它的形式是这样的：resource_type.resource_name[resource index] resource_type：资源类型 resource_name：用户定义的资源名称 [resource index]：(可选)访问多实例资源中特定资源实例的索引，由方括号包围 多实例模块与资源的访问索引 以下规约适用于访问多实例模块及资源时使用的索引值： [N]：当使用count元参数时N是一个自然数。如果省略，并且count > 1，那么指代所有的实例 [\"INDEX\"]：当使用for_each元参数时INDEX是一个字母数字混合的字符串 例子 count的例子 给定一个代码定义： resource \"aws_instance\" \"web\" { # ... count = 4 } 给定一个地址：aws_instance.web[3]，它指代的是最后一个名为web的aws_instance实例；给定地址aws_instance.web，指代的是所有名为web的aws_instance实例。 for_each的例子 给定如下代码： resource \"aws_instance\" \"web\" { # ... for_each = { \"terraform\": \"value1\", \"resource\": \"value2\", \"indexing\": \"value3\", \"example\": \"value4\", } } 地址aws_instance.web[\"example\"]引用的是aws_instance.web中键为\"example\"的实例。 "},"5.4.apply.html":{"url":"5.4.apply.html","title":"apply","keywords":"","body":"apply Terraform最重要的命令就是apply。apply命令被用来生成执行计划(可选)并执行之，使得基础设施资源状态符合代码的描述。 用法 terraform apply [options] [dir-or-plan] 默认情况下，apply会扫描当前目录下的代码文件，并执行相应的变更。然而，也可以通过参数指定其他代码文件目录。在设计自动化流水线时也可以显式分为创建执行计划、使用apply命令执行该执行计划两个独立步骤。 如果没有显式指定变更计划文件，那么terraform apply会自动创建一个新的变更计划，并提示用户是否批准执行。如果生成的计划不包含任何变更，那么terraform apply会立即退出，不会提示用户输入。 该命令有以下参数可以使用： -backup-path：保存备份文件的路径。默认等于-state-out参数后加上\".backup\"后缀。设置为\"-\"可关闭 -compact-warnings：如果Terraform生成了一些告警信息而没有伴随的错误信息，那么以只显示消息总结的精简形式展示告警 -lock=true：执行时是否先锁定状态文件 -lock-timeout=0s：尝试重新获取状态锁的间隔 -input=true：在无法获取输入变量的值是是否提示用户输入 -auto-approve：跳过交互确认步骤，直接执行变更 -no-color：禁用输出中的颜色 -parallelism=n：限制Terraform遍历图时的最大并行度，默认值为10(考试高频考点) -refresh=true：指定变更计划及执行变更前是否先查询记录的基础设施对象现在的状态以刷新状态文件。如果命令行指定了要执行的变更计划文件，该参数设置无效 -state=path：保存状态文件的路径，默认值是\"terraform.tfstate\"。如果使用了远程Backend该参数设置无效。该参数不影响其他命令，比如执行init时会找不到它设置的状态文件。如果要使得所有命令都可以使用同一个特定位置的状态文件，请使用Local Backend(译者也不知道这是什么，官方文档相关链接404，并且搜索不到) -state-out=path：写入更新的状态文件的路径，默认情况使用-state的值。该参数在使用远程Backend时设置无效 -target=resource：通过指定资源地址指定更新目标资源。我们会在随后介绍plan命令时详细介绍 -var 'foo=bar'：设置一组输入变量的值。该参数可以反复设置以传入多个输入变量值 -var-file=foo：指定一个输入变量文件。具体内容我们在介绍输入变量的章节已有介绍，在此不再赘述 "},"5.5.console.html":{"url":"5.5.console.html","title":"console","keywords":"","body":"console 有时我们想要一个安全的调试工具来帮助我们确认某个表达式是否合法，或者表达式的值是否符合预期，这时我们可以使用terraform console启动一个交互式控制台。 用法 terraform console [options] [dir] console命令提供了一个用以执行和测试各种表达式的命令行控制台。在编码时如果我们不确定某个表达式的最终结果时(例如使用字符串模版)，我们可以在这个控制台中搭配当前状态文件中的数据进行各种测试。 如果当前状态是空的或还没有创建状态文件，那么控制台可以用来测试各种表达式语法以及内建函数。 dir参数指定了根模块的路径。如果没有指定path参数，那么则会使用当前工作目录。 支持的参数有： -state=path：指向本机状态文件的路径。表达式计算会使用该状态文件中记录的值。如果没有指定，则会使用当前工作区(Workspace)关联的状态文件 在控制台中可以使用exit命令或是Ctrl-C或是Ctrl-D退出。 脚本化 terraform console命令可以搭配非交互式脚本使用，可以使用管道符将其他命令输出接入控制台执行。如果没有发生错误，只有最终结果会被打印。 样例： $ echo \"1 + 5\" | terraform console 6 远程状态 如果使用了远程Backend存储状态，Terraform会从远程Backend读取当前工作区的状态数据来计算表达式。 "},"5.6.destroy.html":{"url":"5.6.destroy.html","title":"destroy","keywords":"","body":"destroy terraform destroy命令可以用来销毁并回收所有Terraform管理的基础设施资源。 用法 terraform destroy [options] [dir] Terraform管理的资源会被销毁，在执行销毁动作前会通过交互式界面征求用户的确认。 该命令可以接收所有apply命令的参数，除了不可以指定plan文件。 如果-auto-approve参数被设置为true，那么将不会征求用户确认直接销毁。 如果用-target参数指定了某项资源，那么不但会销毁该资源，同时也会销毁一切依赖于该资源的资源。我们会在随后介绍plan命令时详细介绍。 terraform destroy将执行的所有操作都可以随时通过执行terraform plan -destroy命令来预览。 "},"5.7.fmt.html":{"url":"5.7.fmt.html","title":"fmt","keywords":"","body":"fmt terraform fmt命令被用来格式化Terraform代码文件的格式和规范。该命令会对代码文件应用我们之前介绍过的代码风格规范中的一些规定，另外会针对可读性对代码做些微调整。 其他具有生成Terraform代码文件功能的命令会按照terraform fmt的标准来生成代码，所以请在项目中遵循fmt的代码风格以保持代码风格的统一。 Terraform不同版本的代码风格规范会有些微不同，所以在升级Terraform后我们建议要对代码执行一次terraform fmt。 用法 terraform fmt [options] [dir] 默认情况下，fmt会扫描当前文件夹以寻找代码文件。如果dir参数被提供了，那么它会扫描dir指向的目录。如果dir参数是一个减号(-)，那么fmt命令会从标准输入中读取(STDIN)。 该命令支持以下参数： -list=false：不列出包含不一致风格的文件 -write=false：不要重写输入文件(通过-check参数实现，或是使用标准输入流时) -diff：展示格式差异 -check：检查输入是否合规。返回0则代表所有输入的代码风格都是合规，反之则不是0 -recursive：是否递归处理所有子文件夹。默认情况下为false(只有当前文件夹会被处理，不涉及内嵌子模块) "},"5.8.force-unlock.html":{"url":"5.8.force-unlock.html","title":"force-unlock","keywords":"","body":"force-unlock 手动解除状态锁。 这个命令不会修改你的基础设施，它只会删除当前工作区对应的状态锁。具体操作步骤取决于使用的Backend。本地状态文件无法被其他进程解锁。 用法 terraform force-unlock LOCK_ID [DIR] 参数： -force=true：解锁时不提示确认 需要注意的是，就像我们在状态管理篇当中介绍过的那样，每一个状态锁都有一个锁ID。Terraform为了确保我们解除正确的状态锁，所以会要求我们显式输入锁ID。 一般情况下我们不需要强制解锁，只有在Terraform异常终止，来不及解除锁时需要我们手动强制解除锁。错误地解除状态锁可能会导致状态混乱，所以请小心使用。 "},"5.9.get.html":{"url":"5.9.get.html","title":"get","keywords":"","body":"get terraform get命令被用来下载以及更新根模块中使用的模块。 用法 terraform get [options] [dir] 模块被下载并安装在当前工作目录下.terraform子目录中。这个子目录不应该被提交至版本控制系统。这个.terraform文件夹的创建路径是在当前工作目录下的，与dir参数无关。 如果模块已经被安装而-update参数没有设置，那么Terraform什么都不会做，这样我们可以快速并安全地执行该命令任意多次。 该命令所有参数都是可选的： -update：如果指定，已经被下载的模块会被检查是否有新版本，如果存在新版本则会更新 dir：指定根模块的位置 "},"5.10.graph.html":{"url":"5.10.graph.html","title":"graph","keywords":"","body":"graph terraform graph命令可以用来生成代码描述的基础设施或是执行计划的可视化图形。它的输出是DOT格式，可以使用GraphViz来生成图片，也有许多网络服务可以读取这种格式。 用法 terraform graph [options] [DIR] 该命令生成DIR路径下的代码锁描述的Terraform资源的可视化依赖图(如果DIR参数缺省则使用当前工作目录) -type参数被用来指定输出的图表的类型。Terraform为不同的操作创建不同的图。对于代码文件，默认类型为\"plan\"，对于变更计划文件，默认类型为\"apply\"。 参数： -draw-cycles：用彩色的边高亮图中的环，这可以帮助我们分析代码中的环错误(Terraform禁止环状依赖) -type=plan：生成图表的类型。可以是：plan、plan-destroy、apply、validate、input、refresh 创建图片文件 terraform graph命令输出的是DOT格式的数据，可以轻松地使用GraphViz转换为图形文件： $ terraform graph | dot -Tsvg > graph.svg 输出的图片大概是这样的： 如何安装GraphViz 安装GraphViz也很简单，对于Ubuntu： $ sudo apt install graphviz 对于CentOS： $ sudo yum install graphviz 对于Windows，也可以使用choco： > choco install graphviz 对于Mac用户： $ brew install graphviz "},"5.11.import.html":{"url":"5.11.import.html","title":"import","keywords":"","body":"import terraform import命令用来将已经存在的资源对象导入Terraform。 我们并不总是那么幸运，能够在项目一开始就使用Terraform来构建和管理我们的基础设施；有时我们有一组已经运行着的基础设施资源，然后我们为它们编写了相应的Terraform代码，我们进行了测试，确认了这组代码描述的基础设施与当前正在使用的基础设施是等价的；但是我们仍然无法直接使用这套代码来管理现有的基础设施，因为我们缺乏了相应的状态文件。这时我们需要使用terraform import将资源对象“导入”到Terraform状态文件中去。 用法 terraform import [options] ADDRESS ID terraform import会根据资源ID找到相应资源，并将其信息导入到状态文件中ADDRESS对应的资源上。ADDRESS必须符合我们在资源地址中描述的合法资源地址格式，这样terraform import不但可以把资源导入到根模块中，也可以导入到子模块中。 ID取决于被导入的资源对象的类型。举例来说，AWS主机的ID格式类似于i-abcd1234，而AWS Route53 Zone的ID类似于Z12ABC4UGMOZ2N，请参考相关Provider文档来获取有关ID的详细信息。如果不确信的话，可以随便尝试任意ID。如果ID不合法，你会收到一个报错。 需要尤其注意的是，Terraform设想的是每一个资源对象都仅对应一个独一无二的实际基础设施对象，通常来说如果我们完全使用Terraform创建并管理基础设施时这一点不是问题；但如果你是通过导入的方式把基础设施对象导入到Terraform里，要绝对避免将同一个对象导入到两个以及更多不同的地址上，这会导致Terraform产生不可预测的行为。 该命令有以下参数可以使用： -backup=path：生成状态备份文件的地址，默认情况下是-state-out路径加上\".backup\"后缀名。设置为\"-\"可以关闭备份(不推荐) -config=path：包含含有导入目标的Terraform代码的文件夹路径。默认为当前工作目录 -input=true：是否允许提示输入Provider配置信息 -lock=true：如果Backend支持，是否锁定状态文件 -lock-timeout=0s：重试获取状态锁的间隔 -no-color：如果指定，则不会输出彩色信息 -parallelism=n：限制Terraform遍历图的最大并行度，默认值为10(又是考点) -state=path：要读取的状态文件的地址。默认为配置的Backend存储地址，或是\"terraform.tfstate\"文件 -state-out=path：指定修改后的状态文件的保存路径，默认情况下覆盖源状态文件。使用该参数可以生成一个新的状态文件，避免破坏现有状态文件 -var 'foo=bar'：通过命令行设置输入变量值，类似apply命令中的介绍 -var-file=foo：类似apply命令中的介绍 Provider配置 Terraform会尝试读取要导入的资源对应的Provider的配置信息。如果找不到相关Provider的配置，那么Terraform会提示你输入相关的访问凭据。你也可以通过环境变量来配置访问凭据。 Terraform在读取Provider配置时唯一的限制是不能依赖于\"非输入变量\"的输入。举例来说，Provider配置不能依赖于数据源的输出。 举一个例子，如果你想要导入AWS资源而你有这样的一份代码文件，那么Terraform会使用这两个输入变量来配置AWS Provier： variable \"access_key\" {} variable \"secret_key\" {} provider \"aws\" { access_key = var.access_key secret_key = var.secret_key } 例子 $ terraform import aws_instance.foo i-abcd1234 $ terraform import module.foo.aws_instance.bar i-abcd1234 $ terraform import 'aws_instance.baz[0]' i-abcd1234 $ terraform import 'aws_instance.baz[\"example\"]' i-abcd1234 上面这条命令如果是在PowerShell下： $ terraform import 'aws_instance.baz[\\\"example\\\"]' i-abcd1234 如果是cmd： $ terraform import aws_instance.baz[\\\"example\\\"] i-abcd1234 "},"5.12.init.html":{"url":"5.12.init.html","title":"init","keywords":"","body":"init terraform init命令被用来初始化一个包含Terraform代码的工作目录。在编写了一些Terraform代码或是克隆了一个Terraform项目后应首先执行该命令。反复执行该命令是安全的(考点)。 用法 terraform init [options] [DIR] 该命令为初始化工作目录执行了多个不同的步骤。详细说明可以见下文，总体来说用户不需要担心这些步骤。即使某些步骤可能会遭遇错误，但是该命令绝对不会删除你的基础设施资源或是状态文件。 如果不传入任何参数，那么命令会初始化当前工作目录。我们推荐不使用DIR参数，直接在根模块的目录下运行该命令。 常用参数 -input=true：是否在取不到输入变量值时提示用户输入 -lock=false：是否在运行时锁定状态文件 -lock-timeout=\\：尝试获取状态文件锁时的超时时间，默认为0，意为一旦发现锁已被其他进程获取立即报错 -no-color：禁止输出中包含颜色 -upgrade：是否升级模块代码以及插件 从模块源拷贝模块 默认情况下，terraform init会认为工作目录下已经包含了Terraform代码文件。 init配合-from-module=MODULE-SOURCE参数在一个空目录下执行，这将会在运行其他任何步骤之前先把相关模块复制到目标文件夹下。 这种特殊的使用方式有两种场景： 对于source对应的版本控制系统，我们可以用这种方法签出指定版本代码并为它初始化工作目录 如果模块源指向的是一个样例项目，那么这种方式可以把样例代码拷贝到本地目录以便我们后续基于样例编写新的代码 如果是常规运行操作我们建议用独立的步骤从版本控制系统中签出代码，使用版本控制系统所属的工具。 Backend初始化 在执行init时，会分析根模块代码以寻找Backend配置，然后使用给定的配置设定初始化Backend存储。 在已经初始化Backend后重复执行init命令会更新工作目录以使用新的Backend设置。取决于改变的内容，init可能会提示用户是否确认进行状态迁移(我们在状态管理章节中有所介绍)。-force-copy参数跳过了提示，直接确认迁移状态。-reconfigure参数则使得init不理会任何现有配置，防止任何状态迁移。 要跳过Backend配置，可以使用-backend=false。注意某些其他init步骤需要已经被初始化的Backend，所以推荐只在已经初始化过Backend后使用该参数。 -backend-config参数可以用来动态指定Backend配置，我们在状态管理章节中介绍“部分配置“时已经提过，在此不再赘述。 初始化子模块 init会搜索module块，然后通过source参数取回模块代码。 模块安装之后重新运行init命令会继续安装那些自从上次init之后新增的模块，但不会修改已被安装的模块。使用-upgrade可以改变这种行为，将所有模块升级到最新版本的代码。 要跳过子模块安装步骤，可以使用-get=false参数。要注意其他一些init步骤需要模块树完整，所以建议只在成功安装过模块以后使用该参数。 插件安装 我们在Provider章节中介绍了插件安装，所以在此不再赘述，我们值介绍一下参数： -upgrade：将之前所有已安装的插件升级到符合version约束的最新版本。此参数对手动安装的插件无效 -get-plugins=false：跳过插件安装。Terraform会使用已安装在当前工作目录下或是插件缓存路径中的插件。如果这些插件不足以覆盖需求，那么init会失败 -plugin-dir=PATH：跳过插件安装，只从指定目录加载插件。该参数会跳过用户插件目录以及所有当前工作目录下的插件。要在使用过该参数后恢复默认行为，请使用-plugin-dir=\"\"参数重新执行init。 -verify-plugins=false：在下载插件后跳过验证签名(不推荐)。官方插件都会经HashiCorp签名，Terraform会验证这些签名。可以使用该参数跳过签名验证(Terraform不会验证手动安装的插件的签名) "},"5.13.output.html":{"url":"5.13.output.html","title":"output","keywords":"","body":"output terraform output命令被用来提取状态文件中输出值的值。 用法 terraform output [options] [NAME] 如果不添加参数，output命令会展示根模块内定义的所有输出值。如果指定了NAME，只会输出相关输出值。 可以使用以下参数： -json：使用该参数后Terraform会使用JSON格式输出。如果指定了NAME，只会输出相关输出值。该参数搭配jq使用可以构建复杂的流水线 -no-color：不输出颜色 -state=path：状态文件的路径，默认为\"terraform.tfstate\"。启用远程Backend时该参数无效 样例 假设有如下输出值代码： output \"lb_address\" { value = aws_alb.web.public_dns } output \"instance_ips\" { value = [aws_instance.web[*].public_ip] } output \"password\" { sensitive = true value = [var.secret_password] } 列出所有输出值： $ terraform output 注意password输出值定义了sensitive = true，所以它的值在输出时会被隐藏： $ terraform output password password = 要查询负载均衡的DNS地址： $ terraform output lb_address my-app-alb-1657023003.us-east-1.elb.amazonaws.com 查询所有主机的IP： $ terraform output instance_ips test = [ 54.43.114.12, 52.122.13.4, 52.4.116.53 ] 使用-json和jq查询指定主机的ip： $ terraform output -json instance_ips | jq '.value[0]' "},"5.14.plan.html":{"url":"5.14.plan.html","title":"plan","keywords":"","body":"plan terraform plan命令被用来创建变更计划。Terraform会先运行一次refresh(我们后面的章节会介绍，该行为也可以被显式关闭)，然后决定要执行哪些变更使得现有状态迁移到代码描述的期待状态。 该命令可以方便地审查状态迁移的所有细节而不会实际更改现有资源以及状态文件。例如，在将代码提交到版本控制系统前可以先执行terraform plan，确认变更行为如同预期一般。 可选参数-out可以将变更计划保存在一个文件中，以便日后使用terraform apply命令来执行该计划。 如果Terraform检测不到任何变更，那么terraform plan会提示没有任何需要执行的变更。 用法 terraform plan [options] [dir] 默认情况下，plan命令不需要参数，使用当前工作目录下的代码和状态文件执行refresh。 有如下参数可以使用： -compact-warnings：如果Terraform生成了一些告警信息而没有伴随的错误信息，那么以只显示消息总结的精简形式展示告警 -destroy：生成销毁所有资源的计划 -detailed-exitcode：当命令退出时返回一个详细的返回码。如果有该参数，那么返回码将会包含更详细的含义： 0 = 成功的空计划(没有变更) 1 = 错误 2 = 成功的非空计划(有变更) -input=true：在取不到值的情况下是否提示用户给定输入变量值 -lock=true：与apply类似，不再赘述 -lock-timeout=0s：与apply类似，不再赘述 -no-color：关闭彩色输出 -out=path：将变更计划保存到指定路径下的文件中，随后我们可以使用terraform apply执行该计划 -parallelism-n：限制Terraform遍历图的最大并行度，默认值为10 -refresh=true：计算变更前先执行refresh -state=path：状态文件的位置，默认为\"terraform.tfstate\"。如果启用了远程Backend则该参数设置无效 -target=resource：目标资源的地址，该参数可反复声明，用以对基础设施进行部分更新 -var 'foo=bar'：与apply类似，不再赘述 -var-file=foo：与apply类似，不再赘述 部分更新 使用-target参数可以使得Terraform专注于一部分的资源。可以使用资源地址来标记这个集合。资源地址按如下规则被解释： 如果给定地址能够定位到一个资源，那么只该资源会被标记；如果该资源使用了count参数而没有给定具体访问下标，该资源所有实例都会被标记 如果给定地址定位到的不是资源而是一个模块，那么该模块内所有资源及其内嵌模块资源都会被标记 这种标记部分资源并计算更新计划的能力是为了一些比较罕见的场景设计的，例如从先前的错误中恢复或是绕过某些Terraform的设计限制。对于常规操作不推荐使用-target参数，因为它会造成无法检测的配置漂移以及使人无法从代码推导出当前真实的状态。 安全警告 被保存的变更计划文件(使用-out参数)内部可能含有敏感信息，Terraform本身并不会加密计划文件。如果你要移动或是保存该文件一段时间，强烈建议你自行加密该文件。 Terraform未来打算增强计划文件的安全性。 "},"5.15.providers.html":{"url":"5.15.providers.html","title":"providers","keywords":"","body":"providers terraform providers命令打印当前代码定义的Provider的信息。 Provider依赖关系通过几种不同方式创建： 在代码中显式使用terraform.required_providers块，包含可选的version约束 在代码中显式使用provider块，包含可选的version约束 在当前状态文件中存在属于某个Provider管理的资源实例。例如，如果代码中删除了特定资源对象的声明，那么仍然存在对相应Provider实例的依赖，直到对象被销毁 该命令总结了当前所有的Provider依赖，有助于理解为什么会需要特定Provider。 该命令是含有内嵌子命令，这些子命令我们会逐个解释。 用法 terraform providers [config-path] 可以通过显式传递config-path参数来指定根模块路径，默认为当前工作目录。 "},"5.15.1.mirror.html":{"url":"5.15.1.mirror.html","title":"mirror","keywords":"","body":"terraform providers mirror 该子命令从Terraform 0.13开始引入。 terraform providers mirror命令下载当前代码所需要的Provider并且将其拷贝到本地文件系统的一个目录下。 一般情况下，terraform init会在初始化当前工作目录时自动从registry下载所需的Provider。有时Terraform工作在无法执行该操作的环境下，例如一个无法访问registry的局域网内。这时可以通过配置Provider镜像存储来使得在这样的环境下Terraform可以从本地插件镜像存储中获取插件。 terraform providers mirror命令可以自动填充准备用以作为本地插件镜像存储的目录。 用法 terraform providers mirror [options] \\ target-dir参数是必填的。Terraform会自动在目标目录下建立起插件镜像存储所需的文件结构，填充包含插件文件的.zip文件。 Terraform同时会生成一些包含了合法的网络镜像协议响应的.json索引文件，如果你把填充好的文件夹上传到一个静态站点，那就能够得到一个静态的网络插件镜像存储服务。Terraform在使用本地文件镜像存储时会忽略这些镜像文件，因为使用本地文件镜像时文件夹本身的信息更加权威。 该命令支持如下可选参数： -platform=OS_ARCH：选择构建镜像的目标平台。默认情况下，Terraform会使用当前运行Terraform的平台。可以反复声明该参数以构建多目标平台插件镜像 目标平台必须包含操作系统以及CPU架构。例如：linux_amd64代表运行在AMD64或是X86_64 CPU之上的Linux系统。 你可以针对已构建的镜像文件夹重新运行terraform providers mirror来添加新插件。例如，你可以通过传入新的-platform参数来添加新目标平台的插件，Terraform会下载新平台插件同时保留原先的插件，将二者合并存储，并更新索引文件。 "},"5.15.2.schema.html":{"url":"5.15.2.schema.html","title":"schema","keywords":"","body":"terraform providers schema terraform providers schema命令被用来打印当前代码使用的Provider的架构。Provider架构包含了该Provider本身的参数信息，以及所提供的resource、data的架构信息。 用法 terraform providers schema [options] 可选参数为： -json：用机器可读的JSON格式打印架构 请注意，目前-json参数是必填的，未来该命令将允许使用其他参数。 "},"5.16.refresh.html":{"url":"5.16.refresh.html","title":"refresh","keywords":"","body":"refresh terraform refresh命令将实际存在的基础设施对象的状态同步到状态文件中记录的对象状态。它可以用来检测真实状态与记录状态之间的漂移并更新状态文件。 警告！！！该命令已在最新版本 Terraform 中被废弃，因为该命令的默认行为在当前用户错误配置了使用的云平台令牌时会引发对状态文件错误的变更。 该命令并不会修改基础设施对象，只修改状态文件。如果状态文件发生改变，将有可能在下次执行plan或apply时引发变更计划。 用法 terraform refresh [options] [dir] 该命令本质上是以下命令的别名，具有完全相同的效果： terraform apply -refresh-only -auto-approve 因此，该命令支持所有 terraform apply 所支持的参数，除了它不接受一个现存的变更计划文件，不允许选择\"refresh only\"之外的模式，并且始终应用-auto-approve选项。 主动使用refresh是很危险的，因为如果当前用户错误配置了使用的 Provider 的令牌，那么 Terraform 会错误地以为当前状态文件中记录的所有资源都被删除了，随即从状态文件中无预警地删除所有相关记录。 作为替代我们推荐使用如下命令来取得相同的效果，同时可以在修改状态文件之前预览即将对其作出的修改： terraform apply -refresh-only 该命令将会在交互界面中提示用户检测到的变更，并提示用户确认执行。 terraform apply和terraform plan命令的-refresh-only选项是从 Terraform v0.15.4 版本开始被引入的。对更早的版本，用户只能直接使用terraform refresh命令，同时要小心本篇警告过的危险副作用。尽可能避免显式使用terraform refresh命令，Terraform 在执行terraform plan和terraform apply命令时都会自动执行刷新状态的操作以生成变更计划，尽可能依赖该机制来维持状态文件的同步。 "},"5.17.show.html":{"url":"5.17.show.html","title":"show","keywords":"","body":"show terraform show命令从状态文件或是变更计划文件中打印人类可读的输出信息。这可以用来检查变更计划以确定所有操作都是预期的，或是审查当前的状态文件。 可以通过添加-json参数输出机器可读的JSON格式输出。 需要注意的是，使用-json输出时所有标记为sensitive的敏感数据都会以明文形式被输出。 JSON输出 可以使用terraform show -json命令打印JSON格式的状态信息。 如果指定了一个变更计划文件，terraform show -json会以JSON格式记录变更计划、配置以及当前状态。 用法 terraform show [options] [path] 你可以用path参数指定一个状态文件或是变更计划文件。如果没有给定path，那么会使用当前工作目录对应的状态文件。 该命令支持以下参数： -no-color：与apply类似，不再赘述 -json：以JSON格式输出 "},"5.18.state.html":{"url":"5.18.state.html","title":"state","keywords":"","body":"state terraform state命令可以用来进行复杂的状态管理操作。随着你对Terraform的使用越来越深入，有时候你需要对状态文件进行一些修改。由于我们在状态管理章节中提到过的，状态文件的格式属于HashiCorp未公开的私有格式，所以直接修改状态文件是不适合的，我们可以使用terraform state命令来执行修改。 该命令含有数个子命令，我们会一一介绍。 用法 terraform state \\ [options] [args] 远程状态 所有的state子命令都可以搭配本地状态文件以及远程状态使用。使用远程状态时读写操作可能用时稍长，因为读写都要通过网络完成。备份文件仍然会被写入本地磁盘。 备份 所有会修改状态文件的terraform state子命令都会生成备份文件。可以通过-backup参数指定备份文件的位置。 只读子命令(例如list)由于不会修改状态，所以不会生成备份文件。 注意修改状态的state子命令无法禁用备份。由于状态文件的敏感性，Terraform强制所有修改状态的子命令都必须生成备份文件。如果你不想保存备份，可以手动删除。 命令行友好 state子命令的输出以及命令结构都被设计成易于同Unix下其他命令行工具搭配使用，例如grep、awk等等。同样的，输出结果也可以在Windows上轻松使用PowerShell处理。 对于复杂场景，我们建议使用管道组合state子命令与其他命令行工具一同使用。 资源地址 state子命令中大量使用了资源地址，我们在资源地址章节中做了相关的介绍。 "},"5.18.1.list.html":{"url":"5.18.1.list.html","title":"list","keywords":"","body":"list terraform state list命令可以列出状态文件中记录的资源对象。 用法 terraform state list [options] [address...] 该命令会根据address列出状态文件中相关资源的信息(如果给定了address的话)。如果没有给定address，那么所有资源都会被列出。 列出的资源根据模块深度以及字典序进行排序，这意味着根模块的资源在前，越深的子模块定义的资源越在后。 对于复杂的基础设施，状态文件可能包含成千上万到的资源对象。可以通过提供一个或多个资源地址来进行过滤。 可以使用的可选参数有： -state=path：指定使用的状态文件地址。默认为\"terraform.tfstate\"。使用远程Backend时该参数设置无效 -id=id：要显示的资源ID 例子：所有资源 $ terraform state list aws_instance.foo aws_instance.bar[0] aws_instance.bar[1] module.elb.aws_elb.main 例子：根据资源地址过滤 $ terraform state list aws_instance.bar aws_instance.bar[0] aws_instance.bar[1] 例子：根据模块过滤 $ terraform state list module.elb module.elb.aws_elb.main 例子：根据ID过滤 下面的例子显示了根据资源对象ID过滤资源： $ terraform state list -id=sg-1234abcd module.elb.aws_security_group.sg "},"5.18.2.mv.html":{"url":"5.18.2.mv.html","title":"mv","keywords":"","body":"mv terraform state mv命令可以在状态文件中移动资源。该命令可以移动单个资源对象、多实例资源对象中特定实例、整个模块以及其他对象。该命令也可以在不同的状态文件之间移动对象，以配合代码重构。 用法 terraform state mv [options] SOURCE DESTINATION 该命令将会把资源对象从SOURCE地址移动到DESTINATION地址。这可以用来实现单个简单资源的重命名、在模块之间移动对象、移动整个模块等操作。它也可以用来在Terraform管理的不同基础设施栈之间移动对象。 该命令在进行任意修改之前会先生成一个备份文件。备份机制不可关闭。如果是在不同状态文件之间移动对象，那么每个状态文件都会生成一个备份。 该命令的SOURCE与DESTINATION是必填参数，必须是合法的资源地址。 该命令提供以下可选参数： -backup=path：指定源状态文件的备份地址，默认为源状态文件加上\".backup\"后缀 -bakcup-out=path：指定目标状态文件的备份地址，默认为目标状态文件加上\".backup\"后缀 -state=path：源状态文件地址，默认为当前Backend或是\"terraform.tfstate\" -state-out=path：目标状态文件地址。如果不指定则使用源状态文件。可以是一个已经存在的文件或新建一个文件 例子：重命名一个资源 $ terraform state mv 'packet_device.worker' 'packet_device.helper' 例子：将一个资源移动进一个模块 以下例子展示了将packet_device.worker资源移动进名为app的模块。如果模块目前不存在，则会创建模块。 $ terraform state mv 'packet_device.worker' 'module.app.packet_device.worker' 例子：移动一个模块进入另一个模块 $ terraform state mv 'module.app' 'module.parent.module.app' 例子：移动一个模块到另一个状态文件 $ terraform state mv -state-out=other.tfstate 'module.app' 'module.app' 移动一个带有count参数的资源 $ terraform state mv 'packet_device.worker[0]' 'packet_device.helper[0]' 移动一个带有for_each参数的资源 Linux、MacOS以及Unix： $ terraform state mv 'packet_device.worker[\"example123\"]' 'packet_device.helper[\"example456\"]' PowerShell： $ terraform state mv 'packet_device.worker[\\\"example123\\\"]' 'packet_device.helper[\\\"example456\\\"]' Windows命令行： $ terraform state mv packet_device.worker[\\\"example123\\\"] packet_device.helper[\\\"example456\\\"] "},"5.18.3.pull.html":{"url":"5.18.3.pull.html","title":"pull","keywords":"","body":"pull terraform state pull命令可以从远程Backend中人工下载状态并输出。该命令也可搭配本地状态文件使用。 用法 terraform state pull 该命令下载当前位置对应的状态文件，并以原始格式打印到标准输出流。 由于状态文件使用JSON格式，该功能可以搭配例如jq这样的命令行工具使用，也可以用来人工修改状态文件。 "},"5.18.4.push.html":{"url":"5.18.4.push.html","title":"push","keywords":"","body":"push terraform push命令被用来手动上传本地状态文件到远程Backend。该命令也可以被用在当前使用的本地状态文件上。 用法 terraform state push [options] PATH 该命令会把PATH位置的状态文件推送到当前使用的Backend上(可以是当前使用的terraform.tfstate文件)。 如果PATH的值为\"-\"那么会从标准输入流读取要推送的状态数据。这时数据会完全被加载进内存，并且在写入目标状态前进行检查。 Terraform会进行一系列检查以防止你进行一些不安全的变更： 检查lineage：如果两个状态文件的lineage值不同，Terraform会禁止推送。一个不同的lineage说明两个状态文件描述的是完全不同的基础设而你可能会因此丢失重要数据 序列号检查：如果目标状态文件的serial值大于你要推送的状态的serial值，Terraform会禁止推送。一个更高的serial值说明目标状态文件已经无法与要推送的状态文件对应上了 这两种检查都可以通过添加-force参数禁用，但不推荐这样做。如果禁用安全检查直接推送，那么目标状态文件将被覆盖。 "},"5.18.5.replace-provider.html":{"url":"5.18.5.replace-provider.html","title":"replace-provider","keywords":"","body":"replace-provider terraform state replace-provider命令可以替换状态文件中资源对象所使用的Provider的源. 用法 terraform state replace-provider [options] FROM_PROVIDER_FQN TO_PROVIDER_FQN 该命令会更新所有使用from Provider的资源，将资源使用的Provider更新为to Provider。这允许我们更新状态文件中资源所使用的Provider的源。 该命令在进行任意修改之前会先生成一个备份文件。备份机制不可关闭。 支持以下可选参数： -auto-approve：跳过交互式提示确认环节 -backup=path：将备份写入指定路径。如果没有该参数，则会写入当前状态文件加上“.backup\"后缀的路径 -lock=true：类似apply，不再赘述 -lock-timeout=0s：类似apply，不再赘述 -state=path：要读取的状态文件地址。默认为当前使用的Backend或是\"terraform.tfstate\"文件 样例 $ terraform state replace-provider hashicorp/aws registry.acme.corp/acme/aws "},"5.18.6.rm.html":{"url":"5.18.6.rm.html","title":"rm","keywords":"","body":"rm terraform state rm命令可以用来从状态文件中删除对象。该命令可以删除单个资源、多实例资源中特定实例、整个模块以及等等。 用法 terraform state rm [options] ADDRESS... 从状态文件中删除一个或多个对象。 删除对象并非删除实际基础设施对象，而只是状态不再由Terraform管理，从状态文件中删除而已。举例来说，如果你从状态文件中删除一个AWS虚拟机，那么该虚拟机仍然会保持运行，只是运行terraform plan再也看不到该实例了。 从状态文件中删除对象有着广泛的用途。最常见的就是进行代码重构，不再管理某个资源(也许是转移到另一个项目管理了)。 只有当所有要删除的资源被删除成功状态文件才会保存。如果由于任何原因导致某个资源删除发生错误(比如语法错误)，那么状态文件完全不会被修改。 该命令在进行任意修改之前会先生成一个备份文件。备份机制不可关闭。 该命令需要传递一个或多个待删除资源的资源地址。 可以使用如下可选参数： -backup=path：写入备份文件的路径 -state=path：要操作的资源文件路径。如果没有该参数，则会使用当前Backend或是\"terraform.tfstate\"文件 删除一个资源 $ terraform state rm 'packet_device.worker' 删除一个模块 $ terraform state rm 'module.foo' 删除一个模块内资源 $ terraform state rm 'module.foo.packet_device.worker' 删除一个声明count的资源 $ terraform state rm 'packet_device.worker[0]' 删除一个声明for_each的资源 Linux, MacOS, and Unix： $ terraform state rm 'packet_device.worker[\"example\"]' PowerShell： $ terraform state rm 'packet_device.worker[\\\"example\\\"]' Windows命令行： $ terraform state rm packet_device.worker[\\\"example\\\"] "},"5.18.7.show.html":{"url":"5.18.7.show.html","title":"show","keywords":"","body":"show terraform state show命令可以展示状态文件中单个资源的属性。 用法 terraform state show [options] ADDRESS 该命令需要指定一个资源地址。 该命令支持以下可选参数： -state=path：指向状态文件的路径。默认情况下使用\"terraform.tfstate\"。如果启用了远程Backend则该参数设置无效 terraform state show的输出被设计成人类可读而非机器可读。如果想要从输出中提取数据，请使用terraform show -json。 展示单个资源 $ terraform state show 'packet_device.worker' # packet_device.worker: resource \"packet_device\" \"worker\" { billing_cycle = \"hourly\" created = \"2015-12-17T00:06:56Z\" facility = \"ewr1\" hostname = \"prod-xyz01\" id = \"6015bg2b-b8c4-4925-aad2-f0671d5d3b13\" locked = false } 展示单个模块资源 $ terraform state show 'module.foo.packet_device.worker' 展示声明count资源中特定实例 $ terraform state show 'packet_device.worker[0]' 展示声明for_each资源中特定实例 Linux, MacOS, and Unix： $ terraform state show 'packet_device.worker[\"example\"]' PowerShell： $ terraform state show 'packet_device.worker[\\\"example\\\"]' Windows命令行： $ terraform state show packet_device.worker[\\\"example\\\"] "},"5.19.taint.html":{"url":"5.19.taint.html","title":"taint","keywords":"","body":"taint terrform taint命令可以手动标记某个Terraform管理的资源有\"污点\"，强迫在下一次执行apply时删除并重建之。 该命令并不会修改基础设施，而是在状态文件中的某个资源对象上标记污点。当一个资源对象被标记了污点，在下一次plan操作时会计划将之删除并且重建，apply操作会执行这个变更。 强迫重建某个资源可以使你能够触发某种副作用。举例来说，你想重新执行某个预置器操作，或是某些人绕过Terraform修改了虚拟机状态，而你想将虚拟机重置。 注意为某个资源标记污点并重建之会影响到所有依赖该资源的对象。举例来说，一条DNS记录使用了服务器的IP地址，我们在服务器上标记污点会导致IP发生变化从而影响到DNS记录。这种情况下可以使用plan命令查看变更计划。 用法 terraform taint [options] ADDRESS ADDRESS参数是要标记污点的资源地址。 该命令可以使用如下可选参数： -allow-missing：如果声明该参数，那么即使资源不存在，命令也会返回成功(状态码0) -backup=path：写入备份文件的路径，默认为-state-out路径加上\".backup\"后缀。可以通过设置为\"-\"关闭备份 -lock=true：与apply类似，不再赘述 -lock-timeout=0s：与apply类似，不再赘述 -state=path：要读写的状态文件路径。默认为\"terraform.tfstate\"。如果启用了远程Backend则该参数设置无效 -state-out=path：更新后的状态文件写入的路径。默认等于-state路径。如果启用了远程Backend则该参数设置无效 标记单个资源 $ terraform taint aws_security_group.allow_all The resource aws_security_group.allow_all in the module root has been marked as tainted. 标记使用for_each创建的资源的特定实例 $ terraform taint \"module.route_tables.azurerm_route_table.rt[\\\"DefaultSubnet\\\"]\" The resource module.route_tables.azurerm_route_table.rt[\"DefaultSubnet\"] in the module root has been marked as tainted. 标记模块中的资源 $ terraform taint \"module.couchbase.aws_instance.cb_node[9]\" Resource instance module.couchbase.aws_instance.cb_node[9] has been marked as tainted. 虽然我们推荐模块深度不要超过1，但是我们仍然可以标记多层模块中的资源： $ terraform taint \"module.child.module.grandchild.aws_instance.example[2]\" Resource instance module.child.module.grandchild.aws_instance.example[2] has been marked as tainted. "},"5.20.validate.html":{"url":"5.20.validate.html","title":"validate","keywords":"","body":"validate terraform validate命令可以检查目录下Terraform代码，只检查语法文件，不会访问诸如远程Backend、Provider的API等远程资源。 validate检查代码的语法是否合法以及一致，不管输入变量以及现存状态。 validate命令需要已初始化的工作目录，所有引用的插件与模块都被安装完毕。如果只想检查语法而不想与Backend交互，可以这样初始化工作目录： $ terraform init -backend=false 用法 terraform validate [options] [dir] 默认情况下validate命令不需要任何参数就可以在当前工作目录下进行检查。 可以使用如下可选参数： -json：使用JSON格式输出机器可读的结果 -no-color：禁止使用彩色输出 "},"5.21.untaint.html":{"url":"5.21.untaint.html","title":"untaint","keywords":"","body":"untaint terraform untaint命令可以手动清除一个Terraform管理的资源对象上的污点，恢复它在状态文件中的状态。它是terraform taint的逆向操作。 该命令不会修改实际的基础设施资源，只会在资源文件中清除资源对象上的污点标记。 用法 terraform untaint [options] name name参数是要清除污点的资源的资源名称。该参数的格式为TYPE.NAME，比如aws_instance.foo。 可以使用如下可选参数： -allow-missing：如果声明该参数，那么即使name指定的资源不存在，命令执行也会返回成功(状态码0)。命令执行仍然可能报错，但只在发生严重错误时 -backup=path：写入备份文件的路径。默认为-state-out路径加上\".backup\"后缀。设置为\"-\"可关闭备份 -lock=true：类似apply，不再赘述 -lock-timeout=0s：类似apply，不再赘述 -module=path：资源所在模块的名称。默认情况下使用根模块。可以通过\".\"号分隔的路径指定模块，例如\"foo\"指定使用foo模块，\"foo.bar\"指定使用foo模块中的bar模块 -no-color：类似apply，不再赘述 -state=path：读写的状态文件路径。默认为\"terraform.tfstate\"。使用远程Backend时该参数设置无效 -state-out=path：修改后的状态文件的写入路径。默认情况下使用-state参数。使用远程Backend时该参数设置无效 "},"5.22.workspace.html":{"url":"5.22.workspace.html","title":"workspace","keywords":"","body":"workspace terraform workspace命令可以用来管理当前使用的工作区。我们在状态管理章节中介绍过工作区的概念。 该命令包含一系列子命令，我们将会一一介绍。 "},"5.22.1.list.html":{"url":"5.22.1.list.html","title":"list","keywords":"","body":"list terraform workspace list命令列出当前存在的工作区。 用法 terraform workspace list 该命令会打印出存在的工作区。当前工作会使用*号标记： $ terraform workspace list default * development jsmith-test "},"5.22.2.select.html":{"url":"5.22.2.select.html","title":"select","keywords":"","body":"select terraform workspace select命令用来选择使用的工作区。 用法 terraform workspace select [NAME] NAME指定的工作区必须已经存在： $ terraform workspace list default * development jsmith-test $ terraform workspace select default Switched to workspace \"default\". "},"5.22.3.new.html":{"url":"5.22.3.new.html","title":"new","keywords":"","body":"new terraform workspace new命令用来创建新的工作区。 用法 terraform workspace new [NAME] 该命令使用给定名字创建一个新的工作区。不可存在同名工作区。 如果使用了-state参数，那么给定路径的状态文件会被拷贝到新工作区。 该命令支持以下可选参数： -state=path：用来初始化新环境所使用的状态文件路径 创建新工作区： $ terraform workspace new example Created and switched to workspace \"example\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. 使用状态文件创建新工作区： $ terraform workspace new -state=old.terraform.tfstate example Created and switched to workspace \"example\". You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. "},"5.22.4.delete.html":{"url":"5.22.4.delete.html","title":"delete","keywords":"","body":"delete terraform workspace delete命令被用以删除已经存在的工作区。 用法 terraform workspace delete [NAME] 被删除的工作区必须已经存在，并且不可以删除当前正在使用的工作区。如果工作区状态不是空的，Terraform会禁止删除，除非声明-force参数。 如果使用-force删除非空状态，那么这些资源饿状态出于\"dangling\"，也就是实际基础设施资源仍然存在，但脱离了Terraform的管理。有时我们希望这样，只是希望当前Terraform项目不再管理这些资源，交由其他项目管理。但大多数情况下并非这样，所以Terraform默认会禁止删除非空工作区。 该命令可以使用如下可选参数： -force：删除含有非空状态文件的工作区。默认为false 例子： $ terraform workspace delete example Deleted workspace \"example\". "},"5.22.5.show.html":{"url":"5.22.5.show.html","title":"show","keywords":"","body":"show terraform workspace show命令被用以输出当前使用的工作区。 用法 terraform workspace show 例子： $ terraform workspace show development "},"6.Aha——会心一击.html":{"url":"6.Aha——会心一击.html","title":"Aha——会心一击","keywords":"","body":"Aha——会心一击 Terraform使用的是声明式而非命令式的语法，其本身并不是图灵完备的，所以在遇到某些场景时会显得力不从心。 本章我们会介绍一些小技巧以及设计模式和特殊Provider，可以在必要的时候帮助你实现某些特殊的逻辑，起到“会心一击”的效果。 "},"6.1.有条件创建.html":{"url":"6.1.有条件创建.html","title":"有条件创建","keywords":"","body":"有条件创建 Terraform被设计成声明式而非命令式，例如没有常见的if条件语句，后来才加上了count和for_each实现的循环语句(但循环的次数必须是在plan阶段就能够确认的，无法根据其他resource的输出动态决定) 有时候我们需要根据某种条件来判断是否创建一个资源。虽然我们无法使用if来完成条件判断，但我们还有count和for_each可以帮助我们完成这个目标。 我们以UCloud为例，假如我们正在编写一个旨在被复用的模块，模块的逻辑要创建一台虚拟机，我们的代码可以是这样的： data ucloud_vpcs \"default\" { name_regex = \"^Default\" } data \"ucloud_images\" \"centos\" { name_regex = \"^CentOS 7\" } resource \"ucloud_instance\" \"web\" { availability_zone = \"cn-bj2-02\" image_id = data.ucloud_images.centos.images[0].id instance_type = \"n-basic-2\" } output \"uhost_id\" { value = ucloud_instance.web.id } 非常简单。但是如果我们想进一步，让模块的调用者决定创建的主机是否要搭配一个弹性公网IP该怎么办？ 我们可以在上面的代码后面接上这样的代码： variable \"allocate_public_ip\" { description = \"Decide whether to allocate a public ip and bind it to the host\" type = bool default = false } resource \"ucloud_eip\" \"public_ip\" { count = var.allocate_public_ip ? 1 : 0 name = \"public_ip_for_${ucloud_instance.web.name}\" internet_type = \"bgp\" } resource \"ucloud_eip_association\" \"public_ip_binding\" { count = var.allocate_public_ip ? 1 : 0 eip_id = ucloud_eip.public_ip[0].id resource_id = ucloud_instance.web.id } 我们首先创建了名为allocate_public_ip的输入变量，然后在编写弹性IP相关资源代码的时候都声明了count参数，值使用了条件表达式，根据allocate_public_ip这个输入变量的值决定是1还是0.这实际上实现了按条件创建资源。 需要注意的是，由于我们使用了count，所以现在弹性IP相关的资源实际上是多实例资源类型的。我们在ucloud_eip_association.public_ip_binding中引用ucloud_eip.public时，还是要加上访问下标。由于ucloud_eip_association.public_ip_binding与ucloud_eip.public实际上是同生同死，所以在这里他们之间的引用还比较简单；如果是其他没有声明count的资源引用它们的话，还要针对allocate_public_ip为false时ucloud_eip.public实际为空做相应处理，比如在output中： output \"public_ip\" { value = join(\"\", ucloud_eip.public_ip[*].public_ip) } 使用join函数就可以在即使没有创建弹性IP时也能返回空字符串。或者我们也可以用条件表达式： output \"public_ip\" { value = length(ucloud_eip.public_ip[*].public_ip) > 0 ? ucloud_eip.public_ip[0].public_ip : \"\" } "},"6.2.依赖反转.html":{"url":"6.2.依赖反转.html","title":"依赖反转","keywords":"","body":"依赖反转 Terraform编排的基础设施对象彼此之间可能互相存在依赖关系，有时我们在编写一些旨在重用的模块时，模块内定义的资源可能本身需要依赖其他一些资源，这些资源可能已经存在，也可能有待创建。 举一个例子，假设我们编写了一个模块，定义了在UCloud上同一个VPC中的两台服务器；第一台服务器部署了一个Web应用，它被分配在一个DMZ子网里；第二台服务器部署了一个数据库，它被分配在一个内网子网里。现在的问题是，在我们编写模块时，我们并没有关于VPC和子网的任何信息，我们甚至连服务器应该部署在哪个可用区都不知道。VPC和子网可能已经存在，也可以有待创建。 我们可以定义这样的一个模块代码： terraform { required_providers { ucloud = { source = \"ucloud/ucloud\" version = \"~>1.22.0\" } } } variable \"network_config\" { type = object({ vpc_id = string web_app_config = object({ az = string subnet_id = string }) db_config = object({ az = string subnet_id = string }) }) } data \"ucloud_images\" \"web_app\" { name_regex = \"^WebApp\" } data \"ucloud_images\" \"mysql\" { name_regex = \"^MySql 5.7\" } resource \"ucloud_instance\" \"web_app\" { availability_zone = var.network_config.web_app_config.az image_id = data.ucloud_images.web_app.images[0].id instance_type = \"n-basic-2\" vpc_id = var.network_config.vpc_id subnet_id = var.network_config.web_app_config.subnet_id } resource \"ucloud_instance\" \"mysql\" { availability_zone = var.network_config.db_config.az image_id = data.ucloud_images.mysql.images[0].id instance_type = \"n-basic-2\" vpc_id = var.network_config.vpc_id subnet_id = var.network_config.db_config.subnet_id } 在代码中我们把依赖的网络参数定义为一个复杂类型，一个强类型对象结构。这样的话模块代码就不用再关注网络层究竟是查询而来的还是创建的，模块中只定义了抽象的网络层定义，其具体实现由调用者从外部注入，从而实现了依赖反转。 如果调用者需要创建网络层，那么代码可以是这样的(假设我们把前面编写的模块保存在./machine目录下而成为一个内嵌模块)： resource \"ucloud_vpc\" \"vpc\" { cidr_blocks = [ \"192.168.0.0/16\"] } resource \"ucloud_subnet\" \"dmz\" { cidr_block = \"192.168.0.0/24\" vpc_id = ucloud_vpc.vpc.id } resource \"ucloud_subnet\" \"db\" { cidr_block = \"192.168.1.0/24\" vpc_id = ucloud_vpc.vpc.id } module \"machine\" { source = \"./machine\" network_config = { vpc_id = ucloud_vpc.vpc.id web_app_config = { az = \"cn-bj2-02\" subnet_id = ucloud_subnet.dmz.id } db_config = { az = \"cn-bj2-02\" subnet_id = ucloud_subnet.db.id } } } 或者我们想使用现存的网络来托管服务器： data \"ucloud_vpcs\" \"vpc\" { name_regex = \"^AVeryImportantVpc\" } data \"ucloud_subnets\" dmz_subnet { vpc_id = data.ucloud_vpcs.vpc.vpcs[0].id name_regex = \"^DMZ\" } data \"ucloud_subnets\" \"db_subnet\" { vpc_id = data.ucloud_vpcs.vpc.vpcs[0].id name_regex = \"^DataBase\" } module \"machine\" { source = \"./machine\" network_config = { vpc_id = data.ucloud_vpcs.vpc.vpcs[0].id web_app_config = { az = \"cn-bj2-02\" subnet_id = data.ucloud_subnets.dmz_subnet.subnets[0].id } db_config = { az = \"cn-bj2-02\" subnet_id = data.ucloud_subnets.db_subnet.subnets[0].id } } } 由于模块代码中对网络层的定义是抽象的，并没有指定必须是resource或是data，所以使得模块的调用者可以自己决定如何构造模块的依赖层，作为参数注入模块。 "},"6.3.多可用区分布.html":{"url":"6.3.多可用区分布.html","title":"多可用区分布","keywords":"","body":"多可用区分布 这是一个相当常见的小技巧。多数公有云为了高可用性，都在单一区域内提供了多可用区的设计。一个可区是一个逻辑上的数据中心，单个可用区可能由于各种自然灾害、网络故障而导致不可用，所以公有云应用部署高可用应用应时刻考虑跨可用区设计。 假如我们想要创建N台不同的云主机实例，在Terraform 0.12之前的版本中，我们只能用count配合模运算来达成这个目的 variable \"az\" { type = list(string) default = [ \"cn-bj2-03\", \"cn-bj2-04\", ] } variable \"instance_count\" { type = number default = 4 } data \"ucloud_images\" \"centos\" { name_regex = \"^CentOS 7\" } resource \"ucloud_instance\" \"web\" { count = var.instance_count availability_zone = var.az[count.index % length(var.az)] image_id = data.ucloud_images.centos.images[0].id instance_type = \"n-standard-1\" charge_type = \"dynamic\" name = \"${var.az[count.index % length(var.az)]}-${floor(count.index/length(var.az))}\" } 简单来说就是使用count创建多实例资源时，用var.az[count.index % length(var.az)]可以循环使用每个可用区，使得机器尽可能均匀分布在各个可用区。 $ terraform apply -auto-approve data.ucloud_images.centos: Refreshing state... ucloud_instance.web[2]: Creating... ucloud_instance.web[0]: Creating... ucloud_instance.web[1]: Creating... ucloud_instance.web[3]: Creating... ucloud_instance.web[2]: Still creating... [10s elapsed] ucloud_instance.web[0]: Still creating... [10s elapsed] ucloud_instance.web[1]: Still creating... [10s elapsed] ucloud_instance.web[3]: Still creating... [10s elapsed] ucloud_instance.web[2]: Still creating... [20s elapsed] ucloud_instance.web[0]: Still creating... [20s elapsed] ucloud_instance.web[1]: Still creating... [20s elapsed] ucloud_instance.web[3]: Still creating... [20s elapsed] ucloud_instance.web[2]: Creation complete after 22s [id=uhost-txa2owrp] ucloud_instance.web[3]: Creation complete after 24s [id=uhost-v3qxdbju] ucloud_instance.web[1]: Creation complete after 26s [id=uhost-td3x545p] ucloud_instance.web[0]: Still creating... [30s elapsed] ucloud_instance.web[0]: Still creating... [40s elapsed] ucloud_instance.web[0]: Creation complete after 43s [id=uhost-scq1prqj] Apply complete! Resources: 4 added, 0 changed, 0 destroyed. 我们可以看一下创建的主机信息： $ terraform show # data.ucloud_images.centos: data \"ucloud_images\" \"centos\" { id = \"475496684\" ids = [ \"uimage-22noyd\", \"uimage-3p0wg0\", \"uimage-4keil1\", \"uimage-aqvo5l\", \"uimage-f1chxn\", \"uimage-hq5elw\", \"uimage-rkn1v2\", ] images = [ { availability_zone = \"cn-bj2-02\" create_time = \"2019-04-23T17:39:46+08:00\" description = \"\" features = [ \"NetEnhanced\", \"HotPlug\", ] id = \"uimage-rkn1v2\" name = \"CentOS 7.0 64位\" os_name = \"CentOS 7.0 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, { availability_zone = \"cn-bj2-02\" create_time = \"2019-04-16T21:05:03+08:00\" description = \"\" features = [ \"NetEnhanced\", \"HotPlug\", ] id = \"uimage-f1chxn\" name = \"CentOS 7.2 64位\" os_name = \"CentOS 7.2 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, { availability_zone = \"cn-bj2-02\" create_time = \"2019-09-09T11:40:31+08:00\" description = \" \" features = [ \"NetEnhanced\", \"HotPlug\", ] id = \"uimage-aqvo5l\" name = \"CentOS 7.4 64位\" os_name = \"CentOS 7.4 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, { availability_zone = \"cn-bj2-02\" create_time = \"2020-05-07T17:40:42+08:00\" description = \"\" features = [ \"NetEnhanced\", \"HotPlug\", \"CloudInit\", ] id = \"uimage-hq5elw\" name = \"CentOS 7.6 64位\" os_name = \"CentOS 7.6 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, { availability_zone = \"cn-bj2-02\" create_time = \"2019-04-16T21:05:05+08:00\" description = \"\" features = [ \"NetEnhanced\", \"HotPlug\", ] id = \"uimage-3p0wg0\" name = \"CentOS 7.3 64位\" os_name = \"CentOS 7.3 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, { availability_zone = \"cn-bj2-02\" create_time = \"2019-04-16T21:05:02+08:00\" description = \"\" features = [ \"NetEnhanced\", \"HotPlug\", ] id = \"uimage-4keil1\" name = \"CentOS 7.1 64位\" os_name = \"CentOS 7.1 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, { availability_zone = \"cn-bj2-02\" create_time = \"2019-04-16T21:04:53+08:00\" description = \"\" features = [ \"NetEnhanced\", \"HotPlug\", ] id = \"uimage-22noyd\" name = \"CentOS 7.5 64位\" os_name = \"CentOS 7.5 64位\" os_type = \"linux\" size = 20 status = \"Available\" type = \"base\" }, ] most_recent = false name_regex = \"^CentOS 7\" total_count = 7 } # ucloud_instance.web[1]: resource \"ucloud_instance\" \"web\" { auto_renew = true availability_zone = \"cn-bj2-04\" boot_disk_size = 20 boot_disk_type = \"local_normal\" charge_type = \"dynamic\" cpu = 1 cpu_platform = \"Intel/Broadwell\" create_time = \"2020-11-28T23:09:04+08:00\" disk_set = [ { id = \"df06380a-00e1-42df-8c07-eec67d817f97\" is_boot = true size = 20 type = \"local_normal\" }, ] expire_time = \"2020-11-29T00:09:06+08:00\" id = \"uhost-td3x545p\" image_id = \"uimage-dhe5m2\" instance_type = \"n-standard-1\" ip_set = [ { internet_type = \"Private\" ip = \"10.9.44.37\" }, ] memory = 4 name = \"cn-bj2-04-0\" private_ip = \"10.9.44.37\" root_password = (sensitive value) security_group = \"firewall-juhsrlvr\" status = \"Running\" subnet_id = \"subnet-dtu3dgpr\" tag = \"Default\" vpc_id = \"uvnet-f1c3jq2b\" } # ucloud_instance.web[2]: resource \"ucloud_instance\" \"web\" { auto_renew = true availability_zone = \"cn-bj2-03\" boot_disk_size = 20 boot_disk_type = \"local_normal\" charge_type = \"dynamic\" cpu = 1 cpu_platform = \"Intel/IvyBridge\" create_time = \"2020-11-28T23:09:01+08:00\" disk_set = [ { id = \"1d7f07c9-7342-431b-85bb-d3ee0022063d\" is_boot = true size = 20 type = \"local_normal\" }, ] expire_time = \"2020-11-29T00:09:02+08:00\" id = \"uhost-txa2owrp\" image_id = \"uimage-pxplaj\" instance_type = \"n-standard-1\" ip_set = [ { internet_type = \"Private\" ip = \"10.9.45.234\" }, ] memory = 4 name = \"cn-bj2-03-1\" private_ip = \"10.9.45.234\" root_password = (sensitive value) security_group = \"firewall-juhsrlvr\" status = \"Running\" subnet_id = \"subnet-dtu3dgpr\" tag = \"Default\" vpc_id = \"uvnet-f1c3jq2b\" } # ucloud_instance.web[3]: resource \"ucloud_instance\" \"web\" { auto_renew = true availability_zone = \"cn-bj2-04\" boot_disk_size = 20 boot_disk_type = \"local_normal\" charge_type = \"dynamic\" cpu = 1 cpu_platform = \"Intel/Broadwell\" create_time = \"2020-11-28T23:09:04+08:00\" disk_set = [ { id = \"31e2cad6-79a1-4475-a9f5-2c5c95605b18\" is_boot = true size = 20 type = \"local_normal\" }, ] expire_time = \"2020-11-29T00:09:04+08:00\" id = \"uhost-v3qxdbju\" image_id = \"uimage-dhe5m2\" instance_type = \"n-standard-1\" ip_set = [ { internet_type = \"Private\" ip = \"10.9.85.40\" }, ] memory = 4 name = \"cn-bj2-04-1\" private_ip = \"10.9.85.40\" root_password = (sensitive value) security_group = \"firewall-juhsrlvr\" status = \"Running\" subnet_id = \"subnet-dtu3dgpr\" tag = \"Default\" vpc_id = \"uvnet-f1c3jq2b\" } # ucloud_instance.web[0]: resource \"ucloud_instance\" \"web\" { auto_renew = true availability_zone = \"cn-bj2-03\" boot_disk_size = 20 boot_disk_type = \"local_normal\" charge_type = \"dynamic\" cpu = 1 cpu_platform = \"Intel/IvyBridge\" create_time = \"2020-11-28T23:09:04+08:00\" disk_set = [ { id = \"da27595d-9645-4883-bf95-87b9076ab7e4\" is_boot = true size = 20 type = \"local_normal\" }, ] expire_time = \"2020-11-29T00:09:04+08:00\" id = \"uhost-scq1prqj\" image_id = \"uimage-pxplaj\" instance_type = \"n-standard-1\" ip_set = [ { internet_type = \"Private\" ip = \"10.9.107.152\" }, ] memory = 4 name = \"cn-bj2-03-0\" private_ip = \"10.9.107.152\" root_password = (sensitive value) security_group = \"firewall-juhsrlvr\" status = \"Running\" subnet_id = \"subnet-dtu3dgpr\" tag = \"Default\" vpc_id = \"uvnet-f1c3jq2b\" } 可以看到，主机的确是均匀地分散在两个可用区了。 但是这样做在调整可用区时会发生大问题，例如： variable \"az\" { type = list(string) default = [ \"cn-bj2-03\", # \"cn-bj2-04\", ] } 我们禁用了cn-bj2-04可用区，按道理我们期待的变更计划应该是将两台原本属于cn-bj2-04的主机删除，在cn-bj2-03可用区新增两台主机。让我们看看会发生什么： $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.ucloud_images.centos: Refreshing state... [id=475496684] ucloud_instance.web[0]: Refreshing state... [id=uhost-scq1prqj] ucloud_instance.web[3]: Refreshing state... [id=uhost-v3qxdbju] ucloud_instance.web[2]: Refreshing state... [id=uhost-txa2owrp] ucloud_instance.web[1]: Refreshing state... [id=uhost-td3x545p] ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: ~ update in-place -/+ destroy and then create replacement Terraform will perform the following actions: # ucloud_instance.web[1] must be replaced -/+ resource \"ucloud_instance\" \"web\" { ~ auto_renew = true -> (known after apply) ~ availability_zone = \"cn-bj2-04\" -> \"cn-bj2-03\" # forces replacement ~ boot_disk_size = 20 -> (known after apply) ~ boot_disk_type = \"local_normal\" -> (known after apply) charge_type = \"dynamic\" ~ cpu = 1 -> (known after apply) ~ cpu_platform = \"Intel/Broadwell\" -> (known after apply) ~ create_time = \"2020-11-28T23:09:04+08:00\" -> (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) ~ disk_set = [ - { - id = \"df06380a-00e1-42df-8c07-eec67d817f97\" - is_boot = true - size = 20 - type = \"local_normal\" }, ] -> (known after apply) ~ expire_time = \"2020-11-29T00:09:06+08:00\" -> (known after apply) ~ id = \"uhost-td3x545p\" -> (known after apply) ~ image_id = \"uimage-dhe5m2\" -> \"uimage-rkn1v2\" instance_type = \"n-standard-1\" ~ ip_set = [ - { - internet_type = \"Private\" - ip = \"10.9.44.37\" }, ] -> (known after apply) + isolation_group = (known after apply) ~ memory = 4 -> (known after apply) ~ name = \"cn-bj2-04-0\" -> \"cn-bj2-03-1\" ~ private_ip = \"10.9.44.37\" -> (known after apply) + remark = (known after apply) ~ root_password = (sensitive value) ~ security_group = \"firewall-juhsrlvr\" -> (known after apply) ~ status = \"Running\" -> (known after apply) ~ subnet_id = \"subnet-dtu3dgpr\" -> (known after apply) tag = \"Default\" ~ vpc_id = \"uvnet-f1c3jq2b\" -> (known after apply) } # ucloud_instance.web[2] will be updated in-place ~ resource \"ucloud_instance\" \"web\" { auto_renew = true availability_zone = \"cn-bj2-03\" boot_disk_size = 20 boot_disk_type = \"local_normal\" charge_type = \"dynamic\" cpu = 1 cpu_platform = \"Intel/IvyBridge\" create_time = \"2020-11-28T23:09:01+08:00\" disk_set = [ { id = \"1d7f07c9-7342-431b-85bb-d3ee0022063d\" is_boot = true size = 20 type = \"local_normal\" }, ] expire_time = \"2020-11-29T00:09:02+08:00\" id = \"uhost-txa2owrp\" image_id = \"uimage-pxplaj\" instance_type = \"n-standard-1\" ip_set = [ { internet_type = \"Private\" ip = \"10.9.45.234\" }, ] memory = 4 ~ name = \"cn-bj2-03-1\" -> \"cn-bj2-03-2\" private_ip = \"10.9.45.234\" root_password = (sensitive value) security_group = \"firewall-juhsrlvr\" status = \"Running\" subnet_id = \"subnet-dtu3dgpr\" tag = \"Default\" vpc_id = \"uvnet-f1c3jq2b\" } # ucloud_instance.web[3] must be replaced -/+ resource \"ucloud_instance\" \"web\" { ~ auto_renew = true -> (known after apply) ~ availability_zone = \"cn-bj2-04\" -> \"cn-bj2-03\" # forces replacement ~ boot_disk_size = 20 -> (known after apply) ~ boot_disk_type = \"local_normal\" -> (known after apply) charge_type = \"dynamic\" ~ cpu = 1 -> (known after apply) ~ cpu_platform = \"Intel/Broadwell\" -> (known after apply) ~ create_time = \"2020-11-28T23:09:04+08:00\" -> (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) ~ disk_set = [ - { - id = \"31e2cad6-79a1-4475-a9f5-2c5c95605b18\" - is_boot = true - size = 20 - type = \"local_normal\" }, ] -> (known after apply) ~ expire_time = \"2020-11-29T00:09:04+08:00\" -> (known after apply) ~ id = \"uhost-v3qxdbju\" -> (known after apply) ~ image_id = \"uimage-dhe5m2\" -> \"uimage-rkn1v2\" instance_type = \"n-standard-1\" ~ ip_set = [ - { - internet_type = \"Private\" - ip = \"10.9.85.40\" }, ] -> (known after apply) + isolation_group = (known after apply) ~ memory = 4 -> (known after apply) ~ name = \"cn-bj2-04-1\" -> \"cn-bj2-03-3\" ~ private_ip = \"10.9.85.40\" -> (known after apply) + remark = (known after apply) ~ root_password = (sensitive value) ~ security_group = \"firewall-juhsrlvr\" -> (known after apply) ~ status = \"Running\" -> (known after apply) ~ subnet_id = \"subnet-dtu3dgpr\" -> (known after apply) tag = \"Default\" ~ vpc_id = \"uvnet-f1c3jq2b\" -> (known after apply) } Plan: 2 to add, 1 to change, 2 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. 变更计划与期望略有不同。我们仔细看细节： # ucloud_instance.web[2] will be updated in-place ~ resource \"ucloud_instance\" \"web\" { auto_renew = true availability_zone = \"cn-bj2-03\" boot_disk_size = 20 boot_disk_type = \"local_normal\" charge_type = \"dynamic\" cpu = 1 cpu_platform = \"Intel/IvyBridge\" create_time = \"2020-11-28T23:09:01+08:00\" disk_set = [ { id = \"1d7f07c9-7342-431b-85bb-d3ee0022063d\" is_boot = true size = 20 type = \"local_normal\" }, ] expire_time = \"2020-11-29T00:09:02+08:00\" id = \"uhost-txa2owrp\" image_id = \"uimage-pxplaj\" instance_type = \"n-standard-1\" ip_set = [ { internet_type = \"Private\" ip = \"10.9.45.234\" }, ] memory = 4 ~ name = \"cn-bj2-03-1\" -> \"cn-bj2-03-2\" private_ip = \"10.9.45.234\" root_password = (sensitive value) security_group = \"firewall-juhsrlvr\" status = \"Running\" subnet_id = \"subnet-dtu3dgpr\" tag = \"Default\" vpc_id = \"uvnet-f1c3jq2b\" } 原本名为cn-bj2-03-1的主机被更名为cn-bj2-03-2了，原本属于cn-bj2-04的第一台主机的变更计划是： # ucloud_instance.web[1] must be replaced -/+ resource \"ucloud_instance\" \"web\" { ~ auto_renew = true -> (known after apply) ~ availability_zone = \"cn-bj2-04\" -> \"cn-bj2-03\" # forces replacement ~ boot_disk_size = 20 -> (known after apply) ~ boot_disk_type = \"local_normal\" -> (known after apply) charge_type = \"dynamic\" ~ cpu = 1 -> (known after apply) ~ cpu_platform = \"Intel/Broadwell\" -> (known after apply) ~ create_time = \"2020-11-28T23:09:04+08:00\" -> (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) ~ disk_set = [ - { - id = \"df06380a-00e1-42df-8c07-eec67d817f97\" - is_boot = true - size = 20 - type = \"local_normal\" }, ] -> (known after apply) ~ expire_time = \"2020-11-29T00:09:06+08:00\" -> (known after apply) ~ id = \"uhost-td3x545p\" -> (known after apply) ~ image_id = \"uimage-dhe5m2\" -> \"uimage-rkn1v2\" instance_type = \"n-standard-1\" ~ ip_set = [ - { - internet_type = \"Private\" - ip = \"10.9.44.37\" }, ] -> (known after apply) + isolation_group = (known after apply) ~ memory = 4 -> (known after apply) ~ name = \"cn-bj2-04-0\" -> \"cn-bj2-03-1\" ~ private_ip = \"10.9.44.37\" -> (known after apply) + remark = (known after apply) ~ root_password = (sensitive value) ~ security_group = \"firewall-juhsrlvr\" -> (known after apply) ~ status = \"Running\" -> (known after apply) ~ subnet_id = \"subnet-dtu3dgpr\" -> (known after apply) tag = \"Default\" ~ vpc_id = \"uvnet-f1c3jq2b\" -> (known after apply) } 它的名字从cn-bj2-04-0变成了cn-bj2-03-1。 仔细想想，实际上这是一个比较低效的变更计划。原本属于cn-bj2-03的两台主机应该不做任何变更，只需要删除cn-bj2-04的主机，再补充两台cn-bj2-03的主机即可。这是因为我们使用的是count，而count只看元素在列表中的序号。当我们删除一个可用区时，实际上会引起主机序号的重大变化，导致出现大量低效的变更，这就是我们在讲count与for_each时强调过的，如果创建的资源实例彼此之间几乎完全一致，那么count比较合适。否则，那么使用for_each会更加安全。 让我们尝试使用for_each改写这段逻辑： variable \"az\" { type = list(string) default = [ \"cn-bj2-03\", \"cn-bj2-04\", ] } variable \"instance_count\" { type = number default = 4 } locals { instance_names = [for i in range(var.instance_count):\"${var.az[i%length(var.az)]}-${floor(i/length(var.az))}\"] } data \"ucloud_images\" \"centos\" { name_regex = \"^CentOS 7\" } resource \"ucloud_instance\" \"web\" { for_each = toset(local.instance_names) name = each.value availability_zone = var.az[index(local.instance_names, each.value) % length(var.az)] image_id = data.ucloud_images.centos.images[0].id instance_type = \"n-standard-1\" charge_type = \"dynamic\" } 为了生成主机独一无二的名字，我们首先用range函数生成了一个序号集合，比如目标主机数是4，那么range(4)的结果就是[0, 1, 2, 3]；然后我们通过取模运算使得名字前缀在可用区列表之间循环递增，最后用floor(i/length(var.az))计算出当前序号对应在当前可用区是第几台。例如4号主机在第二个可用区就是第二台，生成的名字应该就是cn-bj-04-1。 执行结果是： $ terraform apply -auto-approve data.ucloud_images.centos: Refreshing state... ucloud_instance.web[\"cn-bj2-03-1\"]: Creating... ucloud_instance.web[\"cn-bj2-03-0\"]: Creating... ucloud_instance.web[\"cn-bj2-04-0\"]: Creating... ucloud_instance.web[\"cn-bj2-04-1\"]: Creating... ucloud_instance.web[\"cn-bj2-03-1\"]: Still creating... [10s elapsed] ucloud_instance.web[\"cn-bj2-03-0\"]: Still creating... [10s elapsed] ucloud_instance.web[\"cn-bj2-04-0\"]: Still creating... [10s elapsed] ucloud_instance.web[\"cn-bj2-04-1\"]: Still creating... [10s elapsed] ucloud_instance.web[\"cn-bj2-03-1\"]: Still creating... [20s elapsed] ucloud_instance.web[\"cn-bj2-03-0\"]: Still creating... [20s elapsed] ucloud_instance.web[\"cn-bj2-04-0\"]: Still creating... [20s elapsed] ucloud_instance.web[\"cn-bj2-04-1\"]: Still creating... [20s elapsed] ucloud_instance.web[\"cn-bj2-04-1\"]: Creation complete after 21s [id=uhost-fjci1i4o] ucloud_instance.web[\"cn-bj2-04-0\"]: Creation complete after 23s [id=uhost-bkkhmref] ucloud_instance.web[\"cn-bj2-03-1\"]: Creation complete after 26s [id=uhost-amosgdaa] ucloud_instance.web[\"cn-bj2-03-0\"]: Still creating... [30s elapsed] ucloud_instance.web[\"cn-bj2-03-0\"]: Still creating... [40s elapsed] ucloud_instance.web[\"cn-bj2-03-0\"]: Creation complete after 45s [id=uhost-kltudgnf] Apply complete! Resources: 4 added, 0 changed, 0 destroyed. 如果我们去掉一个可用区： variable \"az\" { type = list(string) default = [ \"cn-bj2-03\", # \"cn-bj2-04\", ] } 我们可以检查一下执行计划： $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.ucloud_images.centos: Refreshing state... [id=475496684] ucloud_instance.web[\"cn-bj2-03-1\"]: Refreshing state... [id=uhost-amosgdaa] ucloud_instance.web[\"cn-bj2-04-0\"]: Refreshing state... [id=uhost-bkkhmref] ucloud_instance.web[\"cn-bj2-03-0\"]: Refreshing state... [id=uhost-kltudgnf] ucloud_instance.web[\"cn-bj2-04-1\"]: Refreshing state... [id=uhost-fjci1i4o] ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create - destroy Terraform will perform the following actions: # ucloud_instance.web[\"cn-bj2-03-2\"] will be created + resource \"ucloud_instance\" \"web\" { + auto_renew = (known after apply) + availability_zone = \"cn-bj2-03\" + boot_disk_size = (known after apply) + boot_disk_type = (known after apply) + charge_type = \"dynamic\" + cpu = (known after apply) + cpu_platform = (known after apply) + create_time = (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) + disk_set = (known after apply) + expire_time = (known after apply) + id = (known after apply) + image_id = \"uimage-rkn1v2\" + instance_type = \"n-standard-1\" + ip_set = (known after apply) + isolation_group = (known after apply) + memory = (known after apply) + name = \"cn-bj2-03-2\" + private_ip = (known after apply) + remark = (known after apply) + root_password = (sensitive value) + security_group = (known after apply) + status = (known after apply) + subnet_id = (known after apply) + tag = \"Default\" + vpc_id = (known after apply) } # ucloud_instance.web[\"cn-bj2-03-3\"] will be created + resource \"ucloud_instance\" \"web\" { + auto_renew = (known after apply) + availability_zone = \"cn-bj2-03\" + boot_disk_size = (known after apply) + boot_disk_type = (known after apply) + charge_type = \"dynamic\" + cpu = (known after apply) + cpu_platform = (known after apply) + create_time = (known after apply) + data_disk_size = (known after apply) + data_disk_type = (known after apply) + disk_set = (known after apply) + expire_time = (known after apply) + id = (known after apply) + image_id = \"uimage-rkn1v2\" + instance_type = \"n-standard-1\" + ip_set = (known after apply) + isolation_group = (known after apply) + memory = (known after apply) + name = \"cn-bj2-03-3\" + private_ip = (known after apply) + remark = (known after apply) + root_password = (sensitive value) + security_group = (known after apply) + status = (known after apply) + subnet_id = (known after apply) + tag = \"Default\" + vpc_id = (known after apply) } # ucloud_instance.web[\"cn-bj2-04-0\"] will be destroyed - resource \"ucloud_instance\" \"web\" { - auto_renew = true -> null - availability_zone = \"cn-bj2-04\" -> null - boot_disk_size = 20 -> null - boot_disk_type = \"local_normal\" -> null - charge_type = \"dynamic\" -> null - cpu = 1 -> null - cpu_platform = \"Intel/Broadwell\" -> null - create_time = \"2020-11-28T22:35:53+08:00\" -> null - disk_set = [ - { - id = \"b214d840-ffec-4958-a3da-3580846fd2a3\" - is_boot = true - size = 20 - type = \"local_normal\" }, ] -> null - expire_time = \"2020-11-28T23:35:53+08:00\" -> null - id = \"uhost-bkkhmref\" -> null - image_id = \"uimage-dhe5m2\" -> null - instance_type = \"n-standard-1\" -> null - ip_set = [ - { - internet_type = \"Private\" - ip = \"10.9.48.82\" }, ] -> null - memory = 4 -> null - name = \"cn-bj2-04-0\" -> null - private_ip = \"10.9.48.82\" -> null - root_password = (sensitive value) - security_group = \"firewall-juhsrlvr\" -> null - status = \"Running\" -> null - subnet_id = \"subnet-dtu3dgpr\" -> null - tag = \"Default\" -> null - vpc_id = \"uvnet-f1c3jq2b\" -> null } # ucloud_instance.web[\"cn-bj2-04-1\"] will be destroyed - resource \"ucloud_instance\" \"web\" { - auto_renew = true -> null - availability_zone = \"cn-bj2-04\" -> null - boot_disk_size = 20 -> null - boot_disk_type = \"local_normal\" -> null - charge_type = \"dynamic\" -> null - cpu = 1 -> null - cpu_platform = \"Intel/Broadwell\" -> null - create_time = \"2020-11-28T22:35:53+08:00\" -> null - disk_set = [ - { - id = \"6a3f274f-e072-4a46-90f8-edc7dbaa27f7\" - is_boot = true - size = 20 - type = \"local_normal\" }, ] -> null - expire_time = \"2020-11-28T23:35:53+08:00\" -> null - id = \"uhost-fjci1i4o\" -> null - image_id = \"uimage-dhe5m2\" -> null - instance_type = \"n-standard-1\" -> null - ip_set = [ - { - internet_type = \"Private\" - ip = \"10.9.176.28\" }, ] -> null - memory = 4 -> null - name = \"cn-bj2-04-1\" -> null - private_ip = \"10.9.176.28\" -> null - root_password = (sensitive value) - security_group = \"firewall-juhsrlvr\" -> null - status = \"Running\" -> null - subnet_id = \"subnet-dtu3dgpr\" -> null - tag = \"Default\" -> null - vpc_id = \"uvnet-f1c3jq2b\" -> null } Plan: 2 to add, 0 to change, 2 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. 可以看到，原来属于cn-bj2-03的两台主机原封不动，删除了属于cn-bj2-04的两台主机，并且在cn-bj2-03可用区新增两台主机。 "},"6.4.provisioner与user_data.html":{"url":"6.4.provisioner与user_data.html","title":"provisioner与user_data","keywords":"","body":"provisioner与user_data 我们在介绍资源时介绍了预置器provisioner。同时不少公有云厂商的虚拟机都提供了cloud-init功能，可以让我们在虚拟机实例第一次启动时执行一段自定义的脚本来执行一些初始化操作。例如我们在\"Terraform初步体验\"一章里举的例子，在UCloud主机第一次启动时我们通过user_data来调用yum安装并配置了ngnix服务。预置器与cloud-init都可以用于初始化虚拟机，那么我们应该用哪一种呢？ 首先要指出的是，provisioner的官方文档里明确指出，由于预置器内部的行为Terraform无法感知，无法将它执行的变更纳入到声明式的代码管理中，所以预置器应被作为最后的手段使用，那么也就是说，如果cloud-init能够满足我们的要求，那么我们应该优先使用cloud-init。 但是仍然存在一些cloud-init无法满足的场景。例如一个最常见的情况是，比如我们要在cloud-init当中格式化卷，后续的所有操作都必须在主机成功格式化并挂载卷之后才能顺利进行下去。但是比如aws_instance，它的创建是不会等待user_data代码执行完成的，只要虚拟机创建成功开始启动，Terraform就会认为资源创建完成从而继续后续的创建了。 解决这个问题目前来看还是只能依靠预置器。我们以一段UCloud云主机代码为例： resource \"ucloud_instance\" \"web\" { availability_zone = \"cn-bj2-03\" image_id = data.ucloud_images.centos.images[0].id instance_type = \"n-standard-1\" charge_type = \"dynamic\" network_interface { eip_internet_type = \"bgp\" eip_charge_mode = \"traffic\" eip_bandwidth = 1 } delete_eips_with_instance = true root_password = var.root_password provisioner \"remote-exec\" { connection { type = \"ssh\" host = [for ipset in self.ip_set: ipset.ip if ipset.internet_type==\"BGP\"][0] user = \"root\" password = var.root_password timeout = \"1h\" } inline = [ \"sleep 1h\" ] } } 我们在资源声明中附加了一个remote-exec类型的预置器，它的host取值使用了self.ip_set，self在当前上下文中指代provisioner所属的ucloud_instance.web，ip_set是ucloud_instance的一个输出属性，内含云主机的内网IP以及绑定的弹性公网IP信息。我们用一个for表达式过滤出弹性公网IP地址，然后使用ssh连接。预置器执行的脚本代码很简单，休眠一小时。如果我们执行这段代码： $ terraform apply -auto-approve data.ucloud_images.centos: Refreshing state... ucloud_instance.web: Creating... ucloud_instance.web: Still creating... [10s elapsed] ucloud_instance.web: Still creating... [20s elapsed] ucloud_instance.web: Provisioning with 'remote-exec'... ucloud_instance.web (remote-exec): Connecting to remote host via SSH... ucloud_instance.web (remote-exec): Host: 106.75.87.148 ucloud_instance.web (remote-exec): User: root ucloud_instance.web (remote-exec): Password: true ucloud_instance.web (remote-exec): Private key: false ucloud_instance.web (remote-exec): Certificate: false ucloud_instance.web (remote-exec): SSH Agent: true ucloud_instance.web (remote-exec): Checking Host Key: false ucloud_instance.web: Still creating... [30s elapsed] ucloud_instance.web (remote-exec): Connecting to remote host via SSH... ucloud_instance.web (remote-exec): Host: 106.75.87.148 ucloud_instance.web (remote-exec): User: root ucloud_instance.web (remote-exec): Password: true ucloud_instance.web (remote-exec): Private key: false ucloud_instance.web (remote-exec): Certificate: false ucloud_instance.web (remote-exec): SSH Agent: true ucloud_instance.web (remote-exec): Checking Host Key: false ucloud_instance.web: Still creating... [40s elapsed] ucloud_instance.web (remote-exec): Connecting to remote host via SSH... ucloud_instance.web (remote-exec): Host: 106.75.87.148 ucloud_instance.web (remote-exec): User: root ucloud_instance.web (remote-exec): Password: true ucloud_instance.web (remote-exec): Private key: false ucloud_instance.web (remote-exec): Certificate: false ucloud_instance.web (remote-exec): SSH Agent: true ucloud_instance.web (remote-exec): Checking Host Key: false ucloud_instance.web (remote-exec): Connected! ucloud_instance.web: Still creating... [50s elapsed] ucloud_instance.web: Still creating... [1m0s elapsed] ucloud_instance.web: Still creating... [1m10s elapsed] ucloud_instance.web: Still creating... [1m20s elapsed] ucloud_instance.web: Still creating... [1m30s elapsed] ucloud_instance.web: Still creating... [1m40s elapsed] ... 不出所料的话，该过程会持续一小时，也就是说，无论预置器脚本中执行的操作耗时多长，ucloud_instance的创建都会等待它完成，或是触发超时。 在这里我们可以使用这种方法的前提是我们使用的UCloud云主机的资源定义允许我们定义资源时声明network_interface属性，直接绑定一个公网IP。如果我们使用的云厂商Provider无法让我们在创建主机时绑定公网IP，而是必须事后绑定弹性IP呢？又或者，初始化脚本必须在云主机成功绑定了云盘之后才能成功运行？这种情况下我们还有最后的武器，就是null_resource。 null_resource可能是Terraform体系中最\"不Terraform\"的存在，它就是我们用来在Terraform这样一个声明式世界里干各种命令式脏活的工具。null_resouce本身是一个空的resource，只有一个名为triggers的参数以及id作为输出属性。 我们看下这个例子： data \"ucloud_images\" \"centos\" { name_regex = \"^CentOS 7\" } resource \"ucloud_eip\" \"eip\" { internet_type = \"bgp\" bandwidth = 1 charge_mode = \"traffic\" } resource \"ucloud_disk\" \"data_disk\" { availability_zone = \"cn-bj2-03\" disk_size = 10 charge_type = \"dynamic\" disk_type = \"data_disk\" } resource \"ucloud_instance\" \"web\" { availability_zone = \"cn-bj2-03\" image_id = data.ucloud_images.centos.images[0].id instance_type = \"n-standard-1\" charge_type = \"dynamic\" root_password = var.root_password } resource \"ucloud_eip_association\" \"eip_association\" { eip_id = ucloud_eip.eip.id resource_id = ucloud_instance.web.id } resource \"ucloud_disk_attachment\" \"data_disk\" { availability_zone = \"cn-bj2-03\" disk_id = ucloud_disk.data_disk.id instance_id = ucloud_instance.web.id } resource \"null_resource\" \"web_init\" { depends_on = [ ucloud_eip_association.eip_association, ucloud_disk_attachment.data_disk ] provisioner \"remote-exec\" { connection { type = \"ssh\" host = ucloud_eip.eip.public_ip user = \"root\" password = var.root_password } inline = [ \"echo hello\" ] } } 我们假设需要远程执行的操纵是必须在云盘挂载成功以后才可以运行的，那么我们可以声明一个null_resource，把provisioner声明放在那里，通过显式声明depends_on确保它的执行一定是在云盘挂载结束以后。 另外这个例子里我们运行的脚本非常简单，考虑一种更加复杂一些的场景，我们运行的脚本是通过文件读取的，我们希望在文件内容发生变化时能够重新在服务器上运行该脚本，这时我们可以使用null_resource的triggers参数： resource \"null_resource\" \"web_init\" { depends_on = [ ucloud_eip_association.eip_association, ucloud_disk_attachment.data_disk ] triggers = { script_hash = filemd5(\"${path.module}/init.sh\") } provisioner \"remote-exec\" { connection { type = \"ssh\" host = ucloud_eip.eip.public_ip user = \"root\" password = var.root_password } script = \"${path.module}/init.sh\" } } 现在provisioner运行的脚本是通过script参数传入的脚本文件路径，而我们通过filemd5函数把文件内容的哈希值传入了triggers。triggers会在值发生改变时触发null_resource的重建，这样脚本发生些许变化都会导致重新执行。 官方文档上还给出了对于triggers的另一个妙用： resource \"aws_instance\" \"cluster\" { count = 3 # ... } resource \"null_resource\" \"cluster\" { # Changes to any instance of the cluster requires re-provisioning triggers = { cluster_instance_ids = \"${join(\",\", aws_instance.cluster.*.id)}\" } # Bootstrap script can run on any instance of the cluster # So we just choose the first in this case connection { host = \"${element(aws_instance.cluster.*.public_ip, 0)}\" } provisioner \"remote-exec\" { # Bootstrap script called with private_ip of each node in the clutser inline = [ \"bootstrap-cluster.sh ${join(\" \", aws_instance.cluster.*.private_ip)}\", ] } } 这个例子里，我们需要所有AWS主机的内网IP参与才能够成功初始化集群，可能是类似Kafka或是RabbitMQ这样的应用，我们需要把集群节点的IP写入配置文件。如何确保未来机器数量发生调整以后，机器上的配置文件始终能够获得完整的集群内网IP信息，这里使用triggers就可以轻松完成目标。 另外在绝大多数生产环境中，服务器都不允许拥有独立的公网IP，或是禁止从服务器对外服务的公网IP直接连接ssh。这时一般我们会在集群中配置一台堡垒机，通过堡垒机进行跳转连接。可以访问通过堡垒机使用SSH的官方文档获取详细信息，在此不再赘述。 "},"6.5.destroy-provisioner中使用变量.html":{"url":"6.5.destroy-provisioner中使用变量.html","title":"destroy-provisioner中使用变量","keywords":"","body":"destroy-provisioner中使用变量 我们可以在定义一个provisioner块时设置when为destroy，资源在销毁之前会首先执行provisioner，可以帮助我们执行一些析构逻辑。但是如果我们在 Destroy-Provisioner 中引用了变量的话，比如这样的代码： resource \"aws_volume_attachment\" \"attachement_myservice\" { count = \"${length(var.network_myservice_subnet_ids)}\" device_name = \"/dev/xvdg\" volume_id = \"${element(aws_ebs_volume.ebs_myservice.*.id, count.index)}\" instance_id = \"${element(aws_instance.myservice.*.id, count.index)}\" provisioner \"local-exec\" { command = \"aws ec2 stop-instances --instance-ids ${element(aws_instance.myservice.*.id, count.index)} --region ${var.region} && sleep 30\" when = \"destroy\" } } 那么我们会看见这样的报错信息： | Error: Invalid reference from destroy provisioner │ │ Destroy-time provisioners and their connection configurations may only reference attributes of the related resource, via 'self', 'count.index', or 'each.key'. │ │ References to other resources during the destroy phase can cause dependency cycles and interact poorly with create_before_destroy. 从0.12开始 Terraform 会对在 Destroy-Time Provisioner 中引用除self、count.index、each.key以外的变量做警告，从0.13开始则会直接报错。 解决方法 目前官方推荐的做法是把需要引用的变量值通过triggers“捕获”一下再引用，例如： resource \"null_resource\" \"foo\" { triggers { interpreter = var.local_exec_interpreter } provisioner { when = destroy interpreter = self.triggers.interpreter ... } } 通过这种方法就可以避免这个问题。 "},"6.6.利用null_resource的triggers触发其他资源更新.html":{"url":"6.6.利用null_resource的triggers触发其他资源更新.html","title":"利用null_resource的triggers触发其他资源更新","keywords":"","body":"利用 null_resource 的 triggers 触发其他资源更新 社区有人提了一个 Terraform 问题，他写了这样一段 Terraform 代码： resource \"azurerm_key_vault_secret\" \"service_bus_connection_string\" { name = \"service-bus-connection-string\" value = azurerm_servicebus_topic_authorization_rule.mysb.primary_connection_string key_vault_id = azurerm_key_vault.main.id } resource \"azurerm_function_app\" \"main\" { name = \"myfn\" location = azurerm_resource_group.main.location resource_group_name = azurerm_resource_group.main.name app_service_plan_id = azurerm_app_service_plan.main.id enable_builtin_logging = true https_only = true os_type = \"linux\" storage_account_name = azurerm_storage_account.main.name storage_account_access_key = azurerm_storage_account.main.primary_access_key version = \"~3\" app_settings = { AzureWebJobsServiceBus = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.service_bus_connection_string.id})\" } } 意思大概是他把一段含有机密信息的连接字符串保存在 Azure KeyVault 服务中，然后创建了一个 Azure Faas 函数，通过 KeyVault 机密引用地址传递该机密。 问题描述 这位老兄发现，如果他修改了机密的内容，也就是azurerm_key_vault_secret声明里的value = azurerm_servicebus_topic_authorization_rule.mysb.primary_connection_string这一段的值的时候，KeyVault 保存的机密内容的确会正确更新，但 Azure Function 读取到的还是旧的机密引用地址，也就是这段代码中得到的 KeyVault 机密引用地址没有更新： app_settings = { AzureWebJobsServiceBus = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.service_bus_connection_string.id})\" } 更加奇怪的是，这之后他什么都没有做，只是重新再执行一次terraform apply，该引用地址又被正确更新了？！ 问题原因 因为 KeyVault Secret 被设计成是不可变的，所以更新azurerm_key_vault_secret的value会导致资源被重新创建。Terraform 官网上的相关文档中对该参数的定义如下： value - (Required) Specifies the value of the Key Vault Secret. 在 Terraform 中 ，一个参数如果被标记为Required，那么它不但是必填项，同时类似数据库记录的主键的概念，主键不同的记录被认定是两条不同的记录，修改记录的主键值可以看作是删除重建之。Terraform 资源的Required参数如果发生变化会触发重新创建资源，这就导致了修改value后，该azurerm_key_vault_secret的id也会发生变化。 那么为什么在azurerm_key_vault_secret被重新创建之后，我们会发现azurerm_function_app中引用的id没有变化呢？ Terraform 的工作流含有 Plan 和 Apply 两个主要阶段，首先会分析 Terraform 代码，调用 terraform refresh（可以用参数跳过该步骤）读取资源在云端目前的最新状态，再加上 State 文件中记录的状态，三个状态对比出一个执行计划，使得最终产生的云端状态能够符合当前代码描述的状态。 就这个场景而言，Terraform 能够意识到 azurerm_key_vault_secret的参数发生了变化，这会导致某种程度的更新，但它无法意识到这个更新会导致azurerm_key_vault_secret的id发生变化，进而导致azurerm_function_app也必须进行更新，所以就发生了他第一次执行terraform apply后看到的情况。 当他第二次执行terraform apply时，Terraform 记录的 State 文件里，azurerm_key_vault_secret的id和azurerm_function_app里使用的id已经对不上了，这时 Terraform 会再生成一个更新azurerm_function_app的 Plan，执行后一切恢复正常。 有没有办法让azurerm_function_app能在第一次生成 Plan 时就感知到这个变更？ 巧用 null_resource 的 triggers HashiCorp 提供了一个非常常用的内建 Provider —— null。其中最知名的资源就是null_resource了，一般它都是和provisioner搭配出现，可以用来在某些资源创建完成后执行一些自定义脚本等等。但是它还有一个很有用的参数： The triggers argument allows specifying an arbitrary set of values that, when changed, will cause the resource to be replaced. triggers参数可以用来指向一些值，只要这些值的内容发生了变动，会导致null_resource资源被重新创建，从而生成一个新的id。 一个小实验 我们尝试构建一个简单的实验环境来验证一下，首先是这样一段代码： resource \"azurerm_key_vault_secret\" \"example\" { name = \"secret-sauce\" value = \"szechuan\" key_vault_id = azurerm_key_vault.example.id } resource \"local_file\" \"output\" { filename = \"${path.module}/output.txt\" content = azurerm_key_vault_secret.example.id } 我们创建一个azurerm_key_vault_secret，然后把它的id输出到一个文件里。随后我们复制一下该文件，比如叫output.bak好了。随后我们修改azurerm_key_vault_secret的value到一个新的值，执行terraform apply以后，我们会发现output.txt与output.bak的内容完全一样，说明value的更新并没有触发local_file的更新。 随后我们把代码改成这样： resource \"azurerm_key_vault_secret\" \"example\" { name = \"secret-sauce\" value = \"szechuan2\" key_vault_id = azurerm_key_vault.example.id } resource \"null_resource\" \"example\" { triggers = { trigger = azurerm_key_vault_secret.example.value } } resource \"local_file\" \"output\" { filename = \"${path.module}/output.txt\" content = null_resource.example.id == null_resource.example.id ? azurerm_key_vault_secret.example.id : \"\" } 我们在代码中插入了一个null_resource，并设置triggers的内容，盯住azurerm_key_vault_secret.example.value。在value发生变化时，null_resource的id也会发生变化。 然后我们在local_file的代码中，content的赋值改成了这样一个三目表达式：null_resource.example.id == null_resource.example.id ? azurerm_key_vault_secret.example.id : \"\"。这个表达式里实际上null_resource.example.id是不起作用的，自己等于自己的永真条件会导致仍然使用azurerm_key_vault_secret.example.id作为值，但是由于掺入了null_resource.example.id，使得 Terraform 在第一次计算 Plan 时就感知到 local_file 的内容发生了变化，从而使得我们可以一次terraform apply搞定。 "},"7.CloudPosse最佳实践.html":{"url":"7.CloudPosse最佳实践.html","title":"来自CloudPosse的Terraform最佳实践","keywords":"","body":"CloudPosse 的 Terraform 最佳实践 CloudPosse是一家在美国的提供 DevOps 咨询顾问服务的公司，他们的口号是: DevOps Accelerator for Startups Own your infrastructure. We build it. You drive it. 我注意到这家公司是因为他们向社区贡献了大量高品质的 Terraform Aws Module，其代码之工整与完善与其他社区模块完全不在一个水平。经过研究找到了他们总结的一篇 Terraform 的最佳实践，在此翻译为中文以飨读者。 不过话说在前，该文档可能编写的时间较早，目前我并不完全同意列出的所有规则，某几条可能因为 Terraform 自身的发展已经显得不再那么绝对，并且由于 CloudPosse 是一家咨询公司，难免有以开源代码为自己打广告招揽顾客的动机，所以其代码在某些程度上甚至有些“过于工程化”。这只是 CloudPosse 的一家之言，读者还是需要结合自身实际情况来分析。 语言 使用带缩进的 HEREDOC 语法 使用（与之相对的是，没有-）来确保内联代码可以与项目中其他部分的代码共同锁进。注意，EOT可以用任意大写字符串代替（例如CONFIG_FILE） block { value = 不要使用 HEREDOC 语法来编写 JSON、YAML或者 Aws IAM 策略代码 Terraform 对于这几种格式有更好的方法来格式化： 对于 JSON，请在locals块中使用jsonencode函数 对于 YAML，请在locals块中使用yamlencode函数 对于 Aws IAM 策略代码，请使用名为aws_iam_policy_document的 Datasource。 不要编写过长的 HEREDOC 代码 如果内容很长，请把配置内容转移到一个独立的文件中，然后使用名为template_file的 Datasource 读取。 使用 Terraform Linting Linting 工具确保代码格式的统一，提升代码质量，并且可以检查一些常见的语法错误。 在提交所有代码之前运行terraform fmt。创建一个pre-commit钩子来自动化调用该命令。 使用合适的数据类型 在 Terraform 中使用合适的数据类型可以更容易地验证输入参数以及编写相关文档。 使用null而不是空字符串（\"\"） 当要表达true/false时，使用bool类型而不是string或者number 使用string存储文本 不要滥用object类型，为object类型编写校验规则以及文档比较困难 使用 CIDR 相关函数来计算网络地址空间 这可以降低其他合作者贡献代码的门槛并降低人为疏失的空间。CloudPosse 编写了一些相关的 Terraform 模块来帮助用户计算子网的地址空间： terraform-aws-dynamic-subnets terraform-aws-multi-az-subnets terraform-aws-named-subnets 更多相关信息请阅读官方文档。 在所有项目仓库中使用.editorconfig文件规定一致的空格风格 所有主流的 IDE 都有插件支持.editorconfig文件，使得我们可以强制实施一致的空格风格 我们推荐针对特定语言或项目规定空格风格。 CloudPosse 使用的标准.editorconfig文件内容如下： # Override for Makefile [{Makefile, makefile, GNUmakefile, Makefile.*}] indent_style = tab indent_size = 4 [*.yaml] intent_style = space indent_size = 2 [*.sh] indent_style = tab indent_size = 4 [*.{tf,tfvars,tpl}] indent_size = 2 indent_style = space 锁定所使用的 Provider 的最低版本 Terraform 的 Provider 保持着持续的更新，在编写模块时很难确定模块代码是否能够在更早的 Provider 版本上正确工作，并且这种测试旧版本 Provider 的努力通常不值得。由此我们希望对外通告我们所测试过的最低的 Provider 版本。 当然未来的 Provider 版本也有可能引入破坏性更新，但在 CloudPosse 的实践中这并不太会发生。另外，对于 CloudPosse 发布的模块代码，他们无法测试限制了 Provider 最高版本后会引入什么样的问题。所以对于 CloudPosse 发布的模块，他们只会锁定 Provider 的最低版本。 在用户编写的根模块中，用户可以锁定 Provider 的最高版本，或是锁定使用指定版本的 Provider 来避免发生意外。这是一个在稳定性与易用性之间进行的权衡，用户必须按照自身情况进行决策。 使用locals改善可读性 使用locals使得代码更加声明式以及可维护。与其在某些 Terraform 资源代码参数中使用复杂的表达式，不如将该表达式封装成一个local，然后在声明资源时引用它。 输入参数 在合适的时候使用上游模块或 Provider 的变量名 当编写一个接受输入参数的模块时，确保参数名与上游模块的output名一致以防止误解以及二义性。 变量名使用小写字母，以下划线作为分隔符 避免使用其他语言的语法规则，例如驼峰命名。所有变量的命名要统一，要遵循 HashiCorp 命名规范。 使用肯定的变量名以避免双重否定 所有用来代表打开或者关闭某项设置的输入变量名都应该以...._enabled结尾（例如：encryption_enabled）。变量的默认值可以是false也可以是true。 使用特性开关来配置打开或关闭某项功能 所有模块都应该通过特性开关来设置打开或是关闭某项功能。所有特性开关都应该以_enabled结尾，数据类型必须为bool。 所有输入参数都应该声明description值 所有输入参数都需要声明descripition值。当该参数源自于另一个上游 Provider（例如：terraform-aws-provider），请完整照搬上游 Provider 文档中的字句。 在合适的时候定义合理的默认值 模块应尽量开箱即用。默认值应尽可能确保整体配置的安全性（例如：encryption_enabled为true）。 所有传递机密的输入变量不可定义默认值 所有用来传递机密的输入变量都不应该定义默认值，这可以确保 Terraform 可以校验用户的输入。唯一的例外是该机密是可选的，并且在用户输入null或是\"\"（空字符串）时会自动生成一个。 输出值 所有的输出值都应该声明description值 所有输输出值都需要声明descripition值。尽可能照搬上游 Provider 中对应参数的description。避免在输出值的description中简单地重复输入参数名。 使用合规的蛇式命名法命名输出参数 避免使用其他语言的语法规则，例如驼峰命名。所有输出值的命名要统一，要遵循 HashiCorp 命名规范。 永远不要输出机密信息 模块永远不应该输出机密，相应的，机密信息应该被写入安全的存储，例如 AWS Secrets Manager，AWS SSM Parameter Store（由 KMS 加密），或是 S3 存储中（由 KMS 加密）。CloudPosse 更倾向于使用 AWS SSM Parameter Store。写入 SSM 的信息可以很容易地被其他 Terraform 模块读取，或是其他诸如chamber的命令行工具使用。 我们在编写根模块时严格执行该规定，因为这些机密信息很容易被泄漏到 CI/CD 流水线中。对于那些内嵌在其他模块中的子模块，我们的规定不会那么严格。 与其输出机密，我们可以输出一段文本指示机密存储的位置，例如创建 RDS 数据时，我们把管理员密码保存在路径为/rds/master_password的 SSM 存储中。我们可能还需要另一个输出值来保存该机密存储的密钥，这样其他需要读取管理员密码的程序可以使用该密钥读取到密码。 命名要对称 CloudPosse 喜欢确保 Terraform 输出值的名字尽可能与上游资源或模块对称，可以添加前缀。这能减少代码中的混乱或是二义性，同时提升一致性。下面是一个反面例子。输出值的名字应该是user_secret_access_key，这是因为它的取值来自于另一个模块的输出值secret_access_key，模块名含有user，所以可以添加前缀user_，最终处于一致性，输出值的名称应该是user_secret_access_key 状态 使用远程状态存储 使用 Terraform 创建用以存储远程状态的存储桶 这需要一个两阶段步骤来实施，第一阶段我们使用本地状态文件来创建一个远程存储桶。第二阶段我们启用远程状态存储配置（例如使用s3 {}）并且将本地状态导入远程存储（添加相关配置文件后简单执行terraform init即可自动导入）。CloudPosse 推荐这种策略因为它可以使用最好的工具来简化工作以及使用一致的工具。 可以使用terraform-aws-tfstate-backend模块来简化创建状态存储桶的工作。 使用支持状态锁的远程存储 CloudPosse 推荐使用 S3 存储状态的同时使用 DynamoDB 提供状态锁控制。 提示：使用terraform-aws-tfstate-backend模块可以轻松完成这一目标。 官方文档 https://www.terraform.io/docs/backends/types/s3.html 严格锁定使用的 Terraform CLI 版本 Terraform 状态文件有时在不同版本的 CLI 之间是不兼容的。CloudPosse 推荐开发人员通过容器使用 Terraform CLI 以锁定使用的版本。 提示：使用geodesic(一款 CloudPosse 出品的开源工具)管理所有的 Terraform 交互。 使用 Terraform CLI 设置状态存储参数 为提升根模块在不同账号之间的可重用性，应避免硬编码状态存储参数。相应的，应使用 Terraform CLI 设置当前使用的参数。 不要锁定使用的 Terraform 的最高版本 terraform { required_version = \">= 0.12.26\" backend \"s3\" {} } Terraform 大多数情况下都能保持向前兼容，所以我们希望可以在未来使用新版本来测试现有的模块代码。所以请不要限制使用的 Terraform 的最高版本，例如~>0.12.26或是>=0.13, 这样都会阻止未来的 Terraform 新版本运行当前模块。应使用>=限制最低版本即可。 使用加密的 S3 存储桶并开启版本控制、加密存储以及严格的 IAM 访问控制策略 CloudPosse 不推荐用一个存储桶存储不同栈的状态文件，这有可能会导致状态文件被错误覆盖或是泄漏。注意，状态文件中包含了所有输出值的内容。尽可能确保 100% 的物理隔离（每个 Stage 拥有独立的存储桶，独立的账号） 提示：使用terraform-aws-tfstate-backend可以轻松地为每一个 Stage 创建独立的状态存储桶。 启用状态存储桶的版本控制 启用状态存储桶的静态加密存储（Encryption at Rest） 使用.gitignore排除 Terraform 状态文件、状态文件备份、Terraform 文件夹等 .terraform .terraform.tfstate.lock.info *.tfstate *.tfstate.backup 使用.dockerignore文件排除 Terraform 状态文件 样例： **/.terraform* 命名规范 使用一致的编程命名规范 所有资源名（比如：在 AWS 上创建的那些资源）必须遵循一个一致的命名规范，这点之所以重要的原因是模块经常被用以组装成其他模块。强制实施一致的命名规范可以降低模块与其他模块创建的资源在名字上发生冲突的概率。 为了确保一致性，CloudPosse 要求所有模块都要调用terraform-null-label模块。使用该模块，用户可以通过修改参数的顺序或是分隔符的方式来修改生成资源名的方式。虽然该模块的使用不是必须的，但事实证明该机制是一种解决命名冲突非常有效的方法。 DNS 基础设施 使用独立的 DNS Zone 不要在不同 Stage 和环境之间混用 DNS Zone。 为每个 AWS 账户委派一个独享 DNS 区域 区分品牌域名与服务发现域名的管理 服务发现域名是指用来提供服务发现服务的域名。终端用户极少会直接使用这种域名。应该只有一个服务发现域名，但不同环境下使用各自独立的 DNS Zone 来管理该域名的解析。 品牌域名是终端用户用来访问服务所使用的域名，这些域名由产品、市场和业务场景来决定。可以有多个不同的品牌域名指向同一个服务发现域名。品牌域名的架构并非是服务发现域名架构的镜像。 模块的设计 小而精的模块 CloudePosse 认为一个模块应该把一件事做到最好。为了达到这个目标，简单地把 Terraform 资源打包成模块化代码并没有什么用。为这些资源设计一种专门的使用场景则更为有用。（译者理解：每一个模块都应有一个特定的使用场景，例如创建 Subnet ，CloudPosse 就编写了dynamic-subnet、named-subnets、multi-az-subnets三种模块 可组合的模块 模块应编写成易于与其他模块进行组合，这是 CloudPosse 用以提升规模经济性以及停止重新发明模式轮子大的方法。 使用输入参数 模块应尽可能使用输入参数。应避免定义类型为object的输入参数，因为该类型很难编写文档（译者理解：很难为object类型输入参数编写详尽的description提示调用者）。当然，这并不是一个绝对的禁令，有时候使用object的确更加合适。需要注意类似terraform-docs这样的工具能否生成有意义的文档。 模块的使用 使用 Terraform registry 格式锁定指定的模块版本 Terraform 模块的source参数有多种表达方式。CloudPosse 的传统是使用 Terraform registry 语法显式锁定一个确切的版本： source = \"cloudposse/label/null\" version = \"0.22.0\" 显式锁定确切版本的原因是因为，使用例如>=0.22.0这样可升级的版本约束可能会引入破坏性变更。对基础设施的所有变更都应该是由最终用户来控制和审查的，不能在部署变更时盲目信任变更结果。 （译者理解：由于模块版本变化带来的变更并非模块调用者所触发的，亦非模块调用者所能控制的，故应避免这种情况的发生。） "},"8.后记.html":{"url":"8.后记.html","title":"后记","keywords":"","body":"后记 这本教程的编写花的时间比我想象的多，一方面是因为个人能力有限，另一方面不少内容是翻译自官方文档。由于官方文档类似于使用手册，不需要考虑阅读者循序渐进学习的顺序，所以花了不少时间斟酌和调整章节的顺序，以期能够使得初学者在按照顺序阅读时不至于会被尚未学习的概念所困扰。 在我编写本作时，其实已经在家里歇了很长一段时间了，有各方面的原因，其中有一部分原因是因为我在近些年以来越来越强烈地感觉到中国的软件行业，尤其是互联网产业出现了问题。当我们越来越依赖软件时，软件已经成为了像电力、自来水、道路桥梁这样关系到国计民生的重要基础设施，但如果我们仔细地观察许多的互联网公司的工作方式，经常会看到许多团队仍然停留在手工作坊的水准；这种问题并不只是小公司有，其实互联网巨头也有，我们不能把巨头看作是水平均匀分布的利维坦，其实巨头内部更像是部落联盟，不同的事业部，不同的产品线，不同的团队，可能理解、眼界和水平相差非常巨大。 大公司有一种精细化分工的倾向，总希望把软件生产过程细分成一个高度协同的流水线，但流水线却是根据技能来分隔成不同的团队的。这样的好处是每个功能团队都可以独立发展自己的技术栈、工具链，都可以独立安排各自的优先等级，另外把技能切分的非常细也有助于用流程和文档把技能沉淀下来，降低特定人员离职所引发的风险，但另一方面这种做法人为地在团队间建立了高高的部门墙，产品经理会说“我不管你怎么实现”；开发人员会不管测试团队如何测试，写出可测性很低的代码，同时视公认的开发最佳实践单元测试为测试的事从而跳过编写单元测试；测试人员很委屈，既然你不配合我做测试，那我索性也不专注于测试具体应用了，测试团队转型变成了测试工具开发团队，反正平台和工具我做出来了，开发不用那就不是我的事了；运维团队往往是最后才拿到要部署的应用，应用上线各种各样的故障运维团队能做的事不多，也只能疲于奔命。 我看了很多“团队”用这种低效的方式协同，造成了许多的问题，互相扯皮指责；管理者为了进度，无意挽起裤脚管下地去了解一线真正的现状，而是制定一些简单的量化指标，比如故障级别、故障率、故障时长、加班时长、BUG率等等，希望简单粗暴的996就可以解决问题。我认为这一切都是非常荒唐的，就像盲人摸象，没有一个盲人认为自己有能力，或者有义务先去了解整个大象的全貌，再下定论。这种精细化分工和简单量化的方式是错误的。 我之所以对Terraform和Pulumi这样的基础设施即代码工具着迷，原因是我认为它们所指出的方向非常正确。在传统的软件开发，或者互联网开发中，开发多多少少会鄙视基础设施和运维，总觉得写代码的能力强，部署应用、配置服务器的那是比较低级的活；开发甚至内部都存在鄙视链，多少面试都是必问算法、原理、底层，考操作系统，考多线程高并发，考数据库锁，结果实际生产中写出来的代码连个像样的单元测试都没法编写，因为可测性太差了，就这样的水准，还会上知乎询问“业务代码写多了只会CRUD怎么办？”；写代码时完全不管安全性、高可用这些问题，因为这些问题都是“低级”的运维和基础设施团队该做的。这种认知是有毒的，是错误的，正确的方式应该是，围绕着一个产品，所有相关的人，不论他的技能特点如何，他们都是一个团队，他们的认知应该是统一的，信息是全面的，我们需要一种新的，覆盖全生命周期的软件研发方法论，技术人员和非技术人员要学会用一种统一的全面的视角来思考问题，眼界绝对不能局限于自己擅长的技能点上。基础设施即代码技术是一个很好的实践，它能使得开发、运维以及测试，对基础设施这件事有完全一样的认知，更好的是，它使得在传统软件开发中一些很好的实践，比如设计模式、SOLID原则等，都可以应用到基础设施领域，我们甚至可以使用单元测试驱动开发的方式来编写基础设施代码。摸象的盲人们虽然还是盲的，但是这一次，盲人们至少认识到，长鼻子和大耳朵都是长在同一个象头上的。这算是我在技术方面的“天下大同”的梦想吧。 在本书的编写过程中，得到了许多师长朋友的鼓励和支持，尤其是我的太太，对于我这样闲居在家的人并没有给予什么压力，使我可以自由地思考和进行学习探索。得妻如此，夫复何求？我太太是一个特别热爱学习特别独立的优秀女性，我为她感到由衷的自豪。 愿中国互联网能够有一个更好的发展，愿中国技术人员不用再被强迫进行无意义的996。 "}}